[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Daniela Delgado\nMachine Learning: Course Blog Posts\nMiddlebury College ’24"
  },
  {
    "objectID": "posts/final-project-post/index.html",
    "href": "posts/final-project-post/index.html",
    "title": "Final Project Blog Post",
    "section": "",
    "text": "Navigating tipping etiquette at restaurants or shops can be challenging due to inconsistencies across different locations and cultures. In our project, we aimed to analyze the tipping behavior following meals at restaurants. Specifically, we sought to investigate whether various factors, such as gender or party size, influenced tip amounts. To address this issue, we employed predictive models, those being linear regression, decision tree classifier, and random forest classifier, to estimate the expected tip for each individual based on the given variables. We ran these models simply on the data and then with combinations of different columns/attributes. The overall results on our testing data was a score accuracy of about 40% and with signs of overfitting.\nGitHub repository\nGitHub py file"
  },
  {
    "objectID": "posts/final-project-post/index.html#your-data",
    "href": "posts/final-project-post/index.html#your-data",
    "title": "Final Project Blog Post",
    "section": "Your Data",
    "text": "Your Data\nThe data was collected from a dataset website known as Kaggle and the collaborator of the dataset is Sakshi Satre ((SatreTipsDataset2024?)). This dataset is used for visualizations in data analysis and it contains information about different factors of customers in a restaurant, such as the total bill amount, tip amount, gender, whether the customer is a smoker or not, the day of the week, time of day (lunch or dinner), and the size of the party. Below are the descriptions of each of these factors as written in the dataset:\ntotal_bill: This attribute represents the total amount of the bill paid by the customer, including the cost of the meal, taxes, and any additional charges.\n\ntip: This attribute denotes the amount of tip left by the customer. It is typically calculated as a percentage of the total bill and is often discretionary. (This helped form our target value)\n\nsex: This attribute indicates the gender of the customer. It could be either male or female.\n\nsmoker: This attribute indicates whether the customer is a smoker or a non-smoker. It's a categorical variable with two possible values: \"Yes\" for smokers and \"No\" for non-smokers.\n\nday: This attribute represents the day of the week when the meal was consumed. It could be any of the seven days in a week (e.g., Monday, Tuesday, etc.).\n\ntime: This attribute denotes the time of the day when the meal was consumed. It's often categorized into two values: \"Lunch\" for meals consumed during the day and \"Dinner\" for meals consumed in the evening.\n\nsize: This attribute indicates the size of the party dining together. It represents the number of people included in the bill.\nThere were a few limitations of the data given that some identifying attributes that impact how much a person tips is based on age and race of the customer. Additionally, the sex of the waiter would be important to note to see if the tip given would be impacted on if the customer was a male and the waitress was a female. Another limitation is the small number of customers/rows in our dataset. We had a little less than 250 rows which is not ideal for training and testing. The type of restaurant, such as if it is a dinner or a sports bar and grille, is also not included. This is important information because that also plays a role on how much is being tipped as it depends on the customers that eat at those restaurants. For example, if a restaurant is higher-end, that will attract people on the wealthier side, thus they might tip more compared to customers from a lower-end restaurant."
  },
  {
    "objectID": "posts/final-project-post/index.html#your-approach",
    "href": "posts/final-project-post/index.html#your-approach",
    "title": "Final Project Blog Post",
    "section": "Your Approach",
    "text": "Your Approach\nFrom the features listed above, our target value was created using the tip column. Using the total_bill column, we found the percentage each tip from the customer fell into, for example, we saw if the tip was 15% of the bill or 10%. Then from this, we grouped the percent tips into groups, that is, if the percent fell into a group of 0-10%, 10-15%, 15-20%, 20-25%, or over 25%. Lastly, we encoded the groupings so our target value y consisted of either 0, 1, 2, 3, or 4s. For our predictor features, we used the remaining attributes such as the size, the day (encoded), the time (encoded), the total_bill, the smoker (encoded), and the sex (encoded). To train our data, we used the models logistic regression, decision tree classifier, and random forest classifier. We chose these as we wanted to compare what model would provide a higher accuracy score with our data, which was our way of evaluating our models. These were the classifier models we worked on for our penguin blog post, so we decided to test them with this data as well. Furthermore, taking more inspiration from the penguins blog post, we decided to also try to see if combinations of different features would affect the accuracy score for each model. We were interested in seeing what factors seemed to classify the tips. As mentioned, we evaluated our models based on the accuracy score and had our testing set be 20% of our data."
  },
  {
    "objectID": "posts/women-in-DS/index.html",
    "href": "posts/women-in-DS/index.html",
    "title": "Women in Data Science",
    "section": "",
    "text": "Abstract\nIn this blog post, I explore why it is important to spotlight women in data science and analyze questions on why women are underrepresented in data science and STEM fields, why it is an issue, how it became an issue, and if there have been changes in representation since the 20th century. To answer these questions, I take information from some of the sections from the report “Solving the Equation: The Variables for Women’s Success in Engineering and Computing” written by Corbett and Hill (2015). Furthermore, I highlight a few women in STEM, specifically in data science, who came to talk at Middlebury College as part of the Middlebury Women in Data Science (WiDS) Conference and report their research. From these readings and the conference talks, my main takeaways are that women are limited in STEM fields based on the false ideas that society imposes on them and assumes of them, women in data science add to the creative and critical thinking skills needed to find solutions to world problems, and in order to increase female presence in STEM fields, we need to hold more spaces for women to see and hear the achievements of other women, such as this WiDS conference.\n\n\nWhy Spotlight Women in Data Science?\nWomen are underrepresented in computing, math, and engineering, and it is a problem for innovation. For example, problems that need solutions, such as climate change and water allocation, require the skills of computing, math and engineering fields. Having a smaller representation of women in the field limits the creative potential to solve these problems. Additionally, companies are also at a loss as, due to the gender biases, they often chose men to work for their company despite them scoring lower in math than some women. This places the company at a disadvantage as they are less globally competitive. Furthermore, the problem is also for women as they are missing out on high-quality job opportunities with high pay. These jobs are also more flexible, which women would be missing out on. Moreover, the continual under-representation of women in these fields leads to a perpetual cycle of living in the harmful stereotypes and gender biases that women do not belong in the computing, math, and engineering fields because they do not see themselves in those jobs.\nTo take this under-representation into perspective, the percent of women who are computing professionals was the same in 2013 as it was in the 1960s. Taking a walk through women in STEM history, a few number of women began to earn engineering degrees in the late 1800s and early 1900s. By the 1950s, women made up about 1% of the students in engineering programs in universities. Throughout the 1950s and into the 60s, male colleges began to admit women to increase the number of female students in the programs. However, because of male-dominated fields and gender norms, engineering was still considered to be for males.\nIn computing, women were more represented in the 1950s than men. For example, during Word War II, women made up most of the computer programmers. However, in the 1960s and 70s, men began to dominate the field due to hiring practices favoring men and because they did more gaming on personal computers so men began to be more attracted to the computing field. Men did more gaming as it was linked to the “hobbyist” culture and game playing in arcades that was usually dominated by males. Moreover, as computing became a more popular field to learn in colleges and universities, the departments had to place strict requirements to allow entry into the field. These requirements were disproportionately disadvantageous to women as they had less experience with programming and math than their counterparts. For all of these reasons, women today are still as underrepresented in the computing field today as they were in the 1950s and 60s.\nDespite the history of how this under-representation began, spotlighting women’s achievements can destroy some of the hurdles women face in deciding to join the STEM fields. For example, a barrier that can be eroded by spotlighting women’s achievements is the barrier of feeling isolated in the field, that is, lacking mentors to help women and feeling like the space is not safe to speak up. This can be eroded by seeing the achievements of women in STEM as they would show that it is possible to be valued and courageous as well as to know that there are other women that can substitute as their mentor and get advice from them and their story. This community of women in STEM fosters a supportive community where women can connect, learn from one another, and access mentorship opportunities to dismantle the feeling of isolation and lack of guidance. Additionally, another barrier faced is the gender stereotype that men are better than girls at math and physical sciences. This roadblock is detrimental to women’s representation in STEM fields as they feel less than and not as intelligent to pursue the fields in the first place. However, it can be destroyed by people seeing women succeeding in the STEM fields as it proves the gender stereotypes wrong. It illustrates that women are smart and do not fall short of men as can do anything they put their minds to. Seeing other women’s achievements allows women to chose to pursue STEM fields as they see themselves represented in that career path and realize that their gender does not limit their capabilities or potential for success. Moreover, with the accomplishments on display, women can combat the sexism found in these fields where women receive less challenging assignments, thus limiting their career advancements. This exhibit of women’s success in STEM can dismantle sexism in the department as it proves to department heads and women themselves that women can do impactful and vigorous work if given the challenge.\n\n\nLightning Talks\nIn the Women in Data Science Conference held at Middlebury College, there were three women who gave lightning talks of 15 minutes describing their research and work in data science. For the first lighting talk, Professor Amy Yuen spoke about addressing the question: Is the United Nations security council a democratic institution? In her findings, she found that the security council is not equal in the way we believe because some people have veto power, while others do not. Specifically, out of 15 members in the council, only five hold the power to veto. To answer the question, she looked at meetings, presidential statements, etc. to see who engages with the council while also looking at what regions are in the council. A surprising finding, at least for me, was that Japan and Brazil have the top two longest sittings in the council. However, as the results came to show, the average line is more flat, illustrating the inclusivity and representation of states in the council. The results came to be that the UN security council is somewhat democratic, but it could be worse in terms of states.\nOn the other hand, Dr. Jessica L’Roe, the second lightning round speaker, researches land use in conservation hotspots and livelihoods, and works with survey data, interview data, property data, land cover data, and more. During her presentation, she spoke on land registration in the Amazon Rainforest in Brazil. The problem she wanted to address was: does the environmental registrar discourage deforestation? To answer this question, she took data from registered property boundaries and found that people lied about where their property boundaries lie and often said they owned less land than they did. This highlights potential flaws in the current land registration system, which are a detriment in raising conservation efforts. Additionally, she also spoke on monitoring the change in tropical forest landscapes, specifically the land covered change in Uganda. Noticing more trees were being planted rather than food production increasing, she asked the question: who is planting these trees and why? She took data from surveys connected to field-mapped woodlot polygons where the woodlots are owned by non-local people. Professor L’Roe tied in this research to a related problem of: as competition for land increases what happens to local youth? To answer this related question, she took quantitative and qualitative surveys over periods of time and found that mothers would rather invest in education rather than land because it was a safer bet for the success and future of their children. Finally, in her presentation, she had an overarching theme that women make big and important contributions to data science and conservation with data. She also emphasized the importance of women role models in the field and how the lack of women in data science and STEM should not discourage women from taking part in it. I especially took away how she mentioned that anything can be data because I did not imagine data science could be taken to the work of land conservation.\nFor the final lightning talk, Professor Laura Biester spoke on her study on computational linguistics models for mental health. She needed to collect text data for mental health research, but it was a huge challenge due to privacy. Thus, she had to rely on using “self-reports.” In her work, she found that self-reports give hints on when the user was first diagnosed with depression, so she turned to Reddit to collect data files from 2006 to 2019 from people who self-reported. She collected statistics from users and then collected all of their posts from Reddit. In the end, she had about 20,500 diagnosed users and nine controls per user. After getting the data, she worked to normalize the models and classify it with a linear model. She found that model weights for pre-diagnosis models correspond more to symptoms while weights for all-encompassing models correspond more to mental health discussion. In her presentation, I learned that computational linguistics models can provide valuable insights into mental health trends, and there are always ways to get access to the data you need for your research.\n\n\nKeynote Presentation by Dr. Sarah M. Brown\nFollowed by the lightning talks, a keynote presentation was given by Dr. Sarah M. Brown. She started by talking about how data science skills can be found in unexpected places, which is true as proven by the professors who gave the three lightning talks. She also spoke on making machine learning more fair, which is something we have been analyzing and discussing in our Machine Learning 451 course at Middlebury College. For this, she mentioned thinking of machine learning as a sociotechnical system and growing our toolbox in data science. To grow the tool box, she spoke on three different projects she has worked on that gave her more tools to add into her toolbox. These three tools, which she calls keys, she explained during her talk and said they were helpful in solving problems in data science.\nThe first project she spoke on used the skill from 2004 which included using context to understand primary sources and importantly mentioned that data is a primary source. This project took place in 2012 that consisted of a patient and clinician seeing if the patient has PTSD, but instead of the clinician diagnosing, it would be the computer. There were scores to differentiate between the people who had PTSD and they were ranked on a scale. The key taken from this project was to understand the data’s context as it can enhance the accuracy and reliability of computational models. The second project’s skill is from her experience in 2009 where, within a given field, the same work can have different meanings in other fields. The key taken away is that disciplines are communities. The third project’s skill is tied to the second where everyone has different rules and ways of running things at the national, regional and chapter level. Thus, the key is to meet people where they are. With this third project, she needed a model to quantify fairness. She wanted to maximize what the feature says about the value variable and minimize the features with what is being fitted, in her research case it is accuracy compared to fairness.\nShe says data is biased because the world is biased, which is the reason biased models exist and why machine learning can be biased. She says choosing data to retrain data makes better data and, in order to solve these biases, creative thinking is a requirement. I really took away from these points as it is true that data is biased and it is those who are affected by the models, usually marginalized people, who want to work to fix the biased models.\n\n\nConclusion and Reflection\nFrom this blog post, I learned that women believe they cannot succeed in math-heavy fields, such as engineering and computing, because society falsely tells them they are not as intelligent as men when it comes to mathematics. I did not know there was such an extensive history behind the reasons the under representation exists in the first place, such as gaming being the reason men decided to take up computing and because of the head start on education men had in the 1800s. Learning about the different barriers deterring women from getting a degree in a STEM field made me reflect and become aware that these were also things I found myself telling myself in order to not pursue computer science as a major, and thoughts I find myself thinking of now at times. However, reading about why it is important for women to be represented and noting everything I and the world would be missing out on in regards to growth opportunities from women partaking in computing and learning about the important work women are doing in data science, it makes me proud of the work I am doing. Moreover, I also learned that all things can be data and data can be found anywhere. My biggest takeaway was the mention of bias in data and how that creates biased machines. I never thought that data was biased as data is science and science has proof behind it. However, after listening to Dr. Brown’s talk and connecting it to the discussions and readings we have done in class, I realized we do live in a biased world where we have to question and be skeptical of the way and the data was gathered and the methods used. This being said, I am interested in learning more on the collection of data and finding ways to make is as less biased as possible."
  },
  {
    "objectID": "posts/optimal-decision-making/index.html",
    "href": "posts/optimal-decision-making/index.html",
    "title": "Optimal Decision Making",
    "section": "",
    "text": "Introduction\n\nIn this blog post, I start off by making different graphs and tables to see if there is any correlation and patterns between a person’s information and seeing how the interest rate is affected by this information. Then, I used logistic regression to construct a score function and threshold for predicting whether a prospective borrower is likely to default on a given loan. Looping through the max and min scores, I found the best threshold to maximize the bank’s profit by calculating how much the bank will gain or lose based on if the person with that score defaults or not from paying the loan. In my test results, I got that the best threshold was about -0.175 with the bank’s expected profit per borrower to be about $1168.39.\nIn seeing if certain groups have more difficulty than others in getting a loan because of defaulting based on the threshold proposed from the system, all of the borrowers have a decision, or probability, of defaulting based on the threshold. There might be an error or missing step in my calculations.\n\n\n\nPart A: Grab the Data\n\n# downloading training data\n\nimport pandas as pd\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n\ndf_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n\n\n\n\n\n\n\nPart B: Explore The Data\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nsns.scatterplot(data = df_train, x = 'loan_int_rate', y = 'loan_percent_income', hue = 'cb_person_default_on_file')\nplt.title(\"Loan interest rate and loan percent income based on person defaulting\")\nplt.show()\n\n\n\n\n\n\n\n\nIn this scatterplot, we can see the how the loan interest rate is affected by seeing if the person defaulted previously on a loan and the person’s percent income. The loan interest rate increases if the person has a record of defaulting on a loan.\n\nsns.boxplot(data = df_train, x = 'person_home_ownership', y = 'loan_int_rate')\nplt.title(\"Interest Rate Based on a Person's Home Ownership\")\nplt.show()\n\n\n\n\n\n\n\n\nThis graph further explores how the loan interest rate differs and compares based on a person’s home ownership. We can see that a person who has a mortgage has a lower mean for the interest rate, while a person renting and those with other forms of home ownership have higher loan interest rates on average.\n\nmeanTable = df_train.groupby(['loan_intent', 'cb_person_default_on_file']).aggregate({'person_age': ['mean', 'std'], 'person_income' : ['mean', 'std'], 'cb_person_cred_hist_length' : ['mean', 'std'], 'loan_int_rate': ['mean', 'std']})\nmeanTable\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\ncb_person_cred_hist_length\nloan_int_rate\n\n\n\n\nmean\nstd\nmean\nstd\nmean\nstd\nmean\nstd\n\n\nloan_intent\ncb_person_default_on_file\n\n\n\n\n\n\n\n\n\n\n\n\nDEBTCONSOLIDATION\nN\n27.523949\n5.822429\n66504.540596\n54849.658619\n5.644276\n3.915509\n10.216206\n3.008325\n\n\nY\n27.883289\n6.379513\n67551.327586\n58425.810386\n5.928382\n4.121033\n14.565023\n1.758878\n\n\nEDUCATION\nN\n26.505755\n6.058923\n64403.688983\n40406.252292\n5.074231\n3.572837\n10.273948\n2.967930\n\n\nY\n27.047126\n6.009493\n61127.258621\n35589.171553\n5.471264\n3.910798\n14.357234\n1.650609\n\n\nHOMEIMPROVEMENT\nN\n29.088624\n5.637893\n72891.920750\n49281.092741\n6.512995\n3.964697\n10.358453\n3.158075\n\n\nY\n28.529730\n5.966250\n73886.228829\n52241.077202\n6.079279\n3.974765\n14.576099\n1.739466\n\n\nMEDICAL\nN\n27.927044\n6.376993\n61528.271447\n48179.985735\n5.912201\n4.004978\n10.281730\n2.989114\n\n\nY\n28.061628\n6.322874\n60326.900000\n59500.584963\n5.919767\n4.109030\n14.531599\n1.718297\n\n\nPERSONAL\nN\n28.361028\n7.562245\n68244.272206\n113892.066168\n6.190763\n4.709577\n10.280876\n2.981917\n\n\nY\n27.933244\n6.696901\n67221.606142\n57537.660727\n5.958611\n4.295520\n14.536935\n1.737584\n\n\nVENTURE\nN\n27.589281\n6.216285\n65544.232157\n46928.520701\n5.745882\n3.957178\n10.189561\n2.935957\n\n\nY\n27.585551\n5.808216\n68787.400507\n82746.627032\n5.735108\n4.021774\n14.544407\n1.740218\n\n\n\n\n\n\n\nIn this table, part of the data is summarized by finding the mean and the standard deviation of a person’s age, their income, their credit history length, and their given loan interest rate based on their loan intent and whether or not they defaulted previously on a loan. This table is helpful as we can see what factors play into having a higher interest rate, and we can see how age, income, or their credit history length varies based on defaulting on a loan and their loan intent. The standard deviation is important to see how much of the data falls into or out of the calculated mean.\n\n\nPart C: Building a Model:\nConstruct a score function and threshold for predicting whether a prospective borrower is likely to default on a given loan. You may use all the features in the data except loan_grade and the target variable loan_status.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(df_train[\"loan_status\"]) #fit encoder on 'loan_status'\n\ndef prepare_data(df):\n  #removing columns that are not needed\n  df = df.drop([\"loan_grade\"], axis = 1)\n  #removing N/A labels\n  df = df.dropna()\n  #print(df)\n  #turns the labels in 'loan_status' to a number\n  y = le.transform(df[\"loan_status\"])\n  #print(y)\n  #removing 'loan_status' col bc now held by y\n  df = df.drop([\"loan_status\"], axis = 1)\n  #converted into “one-hot encoded” 0-1 columns\n  df = pd.get_dummies(df)\n  return df, y\n\n\nX_train, y_train = prepare_data(df_train)\n\n\n\ny_train\n\narray([0, 0, 1, ..., 0, 0, 1])\n\n\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score #use this isntead of for-loop\nfrom sklearn.linear_model import LogisticRegression\nimport random\n\nquant_cols = ['person_income', 'loan_amnt', 'loan_int_rate']\n\nscore_counter = 0\n\nLR = LogisticRegression()\n\n#using cross validation on LR to avoid overfitting\ncv_scores_LR = cross_val_score(LR, X_train[quant_cols], y_train, cv = 5) #training on remaining 80% of data\nif cv_scores_LR.mean() &gt; score_counter:\n      #updating the best score and columns of that score\n      score_counter = cv_scores_LR.mean()\n\nprint('Best Score: ', score_counter)\n\nBest Score:  0.8117172718507574\n\n\n\nX_train\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_percent_income\ncb_person_cred_hist_length\nperson_home_ownership_MORTGAGE\nperson_home_ownership_OTHER\nperson_home_ownership_OWN\n...\nloan_intent_HOMEIMPROVEMENT\nloan_intent_MEDICAL\nloan_intent_PERSONAL\nloan_intent_VENTURE\ncb_person_default_on_file_N\ncb_person_default_on_file_Y\npaid_gain\ndefault_loss\nScores\ndecision\n\n\n\n\n1\n27\n98000\n3.0\n11750\n13.47\n0.12\n6\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n4613.567568\n-6997.533847\n-2.724145\nFalse\n\n\n2\n22\n36996\n5.0\n10000\n7.51\n0.27\n4\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n2044.334031\n-6426.108799\n-0.435472\nFalse\n\n\n3\n24\n26000\n2.0\n1325\n12.87\n0.05\n4\nFalse\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\n493.650464\n-795.445199\n-0.913722\nFalse\n\n\n4\n29\n53004\n2.0\n15000\n9.63\n0.28\n10\nTrue\nFalse\nFalse\n...\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n4028.690420\n-9390.333437\n-0.552180\nFalse\n\n\n6\n21\n21700\n2.0\n5500\n14.91\n0.25\n2\nFalse\nFalse\nFalse\n...\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n2430.522429\n-3211.752128\n-0.294372\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n26059\n36\n150000\n8.0\n3000\n7.29\n0.02\n17\nTrue\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n593.840622\n-1932.967484\n-5.766362\nFalse\n\n\n26060\n23\n48000\n1.0\n4325\n5.42\n0.09\n4\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\n623.093432\n-2849.295748\n-1.486665\nFalse\n\n\n26061\n22\n60000\n0.0\n15000\n11.71\n0.25\n4\nFalse\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\n5017.300210\n-9143.682505\n-0.836032\nFalse\n\n\n26062\n30\n144000\n12.0\n35000\n12.68\n0.24\n8\nTrue\nFalse\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\n12819.204794\n-21064.871625\n-2.113038\nFalse\n\n\n26063\n25\n60000\n5.0\n21450\n7.29\n0.36\n4\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n4245.960448\n-13820.717511\n-0.148728\nFalse\n\n\n\n\n22907 rows × 23 columns\n\n\n\n\ny_train\n\narray([0, 0, 1, ..., 0, 0, 1])\n\n\n\nLR.fit(X_train[quant_cols], y_train)\nw = LR.coef_\nLR.score(X_train[quant_cols], y_train)\n\n\n0.8080062862880342\n\n\n\nw\n\narray([[-4.05735976e-05,  1.06558819e-04,  9.49045880e-08]])\n\n\n\n#finding the scores\nx = X_train[quant_cols]\nx\n\n\n\n\n\n\n\n\nperson_income\nloan_amnt\nloan_int_rate\n\n\n\n\n1\n98000\n11750\n13.47\n\n\n2\n36996\n10000\n7.51\n\n\n3\n26000\n1325\n12.87\n\n\n4\n53004\n15000\n9.63\n\n\n6\n21700\n5500\n14.91\n\n\n...\n...\n...\n...\n\n\n26059\n150000\n3000\n7.29\n\n\n26060\n48000\n4325\n5.42\n\n\n26061\n60000\n15000\n11.71\n\n\n26062\n144000\n35000\n12.68\n\n\n26063\n60000\n21450\n7.29\n\n\n\n\n22907 rows × 3 columns\n\n\n\n\nscores = x@w.T\nscores\n\n\n\n\n\n\n\n\n0\n\n\n\n\n1\n-2.724145\n\n\n2\n-0.435472\n\n\n3\n-0.913722\n\n\n4\n-0.552180\n\n\n6\n-0.294372\n\n\n...\n...\n\n\n26059\n-5.766362\n\n\n26060\n-1.486665\n\n\n26061\n-0.836032\n\n\n26062\n-2.113038\n\n\n26063\n-0.148728\n\n\n\n\n22907 rows × 1 columns\n\n\n\n\n\nPart D: Finding a Threshold\nFind a threshold that maximizes the bank’s profit.\n\nimport numpy as np\n\n#calculate paid gain and loss here and add these array values in the columns of the table\n#vectorization\nint_rate_decimal = np.divide(X_train['loan_int_rate'], 100)\nX_train['paid_gain'] = X_train['loan_amnt'] * (1 + 0.25 * int_rate_decimal)**10 - X_train['loan_amnt']\nX_train['default_loss'] = X_train['loan_amnt'] * (1 + 0.25 * int_rate_decimal)** - 1.7 * X_train['loan_amnt']\nX_train['Scores'] = scores\n\n\nX_train['Scores']\n\n1       -2.724145\n2       -0.435472\n3       -0.913722\n4       -0.552180\n6       -0.294372\n           ...   \n26059   -5.766362\n26060   -1.486665\n26061   -0.836032\n26062   -2.113038\n26063   -0.148728\nName: Scores, Length: 22907, dtype: float64\n\n\n\nall_total_profit = []\nbest_profit = 0\ntotal_t_profit = 0\n\nfor threshold in np.linspace(scores.min(), scores.max(), 100): #np.linspace(scores.min(), scores.max(), 100)\n    #new col in for loop that makes the decision \"decision col\" checks if score is larger than threshold\n    X_train['decision'] = X_train['Scores'] &gt;= threshold[0] #returns bool threshold[0] with np.linspace\n\n\n    t_profit = (1 - X_train['decision']) * (X_train['paid_gain'] * (1 - y_train) + X_train['default_loss'] * (y_train))\n\n    # t_profit = (1-threshold) * (X_train['paid_gain'] + threshold * X_train['default_loss'])\n    \n    # print(f\"{X_train['paid_gain']= }\")\n    # print(f\"{X_train['default_loss']= }\")\n\n    #calculating mean profit\n    all_total_profit.append(t_profit.mean())\n\n    #return highest threshold based on highest gain\n    if t_profit.mean() &gt; best_profit:\n        best_profit = t_profit.mean()\n        best_t = threshold[0] #threshold[0] with np.linspace\n        profit_per_borrower = t_profit.mean()\n\n\n        #find probability and loop through thresholds\nprint(total_t_profit)\nprint('highest profit: ', best_profit)\nprint('best threshold that optimizes profit for the bank: ', best_t)\nprint('bank’s expected profit per borrower: ', profit_per_borrower)\n\n0\nhighest profit:  1158.6189787929175\nbest threshold that optimizes profit for the bank:  -0.9466451695144542\nbank’s expected profit per borrower:  1158.6189787929175\n\n\n\n#threshold vs profit (all_total_profit)\nplt.plot(np.linspace(scores.min(), scores.max(), 100), all_total_profit)\nplt.gca().set(xlim=(-7,None))\nplt.grid(True)\nplt.axvline(x = best_t, color = 'red', linestyle = '--', lw = 1)\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Total Profit\")\nplt.title(\"Threshold vs. Total Profit\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPart E: Evaluate Your Model from the Bank’s Perspective\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\nX_test, y_test = prepare_data(df_test)\nLR.score(X_test[quant_cols], y_test)\nx = X_test[quant_cols]\ntest_scores = x@w.T\n\nFinding threshold of testing set:\n\nimport numpy as np\n\n#calculate paid gain and loss here and add these array values in the columns of the table\n#vectorization\nint_rate_decimal = np.divide(X_test['loan_int_rate'], 100)\nX_test['paid_gain'] = X_test['loan_amnt'] * (1 + 0.25 * int_rate_decimal)**10 - X_test['loan_amnt']\nX_test['default_loss'] = X_test['loan_amnt'] * (1 + 0.25 * int_rate_decimal)**3 - 1.7 * X_test['loan_amnt']\nX_test['Scores'] = test_scores\n\n\nall_total_profit = []\nbest_profit = 0\ntotal_t_profit = 0\n\nfor threshold in np.linspace(test_scores.min(), test_scores.max(), 100):\n    #new col in for loop that makes the decision \"decision col\" checks if score is larger than threshold\n    X_test['decision'] = X_test['Scores'] &gt; threshold[0] #returns bool threshold[0] with np.linspace\n\n    t_profit = (1 - X_test['decision']) * (X_test['paid_gain'] * (1 - y_test) + X_test['default_loss'] * (y_test))    \n\n    #calculating mean profit\n    all_total_profit.append(t_profit.mean())\n\n    #return highest threshold based on highest gain\n    if t_profit.mean() &gt; best_profit:\n        best_profit = t_profit.mean()\n        best_t = threshold[0] #threshold[0] with np.linspace\n        profit_per_borrower = t_profit.mean()\n\n\n        #find probability and loop through thresholds\nprint(total_t_profit)\nprint('highest profit: ', best_profit)\nprint('best threshold that optimizes profit for the bank: ', best_t)\nprint('bank’s expected profit per borrower: ', profit_per_borrower)\n\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0        True\n1        True\n2       False\n3        True\n4       False\n        ...  \n6511     True\n6513     True\n6514     True\n6515    False\n6516     True\nName: decision, Length: 5731, dtype: bool\n0       False\n1        True\n2       False\n3       False\n4       False\n        ...  \n6511    False\n6513     True\n6514     True\n6515    False\n6516    False\nName: decision, Length: 5731, dtype: bool\n0       False\n1       False\n2       False\n3       False\n4       False\n        ...  \n6511    False\n6513    False\n6514    False\n6515    False\n6516    False\nName: decision, Length: 5731, dtype: bool\n0       False\n1       False\n2       False\n3       False\n4       False\n        ...  \n6511    False\n6513    False\n6514    False\n6515    False\n6516    False\nName: decision, Length: 5731, dtype: bool\n0       False\n1       False\n2       False\n3       False\n4       False\n        ...  \n6511    False\n6513    False\n6514    False\n6515    False\n6516    False\nName: decision, Length: 5731, dtype: bool\n0\nhighest profit:  1168.3899694144973\nbest threshold that optimizes profit for the bank:  -0.17519863260740465\nbank’s expected profit per borrower:  1168.3899694144973\n\n\n\n#threshold vs profit (all_total_profit)\nplt.plot(np.linspace(test_scores.min(), test_scores.max(), 100), all_total_profit)\nplt.gca().set(xlim=(-7,None))\nplt.grid(True)\nplt.axvline(x = best_t, color = 'red', linestyle = '--', lw = 1)\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Total Profit\")\nplt.title(\"Threshold vs. Total Profit\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPart F: Evaluate Your Model From the Borrower’s Perspective\nIs it more difficult for people in certain age groups to access credit under your proposed system?\n\nimport seaborn as sns\n\nX_test['age_cat'] = pd.cut(X_test['person_age'], range(0,70, 10))\n\napproval_rate_percent = X_test.groupby('age_cat')['decision'].mean() * 100\nplt.figure(figsize=(11,5))\nsns.barplot(X_test, x = approval_rate_percent.index, y = approval_rate_percent.values)\nplt.xlabel('Age Group')\nplt.ylabel('Approval Rate Percent')\nplt.grid(True)\nplt.show()\n#(X_test['person_age'], y_test)\n\n/var/folders/1j/mlsnh9t96n70j2n5mmm9h9780000gn/T/ipykernel_11168/2421308665.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  approval_rate_percent = X_test.groupby('age_cat')['decision'].mean() * 100\n/Users/ddelgado/anaconda3/envs/ml-0451/lib/python3.9/site-packages/seaborn/categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grouped_vals = vals.groupby(grouper)\n\n\n\n\n\n\n\n\n\nSince, all of my decision column has the boolean true, they are all 0.0 floats. Therefore, no one age group has more difficulty in getting a loan in the proposed system.\nIs it more difficult for people to get loans in order to pay for medical expenses? How does this compare with the actual rate of default in that group? What about people seeking loans for business ventures or education?\n\nloan_intent_rate = X_test.groupby(['loan_intent_EDUCATION', 'loan_intent_MEDICAL', 'loan_intent_VENTURE']).aggregate({'decision' : 'mean', 'cb_person_default_on_file_N' : 'mean', 'cb_person_default_on_file_Y' : 'mean'})\nprint(loan_intent_rate)\n\n                                                               decision  \\\nloan_intent_EDUCATION loan_intent_MEDICAL loan_intent_VENTURE             \nFalse                 False               False                     0.0   \n                                          True                      0.0   \n                      True                False                     0.0   \nTrue                  False               False                     0.0   \n\n                                                               cb_person_default_on_file_N  \\\nloan_intent_EDUCATION loan_intent_MEDICAL loan_intent_VENTURE                                \nFalse                 False               False                                   0.809770   \n                                          True                                    0.816390   \n                      True                False                                   0.835974   \nTrue                  False               False                                   0.816327   \n\n                                                               cb_person_default_on_file_Y  \nloan_intent_EDUCATION loan_intent_MEDICAL loan_intent_VENTURE                               \nFalse                 False               False                                   0.190230  \n                                          True                                    0.183610  \n                      True                False                                   0.164026  \nTrue                  False               False                                   0.183673  \n\n\nSince the decision column is all zeros, the comparison here is that the approval rate, or the decision, is less than the actual default rate for each education, medical and venture groups.\nHow does a person’s income level impact the ease with which they can access credit under your decision system?\n\n#income_groups = pd.cut(X_test['person_income'], range(4800,1782000, 10))\napproval_rate_income = X_test.groupby(pd.cut(X_test['person_income'], 25))['decision'].mean()\nprint(approval_rate_income)\n\nperson_income\n(3022.8, 75888.0]         0.0\n(75888.0, 146976.0]       0.0\n(146976.0, 218064.0]      0.0\n(218064.0, 289152.0]      0.0\n(289152.0, 360240.0]      0.0\n(360240.0, 431328.0]      0.0\n(431328.0, 502416.0]      0.0\n(502416.0, 573504.0]      0.0\n(573504.0, 644592.0]      NaN\n(644592.0, 715680.0]      0.0\n(715680.0, 786768.0]      0.0\n(786768.0, 857856.0]      0.0\n(857856.0, 928944.0]      NaN\n(928944.0, 1000032.0]     NaN\n(1000032.0, 1071120.0]    NaN\n(1071120.0, 1142208.0]    NaN\n(1142208.0, 1213296.0]    0.0\n(1213296.0, 1284384.0]    NaN\n(1284384.0, 1355472.0]    NaN\n(1355472.0, 1426560.0]    NaN\n(1426560.0, 1497648.0]    NaN\n(1497648.0, 1568736.0]    NaN\n(1568736.0, 1639824.0]    NaN\n(1639824.0, 1710912.0]    NaN\n(1710912.0, 1782000.0]    0.0\nName: decision, dtype: float64\n\n\n/var/folders/1j/mlsnh9t96n70j2n5mmm9h9780000gn/T/ipykernel_11168/4155170202.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  approval_rate_income = X_test.groupby(pd.cut(X_test['person_income'], 25))['decision'].mean()\n\n\nA person’s income level does not impact the ease in which a person can access credit under the decision system as the decision says the mean is 0.0\n\n\nConclusion\n\nIn this blog post, what I learned was that something in my decisions might be calculated wrong or I might be missing something as all of my decisions say they are True for defaulting. If everything is correct, I learned that everyone is set to default on the loan, so there really is no difference between groups of people.\n\nConsidering that people seeking loans for medical expense have high rates of default, is it fair that it is more difficult for them to obtain access to credit?\n\nAssuming my data showed that people seeking loans for medical expenses have higher rates of defaulting, I believe that it is fair for them to have more difficulty in obtaining access to credit. In this sense, it is fair because the bank has to think in terms of itself and if the people who seek medical expenses cannot pay the loan back, it is fair for the bank to deny their loan as it is money the bank will be losing. If something is fair, it does not mean it is morally correct. In this case, fairness is based on the system proposed and if a borrower falls into the given threshold for loan acceptance based on different factors. However, I would say it is not fair according to morals to deny the loan for their medical expenses as they need the money to get treatment/medication in order to remain alive."
  },
  {
    "objectID": "posts/classifying-penguins/index.html",
    "href": "posts/classifying-penguins/index.html",
    "title": "Classifying Palmer Penguins Post",
    "section": "",
    "text": "Abstract\nIn this blog post, we will predict the species of a penguin based on its measurements and aim to achieve 100% testing accuracy with my select choice in model. First, I will do data preparation where I will clean the dataset by removing unnecessary columns, labels, and, of course, the species column. Then, by looking at this new dataset, I will make graphs using seaborn based on the information given to see if I can spot any patterns that can help identify a penguin’s species. In my graphs, I look at flipper length in relation to body mass, culmen depth and length in relation to the penguin’s sex, and the correlation between the penguin’s culmen depth and lengh with the flipper length. Then I made a summary table where I found the mean and the standard deviation of the culmen length and depth, the flipper length, and the body mass of the penguins on each island based on their sex to see the areas where penguins had a closer correlation to. Then, using LogisticRegression and DecisionTreeClassifier, we will find the best mean score and its corresponding column out of every set of 3 features- two quantitative and one qualitative features. We will also test this on our testing data. Afterwards, we will plot a graph panel of decision regions for the classifiers where we will see the DTC predictions for the penguin species based on the best column we got from finding the best mean with the DTC. Finally, we will see the errors our prediction model made in comparison to the actual data by looking at a color-coded confusion matrix.\nAs the results will show, the DecisionTreeClassifier model worked better than the LogisticRegression model yet, in the test data, LogisticRegression returned a better output with 100% while DTC returned about 98.5% accuracy. This can be due to the depth limit placed on the DTC in comparison to no limit set on the LR model. Additionally, the confusion matrix showed the DTC made a very small margin error with one penguin being mislabeled. The prediction DTC classified this penguin as Chinstrap when it was actually a Gentoo penguin. Overall, the prediction model was accurate.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\nIn the code above, I am first getting the data.\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nDown below, I am beginning to clean the data by getting rid of unnecessary columns and data, and creating my training sets.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"]) #fit encoder on 'Species'\n\ndef prepare_data(df):\n  #removing columns that are not needed\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  #removing when sex = .\n  df = df[df[\"Sex\"] != \".\"]\n  #removing N/A labels\n  df = df.dropna()\n  #turns the labels in 'Species' to a number\n  y = le.transform(df[\"Species\"])\n  #print(y)\n  #removing 'Species' col bc now held by y\n  df = df.drop([\"Species\"], axis = 1)\n  #converted into “one-hot encoded” 0-1 columns\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\nPart 1: Exploring the data:\nHere, I constructed three interesting displayed figures and one summary table that will help draw conclusions about what features I can use for the model (DTC model).\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nsns.scatterplot(data = X_train, x = 'Flipper Length (mm)', y = 'Body Mass (g)', hue = 'Flipper Length (mm)')\n\nplt.title('Scatterplot of Flipper Length in Relation to Body Mass')\nplt.show()\n\n\n\n\n\n\n\n\nIn this graph, we see the correlation between the flipper length and the body mass of penguins as the data is grouped by the flipper length. In the graph, the correlation between both seems to be positive as the longer the flipper length, the higher the body mass. This can help define a species as maybe some penguin species are smaller, which would allow us to know their body mass is lighter, thus their flipper length is smaller as well. This can be used in my model as it can use the weigths/sizes of penguins to possibibly help distinguish the species, along with the help of looking at other features to understand the outlier points in this set.\n\nsns.scatterplot(data = X_train, x = 'Culmen Length (mm)', y = 'Culmen Depth (mm)', hue = 'Sex_FEMALE')\nplt.title('Culmen Length and Depth Based on Gender')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIn this graph, we can see the culmen depth and length in relation to the penguin’s sex. The female culmens tend to be on the lower half of the graph. There also seems to be three different clusters: one on the middle left averaging on the point (40,18), another one starting at (45,16) and expanding upwards right to (50,20), and the final one being on the mid-lower part of the graph at about (45,14) to (50,16). In these three clusters, the female’s culmen dimensions are smaller than the men’s. This can tell us that the species of penguins all have different culmen lengths and depths, and they vary by sex. Thus, the penguin species can be distinguishable by their culmen sizes. This information can be useful in modeling as we can see if the culmen length and culmen depth compared to the gender play a role in distinguishing the species.\n\nsns.scatterplot(data = X_train, x = 'Culmen Length (mm)', y = 'Culmen Depth (mm)', hue = 'Flipper Length (mm)')\nplt.title('Correlation Between Culmen Length and Depth, and Flipper Length')\nplt.show()\n\n\n\n\n\n\n\n\nIn this graph, we can see the correlation between the flipper length and the culmen depth/length. We can see how the deeper the culmen depth goes, the smaller the flipper and culmen lengths are. If the penguin has a medium to high range in culmen length with a lower depth, then the flipper lenght is longer. However, if both the culmen length and depth are high, then the flipper length is in about the middle size. This information can be used in modeling as we can see if the species of the penguins are identifiable based on the different correlations between the culmen dimensions and the flipper length.\n\nmeanTable = X_train.groupby(['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Sex_MALE', 'Sex_FEMALE']).aggregate(\n    {'Culmen Length (mm)' : ['mean', 'std'], 'Culmen Depth (mm)' : ['mean', 'std'], 'Flipper Length (mm)' : ['mean', 'std'], 'Body Mass (g)' : ['mean', 'std']})\nmeanTable\n\n\n\n\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\n\n\n\n\n\n\n\nmean\nstd\nmean\nstd\nmean\nstd\nmean\nstd\n\n\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nSex_MALE\nSex_FEMALE\n\n\n\n\n\n\n\n\n\n\n\n\nFalse\nFalse\nTrue\nFalse\nTrue\n37.537500\n2.111200\n17.475000\n0.863713\n188.000000\n4.661902\n3309.375000\n251.143219\n\n\nTrue\nFalse\n40.961111\n3.273268\n19.300000\n1.058856\n196.000000\n5.455704\n4100.000000\n370.611577\n\n\nTrue\nFalse\nFalse\nTrue\n43.041176\n5.368843\n17.629412\n0.767670\n190.784314\n5.923896\n3471.078431\n267.225212\n\n\nTrue\nFalse\n46.176087\n5.930081\n19.058696\n0.971271\n196.782609\n7.828475\n4027.173913\n328.541647\n\n\nTrue\nFalse\nFalse\nFalse\nTrue\n43.423077\n4.061703\n15.093846\n1.727795\n206.507692\n11.936189\n4356.538462\n655.569244\n\n\nTrue\nFalse\n46.595000\n4.511583\n16.696667\n1.738007\n212.366667\n15.248192\n5076.250000\n721.116498\n\n\n\n\n\n\n\nIn this table, we can see the mean and standard deviation values for the culmen length and depth, the flipper length, and the body mass of the penguins on each island based on their sex. This table can be helpful as we can see the how the dimensions differ based on the island the penguins are on and their sex. These can be a telling factor on the kind of species they are by seeing the grouping they fall into and if the standard deviation is too big, then we know there are more outliers that are not close to the mean. Thus, this shows that there might not be a correlatioin with that said data.\nPart 2: Choosing Features\nThe code below is a modified version of the code Phil provided in the notes of this assignment. What is going on in this block of code is that I first chose the qualitative and quantitative columns that I wanted to compare and look into. Then, I created unique pairs of the quantitative columns and added a qualitative column to the pairings, so I formed groups of three, and ran the logistic regression model on the columns. When thinking of the approach in choosing the final three features, I used cross validation on the training data to account for overfitting. If the CR mean score was greater than the score counter, then I updated the score counter to be the value of the CR mean. I then got the column names that were associated with the best score and returned them.\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score #use this isntead of for-loop\nfrom sklearn.linear_model import LogisticRegression\nimport warnings\n\nwarnings.filterwarnings('ignore')\n#warnings.filterwarnings('ignore', category = FutureWarning)\n\n\nscore_counter = 0\n# these are not actually all the columns: you'll\n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\", \"Egg Stage\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 3):\n    cols = list(pair) + qual_cols\n    print(cols)\n    # training LR model and scoring it\n    LR = LogisticRegression()\n    #using cross validation on LR to avoid overfitting\n    cv_scores_LR = cross_val_score(LR, X_train[cols], y_train, cv = 5) #training on remaining 80% of data\n\n    if cv_scores_LR.mean() &gt; score_counter:\n      #updating the best score and columns of that score\n      score_counter = cv_scores_LR.mean()\n      col_best = cols\n\nprint('Best Score: ', score_counter)\nprint('Best Three Columns: ', col_best)\n\n\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Stage_Adult, 1 Egg Stage']\nBest Score:  0.9922322775263952\nBest Three Columns:  ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Sex_FEMALE', 'Sex_MALE']\n\n\nHere, I fit the data of the final columns chosen from the code above using logistic regression to calculate the score.\n\n# LR with the selected better columns from the code above\ncols = col_best\n\nLR = LogisticRegression()\nLR.fit(X_train[cols], y_train)\nLR.score(X_train[cols], y_train)\n\n0.9921875\n\n\nNow to test LogisticRegression:\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nLR.score(X_test[cols], y_test)\n\n1.0\n\n\nOn the test set, logistic regression returned a 100% accuracy!\nUsing DecisionTreeClassifier instead of Logistic Regression, here is another model choice:\n\nSimilar to the code blocks above where I worked with the LR model, the code below uses the modified version of the code Phil provided in the notes of this assignment. Additionally, I took unique pairs of quantitative columns and a random qualitative column (three features total) that I chose to make the comparisons. On these groupings, I ran the decision tree classifier model where I set the depth to be a range between 1 and 19 to test it. I used cross validation on the model and testing set once again to avoid overfitting. To figure out the best grouping of features to look at, I saw if the mean of the CR score was greater than the score counter, and it it was, I updated the score counter to be the value of the CR mean. I then got the column names that were associated with the best score and returned them.\n\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score #use this isntead of for-loop\nfrom sklearn.tree import DecisionTreeClassifier\n\nscore_counter = 0\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\", \"Egg Stage\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nfor qual in all_qual_cols:\n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols =  list(pair) + qual_cols\n    print(cols)\n\n    for i in range(1,20):\n      #setting the max depth to be between 1-19 and iterating through each one\n      DTC = DecisionTreeClassifier(max_depth=i)\n      #using cross validation on DTC to avoid overfitting\n      cv_scores_DTC = cross_val_score(DTC, X_train[cols], y_train, cv = 5)\n      #updating the best score and columns of that score\n      if cv_scores_DTC.mean() &gt; score_counter:\n        score_counter = cv_scores_DTC.mean()\n        col_best = cols\n    \nprint('Best Score: ', score_counter)\nprint('Best Three Columns: ', col_best)\nprint('At depth: ', i)\n\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Length (mm)', 'Flipper Length (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Length (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Depth (mm)', 'Flipper Length (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Depth (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Flipper Length (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n\n\nKeyboardInterrupt: \n\n\nHere, I fit the training data with the final features using the decision tree classifier model.\n\n#Feeding the best cols\ncols = col_best\n\nDTC = DecisionTreeClassifier(max_depth=i)\nDTC.fit(X_train[cols], y_train)\nDTC.score(X_train[cols], y_train)\n\n1.0\n\n\nFor the training set, it returns a 100% accuracy rate!\nNow to test the data we do:\n\n#download the test data set \ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n#prepping data\nX_test, y_test = prepare_data(test)\nDTC.score(X_test[cols], y_test)\n\n0.9852941176470589\n\n\n\nThe testing data did not reach 100% with the decision tree classifier model.\n\nNow we are going to plot a panel of decision regions for the classifiers:\n\nThis code was provided by Phil in the assignment notes as well.\n\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    #sets first two columns, which are quantitative, of X_train[cols]\n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    #says remaining columns are one-hot qualitative columns\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\nplot_regions(DTC, X_train[cols], y_train)\n\nError in callback &lt;function flush_figures at 0x7f974a554280&gt; (for post_execute):\n\n\nKeyboardInterrupt: \n\n\nFinally, we will show a confusion matrix on the DTC model, which will be evaluated on the test set.\n\nfrom sklearn.metrics import confusion_matrix\n\nactual = y_test\npredict = DTC.predict(X_test[cols])\n\nconf_matrix = confusion_matrix(actual, predict)\n\nprint(conf_matrix)\n\n[[31  0  0]\n [ 0 10  1]\n [ 0  0 26]]\n\n\nIn this confusion matrix, we see the error is low, but it is seen with the Gentoo and Chinstrap penguins. The data predicted one penguin to be Chinstrap when it was actually a Gentoo penguin. With this information, I do not believe there was an error greater than others as that seems to be the only error.\nDiscussion\nIn this blog post, I found that using a DecisionTreeClassifier model worked better than the LogisticRegression model as seen by the best score prints, yet, in the test data, LogisticRegression returned a better output with 100% while DTC returned about 98.5% accuracy. I believe this is because LR does not have a limit on the iterations while DTC has a set depth, which can limit it from getting to 100% accuracy. Furthermore, the graphs explored in the beginning did help classify the data to guess the correct species, specifically the penguin’s culmen dimensions correlating to its sex as that ended up being the best column outcome for the DTC! The three clusters I saw in that graph also proved to help identify the species as seen in the plotted graph panel of decision regions for the species classifiers. Lastly, as we can see from the confusion matrix, we can conclude the DTC prediction model is accurate.\nThrough the coding process, I learned and felt more comfortable in working with seaborn and the different graphs available to make since, in part one, I originally created about seven different graphs from pairplots, to boxplots, to bar graphs before deciding on my final three. Additionally, I learned what the DecisionTreeClassifies does and the different methods it has to help with prediction and other needs. One more thing I learned was what a confusion matrix was. I had to do research on it as I had no idea what the purpose of it was nor how to use the data I had to create it. However, with the help of Geeks4Geeks and the scikitlearn website on confusion matrices, I understood the purpose and what data to look at."
  },
  {
    "objectID": "posts/logistic_regression_optimization/index.html",
    "href": "posts/logistic_regression_optimization/index.html",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "logistic.py file"
  },
  {
    "objectID": "posts/logistic_regression_optimization/index.html#experiments",
    "href": "posts/logistic_regression_optimization/index.html#experiments",
    "title": "Implementing Logistic Regression",
    "section": "Experiments",
    "text": "Experiments\n\nVanilla Gradient Descent\nIn this first experiment, I tested to see that when \\(p_dim = 2\\), \\(\\alpha\\) is sufficiently small, and \\(\\beta = 0\\), then the gradient descent for logistic regression converges to a weight vector \\(\\mathbf{w}\\) that looks visually correct. I showed this by plotting the decision boundary with the data and graphing the plot the loss over iterations.\nThis code was provided by Phil in his assignment notes! This code creates classification data with noise.\n\nimport torch\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(noise = 0.5)\n\nThe code below was taken from Phil’s class notes on perceptron. It was modified to adjust the target to be the y values of this data.\nThis code creates the graph to show the classification_data through a graph. There are 300 points graphed where the x-axis (x_1) is a number you can measure and the y-axis (x_2) is another feature vector.\n\nimport matplotlib.pyplot as plt\n\ndef plot_classification_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = classification_data()\nplot_classification_data(X, y, ax)\nplt.grid(True)\n\n\n\n\n\n\n\n\nNow, to show the decision boundary, we draw the line by editing the code from the perceptron notes:\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\nfig, ax = plt.subplots(1, 1)\nplot_classification_data(X, y, ax)\n\nw_1 = torch.Tensor([1,  1, -1]) \n\ndraw_line(w_1, x_min = -1, x_max = 1.5, ax = ax, color = \"black\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nAs we can see, the line exactly separates the two classes.\nNext, I am plotting the loss over iterations, 5000 in my case, to show the loss decreasing monotonically. Part of the set-up code was provided in the assignment, but the code to keep track of the loss and the graph was created by me.\n\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\n\ntotal_loss = []\nfor _ in range(5000):\n    # keeps track of the loss over time\n    loss = LR.loss(X, y)\n    total_loss.append(loss)\n    opt.step(X, y, alpha = 0.1, beta = 0.0)\n\nplt.plot(total_loss)\nplt.grid(True)\nplt.title(\"Loss Over Iterations\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\n#plt.text(0.2, 0.2, f'Total Loss: {loss:.3f}')\nplt.show()\n\n\n\n\n\n\n\n\nThis graph shows the loss decreasing monotonically. It shows the loss over iterations when alpha is small and beta is 0.0, and as seen, it begins to flatten out consistently at bout 2,800 iterations.\n\n\nBenefits of Momentum\nIn this experiment, I used the same data that shows classification_data through a graph, but with momentum as the beta was increased to be 0.9.\n\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\n\ntotal_loss_m = []\nfor _ in range(5000):\n    # keeps track of the momentum loss over time\n    loss = LR.loss(X, y)\n    total_loss_m.append(loss)\n    opt.step(X, y, alpha = 0.1, beta = 0.0)\n\nfig, ax = plt.subplots(1, 1)\nplot_classification_data(X, y, ax)\nplt.grid(True)\n\n\n\n\n\n\n\n\nTo show the decision boundary, we draw the line by editing the code from the same perceptron notes where the line exactly separates the two classes:\n\nfig, ax = plt.subplots(1, 1)\nplot_classification_data(X, y, ax)\n\nw_1 = torch.Tensor([1,  1, -1]) \n\ndraw_line(w_1, x_min = -1, x_max = 1.5, ax = ax, color = \"black\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nNext, I am plotting the loss over iterations, 300 in this case as seen in the first code block of this experiment, to show the loss decreasing monotonically. Part of the set-up code was provided in the assignment, but the code to keep track of the loss and the graph was created by me.\n\nplt.plot(total_loss_m)\nplt.grid(True)\nplt.title(\"Momentum Loss Over Iterations\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\n#plt.text(0.2, 0.2, f'Total Loss: {loss:.4f}')\nplt.show()\n\n\n\n\n\n\n\n\nAs seen, the loss over iterations reaches a consistent flattening at around 50 iterations. Much quicker than Vanilla Gradient Descent!\nNext, I graphed the loss over iterations for each method, vanilla optimizer at a range of 6000 iterations while the momentum optimizer at 4000 iterations, to compare the two and see the speedup due to momentum:\n\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\n\n#vanilla\ntotal_loss = []\nfor _ in range(6000):\n    # keeping track of the loss over time\n    loss = LR.loss(X, y)\n    total_loss.append(loss)\n    opt.step(X, y, alpha = 0.1, beta = 0.0)\n\n\n#momentum\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\ntotal_m_loss = []\nfor _ in range(4000):\n    # keeping track of the loss over time\n    loss_m = LR.loss(X, y)\n    total_m_loss.append(loss_m)\n    \n    opt.step(X, y, alpha = 0.2, beta = 0.9)\n\n\nplt.plot(total_loss, label='Without Momentum', color = 'purple')\nplt.plot(total_m_loss, label='With Momentum', color = 'green')\nplt.grid(True)\nplt.title(\"Loss Over Iterations: No Momentum vs. Momentum\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\n\n\n\n\n\n\n\nAs seen, with momentum (the green line), a faster convergence is achieved. At 4000 iterations, it seems like the line with momentum was able to achieve a lower loss than the line without momentum (the purple line) as the green line is closer to the 0.0 loss value compared to the purple line that is above the green line. If the iterations were increased to 8000, we would see the purple line grow closer to the 0.0 loss like the green line is.\n\n\nOverfitting\nIn this experiment, I generate data where p_dim &gt; n_points as seen with n_points = 50 and p_dims = 100. I do this twice, first on the dataset X_train, y_train and the second time on the dataset X_test, y_test. Then, I fit a logistic regression model to the data X_train, y_train where the goal was to obtain 100% accuracy on the training data, which is achieved as seen in the output.\n\nX_train, y_train = classification_data(n_points = 50, noise = 0.6, p_dims = 51)\n\n\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\n\nlosses = []\nchange = float('inf') #change in losses\nloss = LR.loss(X_train, y_train)\nlosses.append(loss)\n\nopt.step(X_train, y_train, alpha = 0.2, beta = 0.9)\nwhile change &gt; 10**(-6):\n    #change is how much better it is getting\n\n    #old loss is current loss\n    new_loss = LR.loss(X_train, y_train)\n    losses.append(new_loss)\n    \n    opt.step(X_train, y_train, alpha = 0.2, beta = 0.9)\n    change = abs(new_loss - loss)\n    loss = new_loss\n\n#predicting \npred_train = LR.predict(X_train)\npred_accuracy = torch.mean((pred_train == y_train).float())\nprint(\"Training predicting accuracy\", float(pred_accuracy))\n\nTraining predicting accuracy 1.0\n\n\nTo show the change in loss during training, I graphed the loss over iterations with the values of the loss function at that iteration plotted. In the graph, we can see a decreasing trend, indicating that the model is improving its performance and converging towards an optimal solution.\n\n# Plotting change in losses during training\nplt.plot(range(len(losses)), losses, marker='o', linestyle='-')\nplt.title('Loss Over Iterations during Training')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\nFinally, I used the training model and ran it on the testing data where I got a lower accuracy rating. This shows the negative effects of overfitting a model on the training data.\n\nX_test, y_test = classification_data(n_points = 50, noise = 0.6, p_dims = 51)\n\n#predicting\npred_test = LR.predict(X_test)\npred_accuracy = torch.mean((pred_test == y_test).float())\nprint(\"Testing prediction accuracy\", float(pred_accuracy))\n\nTesting prediction accuracy 0.9200000166893005"
  },
  {
    "objectID": "posts/implementing-perceptron/index.html",
    "href": "posts/implementing-perceptron/index.html",
    "title": "Implementing Perceptron",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "posts/implementing-perceptron/index.html#implementation-of-perceptron.grad",
    "href": "posts/implementing-perceptron/index.html#implementation-of-perceptron.grad",
    "title": "Implementing Perceptron",
    "section": "Implementation of perceptron.grad()",
    "text": "Implementation of perceptron.grad()\nFor my perceptron.grad() function, I wrote the following code:\n    def grad(self, X, y):\n\n            s = X @ self.w.T\n            \n            # this return does same as return torch.where((y * s) &lt; 0, y@X, 0.0)\n            \n            return ((y * X) * (s * y &lt; 0))\nHere, I begin by setting the score to be the product of X matrix-multiplied by the transpose of w as given in the instructions to compute \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle\\). Then, I return the gradient which is (y multiplied by X) and then multiplied by s times y if it is less than 0. This is the same as the equation: \\(\\mathbb{1}\\left[s_i y_{i} &lt; 0 \\right] y_{i} \\mathbf{x}_{i}\\). If s*y is greater than zero, then the boolean tensor would return False and it would be set to zero, thus making the entire thing return zero. Otherwise, it returns a gradient calculation.\n\nTesting the perceptron.py file with a Minimal Training Loop\nIn the training loop, we will repeat the procedure for a specified number of times (or until convergence).\nThis was taken from the perceptron lecture notes:\n\nimport torch\ntorch.manual_seed(12345)\n\n\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\nNow, we will plot the data to visualize if it is linearly separable.\n\nfrom matplotlib import pyplot as plt\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = perceptron_data()\nplot_perceptron_data(X, y, ax)\nplt.grid(True)\n\n\n\n\n\n\n\n\nAs we can see, the data points are linearly separable as the circle points are on the lower left while the square points are on the upper right of the graph.\nFinally, we will check if the code is working by running the “minimal training loop” code taken from the perceptron lecture notes and see if it will eventually achieve loss = 0 on linearly separable data:\n\n# instantiate a model and an optimizer\np = Perceptron()\nopt = PerceptronOptimizer(p)\n\nloss = 1.0\n\n# for keeping track of loss values\nloss_vec = []\n\nn = X.size()[0]\n\nwhile loss &gt; 0 : # dangerous -- only terminates if data is linearly separable\n    \n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y)\n    loss_vec.append(loss)\n    # pick a random data point\n    i = torch.randint(n, size = (1,))\n    \n    x_i = X[[i],:]\n    y_i = y[i]\n    # perform a perceptron update using the random data point\n    opt.step(x_i, y_i)\n\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nAs we can see with the graph, the data is linearly separable as the loss reaches 0, demonstrating a perfect training accuracy."
  },
  {
    "objectID": "posts/implementing-perceptron/index.html#part-b-experiments",
    "href": "posts/implementing-perceptron/index.html#part-b-experiments",
    "title": "Implementing Perceptron",
    "section": "Part B: Experiments",
    "text": "Part B: Experiments\n\nExperiment 1:\nUsing 2d data like the data in the example above, if the data is linearly separable then the perceptron algorithm converges to weight vector w describing a separating line (provided that the maximum number of iterations is large enough).\nTaken from my Logistic Regression blog post where I edited Phil’s code from the notes, this code creates classification data with noise and the second function creates the graph to show the classification_data through a graph. There are 300 points graphed where the x-axis (x_1) is a number you can measure and the y-axis (x_2) is another feature vector:\n\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + -torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = perceptron_data()\nplt.grid(True)\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\nHere, we see the data is linearly separable as the circle points are on the lower left while the square points are on the upper right of the graph.\nNow, we will show the separating line through the points:\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\nfig, ax = plt.subplots(1, 1)\nplot_perceptron_data(X, y, ax)\n\nw_1 = torch.Tensor([1,  1, -1]) \n\ndraw_line(w_1, x_min = -1, x_max = 1.5, ax = ax, color = \"black\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nThe line above effectively separates the points with the line being drawn right between the points.\nNext, we will see the evolution of the loss function during training. This was taken from Phil’s perceptron notes:\n\ntorch.manual_seed(123456)\n\n# initialize a perceptron\np = Perceptron()\nopt = PerceptronOptimizer(p)\np.loss(X, y)\n\n# set up the figure\nplt.rcParams[\"figure.figsize\"] = (7, 5)\nfig, axarr = plt.subplots(2, 3, sharex = True, sharey = True)\nmarkers = [\"o\", \",\"]\nmarker_map = {-1 : 0, 1 : 1}\n\n# initialize for main loop\ncurrent_ax = 0\nloss = 1\nloss_vec = []\nwhile loss &gt; 0:\n\n    ax = axarr.ravel()[current_ax]\n\n    # save the old value of w for plotting later\n    old_w = torch.clone(p.w)\n\n    # make an optimization step -- this is where the update actually happens\n    # now p.w is the new value\n    i = torch.randint(n, size = (1,))\n    \n    x_i = X[[i],:]\n    y_i = y[i]\n    # perform a perceptron update using the random data point\n    local_loss = opt.step(x_i, y_i)\n\n    if local_loss &gt; 0:\n        #ax.clear()\n        plot_perceptron_data(X, y, ax)\n        draw_line(old_w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n        loss = p.loss(X, y).item()\n        loss_vec.append(loss)\n        draw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n        ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\", marker = markers[marker_map[y[i].item()]])\n        ax.set_title(f\"loss = {loss:.3f}\")\n        ax.set(xlim = (-1, 2), ylim = (-1, 2))\n        current_ax += 1\n        #current_ax = min(5, current_ax + 1)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nAs seen by the graphs, the loss reaches zero, proving the data is linearly separable and demonstrating a perfect accuracy score.\n\n\nExperiment 2:\nIn this second experiment, we will explore when data is not linearly separable.\nFirst, we make points where the circles and squares are mixed within each other by increasing the noise:\n\ntorch.manual_seed(12345)\n\nfig, ax = plt.subplots(1, 1)\nX, y = perceptron_data(noise = 0.8)\nplot_perceptron_data(X, y, ax)\nplt.grid(True)\n\n\n\n\n\n\n\n\nNext, we attempt to draw the line with a maximum iteration of 1000. If we do nt give it this maximum number of iterations, the code will keep running trying to find the line that linearly separates the points, which =, as we can see, will not be possible.\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\n\n# instantiate a model and an optimizer\np = Perceptron()\nopt = PerceptronOptimizer(p)\n\nloss = 1.0\n# for keeping track of loss values\nloss_vec = []\n\nn = X.size()[0]\n\nnum_iter = 1000\nwhile loss &gt; 0 and num_iter &gt; 0: # dangerous -- only terminates if data is linearly separable\n    \n    # not part of the update: just for tracking our progress\n    loss = p.loss(X, y)\n    loss_vec.append(loss)\n    # print(loss)\n    # pick a random data point\n    i = torch.randint(n, size = (1,))\n    \n    x_i = X[[i],:]\n    y_i = y[i]\n    # perform a perceptron update using the random data point\n    opt.step(x_i, y_i)\n    num_iter = num_iter - 1\n\nfig, ax = plt.subplots(1, 1)\nplot_perceptron_data(X, y, ax)\n\ndraw_line(w_1, x_min = -3, x_max = 3, ax = ax, color = \"black\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nHere, we see the the data is not linearly separable as the points are scattered within each other on either side of the line.\nTo see the evolution of loss over time, I create the following graph:\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nThe graph above demonstrates the evolution of the loss over training. As seen, it never reaches 0.0 in the 1000 iterations, so if there was no limit, it would keep running.\n\n\nExperiment 3:\nHere, I run algorithm on data with at least 5 features instead of 2:\n\n\nX, y = perceptron_data(n_points = 300, noise = 0.5, p_dims=5)\n\n# instantiate a model and an optimizer\np = Perceptron()\nopt = PerceptronOptimizer(p)\n\nloss = 1.0\n\n# for keeping track of loss values\nloss_vec = []\n\nn = X.size()[0]\n\nwhile loss &gt; 0 : # dangerous -- only terminates if data is linearly separable\n    \n    # not part of the update: just for tracking our progress\n    loss = p.loss(X, y)\n    loss_vec.append(loss)\n    # pick a random data point\n    i = torch.randint(n, size = (1,))\n    \n    x_i = X[[i],:]\n    y_i = y[i]\n    # perform a perceptron update using the random data point\n    opt.step(x_i, y_i)\n\nNext, I will show the evolution of the score over the training period:\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nGiven the data above, I believe the data is linearly separable as the code is set to terminate when it reaches 0, which, as we can see, it does."
  },
  {
    "objectID": "posts/implementing-perceptron/index.html#minibatch-perceptron-experiments",
    "href": "posts/implementing-perceptron/index.html#minibatch-perceptron-experiments",
    "title": "Implementing Perceptron",
    "section": "Minibatch Perceptron Experiments",
    "text": "Minibatch Perceptron Experiments\n\nExperiment 1:\nWhen k = 1, minibatch perceptron performs similarly to regular perceptron:\n\nX, y = perceptron_data(n_points = 300, noise = 0.2, p_dims=2)\n\nloss_vec = mini_batch(X, y, k=1)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nAs we can see, the evolution of the score over the training period looks similar to the regular perceptron evolution graph, where the data is found to be linearly separable before it reaches the number of max iterations."
  },
  {
    "objectID": "posts/implementing-perceptron/index.html#experiment-2-1",
    "href": "posts/implementing-perceptron/index.html#experiment-2-1",
    "title": "Implementing Perceptron",
    "section": "Experiment 2:",
    "text": "Experiment 2:\nWhen k = 10, minibatch perceptron can still find a separating line in 2d.\n\nX, y = perceptron_data(n_points = 300, noise = 0.17, p_dims=2)\n\nloss_vec = mini_batch(X, y, k=10)\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nHere, we see how the algorithm can still find a separating line as the evolution of the score over the training period reaches a loss=0 before the number of max iterations."
  },
  {
    "objectID": "posts/implementing-perceptron/index.html#experiment-3-1",
    "href": "posts/implementing-perceptron/index.html#experiment-3-1",
    "title": "Implementing Perceptron",
    "section": "Experiment 3:",
    "text": "Experiment 3:\nWhen k = n (that is, the batch size is the size of the entire data set), minibatch perceptron can converge even when the data is not linearly separable, provided that the learning rate alpha is small enough\n\nX, y = perceptron_data(n_points = 300, noise = 0.8, p_dims=5)\n\nloss_vec = mini_batch(X, y, k=X.size()[0])\n#loss_vec = mini_batch(k=X.size()[0]) # k = n(num of points in data set)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nAs seen, the data still converges, but does not get a loss=0 when the data is not linearly separable. It seems to even out and not move up and down when the learning rate alpha is 0.01."
  },
  {
    "objectID": "posts/implementing-perceptron/index.html#runtime-complexity",
    "href": "posts/implementing-perceptron/index.html#runtime-complexity",
    "title": "Implementing Perceptron",
    "section": "Runtime Complexity",
    "text": "Runtime Complexity\nWhat is the runtime complexity of a single iteration of the perceptron algorithm? Does the runtime complexity of a single iteration depend on the number of data points n? What about the number of features p? If you implemented minibatch perceptron, what is the runtime complexity of a single iteration of the minibatch perceptron algorithm?\n\nThe runtime complexity of a single iteration of the perceptron algorithm is O(n * p) because n, the number of data points, and p, the number of features, both make up the computational time. Therefore, the runtime complexity of a single iteration does depend on the number of data points n and the number fo features p because the algorithm iterates through each data point once to update the weights on misclassifications, creating the runtime of O(n), and for ech data point it also calculates the matrix multiplication of X and w, thus creating the runtime of O(p).\nThe runtime complexity of a single iteration of the minibatch perceptron algorithm is based on k, the size of the minibatch, and the number of features p, thus it has a runtime of O(k*p). In a singe iteration, the algorithm goes through a “minibatch” of data points rather than processing the entire dataset. Thus, it is now based on k, the size of the minibatch, instead of n as it processes k points at each iteration. Furthermore, it is still based on the number of features p because the algorithm iterates through each data point in the minibatch once to update the weights."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Final Project Blog Post\n\n\n\n\n\nA blog post describing our final project\n\n\n\n\n\nMay 16, 2024\n\n\nDaniela Delgado and Lenox Herman\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing Perceptron\n\n\n\n\n\nIn this blog post, I completed an implementation of the perceptron algorithm and tested it in several experiments. I implemented simple perceptron and minibatch perceptron. objectives: - Theory - Implementation - Experimentation\n\n\n\n\n\nMay 14, 2024\n\n\nDaniela Delgado\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing Logistic Regression\n\n\n\n\n\nIn this blog post, I implemented several first-order methods: optimization algorithms based on the gradients of functions. I implemented simple gradient descent, a momentum method, and stochastic gradient descent, comparing their performance for training logistic regression. objectives: - Theory - Implementation - Experimentation\n\n\n\n\n\nApr 23, 2024\n\n\nDaniela Delgado\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Decision Making\n\n\n\n\n\nTraining data to predict if a person will default on a loan by finding a threshold using a LogisticRegression model!\n\n\n\n\n\nMar 26, 2024\n\n\nDaniela Delgado\n\n\n\n\n\n\n\n\n\n\n\n\nWomen in Data Science\n\n\n\n\n\nIn this blog post, we explore why there are fewer women in the data science field thorugh readings and analyzations. We also reflect and contexualize on the women who spoke on their careers in the data science field.\n\n\n\n\n\nMar 24, 2024\n\n\nDaniela Delgado\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins Post\n\n\n\n\n\nTraining data to accurately classify penguins using LogisticRegression and DecisionTreeClassifier models!\n\n\n\n\n\nFeb 20, 2024\n\n\nDaniela Delgado\n\n\n\n\n\n\nNo matching items"
  }
]