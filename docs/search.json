[
  {
    "objectID": "ClassNotes/22-convex-erm.html",
    "href": "ClassNotes/22-convex-erm.html",
    "title": "Convex Empirical Risk Minimization",
    "section": "",
    "text": "Last time, we studied the binary classification problem. In this problem, we assume that we have a feature matrix \\(\\mathbf{X} \\in \\mathbb{R}^{n\\times p}\\). Each row of this feature matrix gives the predictor data (features) for each of \\(n\\) total observations:\n\\[\n\\mathbf{X} = \\left[\\begin{matrix} & - & \\mathbf{x}_1 & - \\\\\n& - & \\mathbf{x}_2 & - \\\\\n& \\vdots & \\vdots & \\vdots \\\\\n& - & \\mathbf{x}_{n} & - \\end{matrix}\\right]\n\\]\nWe also have a target vector \\(\\mathbf{y} \\in \\{0,1\\}^n\\).  Here’s an example of how our training data might look:For convenience, we will continue to assume that the final column of \\(\\mathbf{X}\\) is a column of 1s; i.e. \\(x_{ip} = 1\\) for all \\(i = 1,\\ldots,n\\).\n\n\nCode\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(n_points = 300, noise = 0.2)\n\ndef plot_classification_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -1, vmax = 2, alpha = 0.8, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = classification_data()\nplot_classification_data(X, y, ax)\n\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\n\n\n\n\n\n\nFigure 1: 300 data points in the 2d plane, each of which has one of two labels.\n\n\n\n\n\nWe continue to study the linear classification problem. We will find a vector of weights \\(\\mathbf{w}\\) with the property that the hyperplane defined by the equation\n\\[\n\\langle \\mathbf{w}, \\mathbf{x} \\rangle = 0\n\\]\napproximately separates the two classes.\n\n\nOnce we have chosen linear models as our tool, we can specify a model for the binary classification task by making two additional choices:\n\nLoss: How will we measure the success of the model in distinguishing the two classes?\nOptimizer: What algorithm will we use in order to minimize the loss?\n\nWhat choices did we make in the context of the perceptron?\nThe loss function was the misclassification rate. If we let \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle\\), then we can write the loss like this: Here, the term \\(2y_i - 1\\) transforms a \\(y_i\\) with values in \\(\\{0,1\\}\\) into one with values in \\(\\{-1,1\\}\\).\n\\[\nL(\\mathbf{w}) = \\frac{1}{n}\\sum_{i = 1}^n \\mathbb{1}[s_i (2y_i-1) &lt; 0]\n\\]\nThe optimizer we used to minimize the loss was the perceptron update, in which we picked a random point \\(i\\) and then performed the update\n \\[\n\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} + \\mathbb{1}[s_i (2y_i-1) &lt; 0]y_i \\mathbf{x}_i\n\\]If \\(i\\) is correctly classified (i.e. if \\(s_i(2 y_i - 1) &gt; 0\\)), then the second term zeros out and nothing happens.\nHowever, as we saw, this doesn’t actually work that well. There are two problems:\n\nOur problem with the optimizer was that this update won’t actually converge if the data is not linearly separable. Maybe we could choose a better optimizer that would converge?\nUnfortunately not – as we saw last time, the very problem of minimizing \\(L(\\mathbf{w})\\) is NP-hard. This is a problem with the loss function itself.\n\nSo, how could we choose a better loss function that would allow us to create efficient algorithms?\n\n\n\nLet’s start by visualizing a single term of the perceptron loss function. We’ll view this as a function of the score \\(s\\) and the true target value \\(y\\):\n\\[\n\\ell(s, y) = \\mathbb{1}[s (2y-1) &lt; 0]\\;.\n\\]\nWe’ll call this the 0-1 loss function. Here’s a plot of this function for each of the two possible values of \\(y\\):\n\n\n\n# or \n# hinge_loss = lambda s, y: 1*(s*(2*y-1) &lt; 0)\n\n\n\nCode\nfrom matplotlib import pyplot as plt \nplt.style.use('seaborn-v0_8-whitegrid')\n# plt.rcParams[\"figure.figsize\"] = (10, 4)\n\ndef plot_loss(loss_fun, show_line = False):\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n\n        fig, axarr = plt.subplots(1, 2, figsize = (6, 3)) \n        s = torch.linspace(-1, 1, 10001)\n\n        for j in range(2):\n            y = [0, 1][j]\n            axarr[j].set_title(f\"y = {y}\")\n            axarr[j].set(xlabel = r\"$s$\", \n                        ylabel = r\"$\\ell(s, y)$\")\n            \n            ix1 = s &lt; 0\n            axarr[j].plot(s[ix1], loss_fun(s[ix1], y), color = \"black\")\n            ix2 = s &gt; 0\n            axarr[j].plot(s[ix2], loss_fun(s[ix2], y), color = \"black\")\n\n            if show_line: \n                s1 = torch.tensor([-0.7])\n                s2 = torch.tensor([0.9])\n\n                axarr[j].plot([s1, s2], [loss_fun(s1, y), loss_fun(s2, y)], color = \"darkgrey\", linestyle = \"--\")\n\n        plt.tight_layout()\n        return fig, axarr\n\nfig, axarr = plot_loss(loss_fun = zero_one_loss, show_line = False)\n\n\n\n\n\n\n\n\nFigure 2: The 0-1 loss function.\n\n\n\n\n\nSurprsingly, the problem with this loss function \\(\\ell\\) is that we can “draw lines under the function.” What this means is that we can pick two points on the graph of the function, connect them with a line, and find that the line lies under the graph of the function in some regions:\n\n\nCode\nfig, axarr = plot_loss(loss_fun = zero_one_loss, show_line = True)\n\n\n\n\n\n\n\n\nFigure 3: The 0-1 loss function with a line demonstrating that this function is nonconvex.\n\n\n\n\n\nNot convex. this is why perceptron does not work. Convex definition: a function f that takes vector of R^n and scalarars of R, is strictly convex if for any scalar in interval (0, 1) and z if z is in R^n then f(lambda Z1 + (1-lambda) z2) &lt;= lambdaf(z1) + (1-lambda) f(z2)\n- line cannot be underneath the line\nSurprisingly, this specific geometric property is what’s blocking us from achieving performant searchability for the problem of finding \\(\\mathbf{w}\\).\n\n\n\nIn order to develop good properties of loss functions, we need to define two concepts: convex sets, which we mostly won’t need to worry about, and convex functions.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 1 A set \\(S \\subseteq \\mathbb{R}^n\\) is convex if, for any two points \\(\\mathbf{z}_1, \\mathbf{z}_2 \\in S\\) and for any \\(\\lambda \\in [0,1]\\), the point \\(\\mathbf{z} = \\lambda \\mathbf{z}_1 + (1-\\lambda) \\mathbf{z}_2\\) is also an element of \\(S\\).\n\n\n\nWe also need to define convex functions:\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 2 (Convex Functions) Let \\(S \\subseteq \\mathbb{R}^n\\) be convex. A function \\(f:S \\rightarrow \\mathbb{R}\\) is convex if, for any \\(\\lambda \\in \\mathbb{R}\\) and any two points \\(\\mathbf{z}_1, \\mathbf{z}_2 \\in S\\), we have\n\\[\nf(\\lambda \\mathbf{z}_1 + (1-\\lambda)\\mathbf{z}_2) \\leq \\lambda f( \\mathbf{z}_1 ) + (1-\\lambda)f(\\mathbf{z}_2)\\;.\n\\]\nThe function \\(f\\) is strictly convex if the inequality is strict: for all \\(\\lambda\\), \\(\\mathbf{z}_1\\), and \\(\\mathbf{z}_2\\),\n\\[\nf(\\lambda \\mathbf{z}_1 + (1-\\lambda)\\mathbf{z}_2) &lt; \\lambda f( \\mathbf{z}_1 ) + (1-\\lambda)f(\\mathbf{z}_2)\\;.\n\\]\n\n\n\nRoughly, a convex function is “bowl-shaped,” in the sense that any line connecting two points on its graph must lie above the graph. The most familiar example of a convex function is our good friend the convex parabola:\n\n\nCode\nx = torch.linspace(-1, 1, 10001)\ny = x**2\n\nplt.plot(x, y, color = \"black\")\nlabs = plt.gca().set(xlabel = r\"$x$\", ylabel = r\"$f(x)$\")\n\n\n\n\n\n\n\n\nFigure 4: The convex parabola \\(f(x) = x^2\\)\n\n\n\n\n\nNote that any straight line connecting two points on this graph always stays above the graph of the parabola. As we saw above, the 0-1 loss function \\(\\ell(s, y) = \\mathbb{1}[s(2y-1)&lt;0]\\) does not have this property.\nWe can also define convex functions to replace the nonconvex 0-1 loss function from earlier. Here’s an example, which is usually called the hinge loss, which is defined by the formula\n\\[\n\\ell(s, y) = y\\max\\{0, -s\\}  + (1 - y) \\max \\{0, s\\}\\;.\n\\]\n\ndef hinge_loss(s, y):\n    first_term = y*torch.max(torch.zeros_like(s), -s)\n    second_term = (1-y)*torch.max(torch.zeros_like(s), s)\n    return first_term + second_term\n\n\n\nCode\nfig, axarr = plot_loss(loss_fun = hinge_loss, show_line = True)\n\n\n\n\n\n\n\n\nFigure 5: The hinge loss function.\n\n\n\n\n\nThe hinge loss is not strictly convex and is not even everywhere differentiable! Despite this, the fact that it is convex has made it a modern workhorse of machine learning. The support vector machine (SVM) operates by minimizing the hinge loss. The “Rectified Linear Unit” (ReLU) is a mainstay of modern deep learning–and is just another name for the hinge loss.\nAn even handier loss function for our purposes is the sigmoid binary cross entropy, which is defined by the formula  \\[\n\\begin{aligned}\n\\ell(s, y) &=  -y \\log \\sigma(s) - (1-y)\\log (1-\\sigma(s))\\;,\n\\end{aligned}\n\\]In this formula, \\(\\sigma(s) = \\frac{1}{1 + e^{-s}}\\) is the logistic sigmoid function.\n\n#B4 and B5 on warmup\ndef sig(s):\n     return 1 / (1 + torch.exp(-s))\ndef binary_cross_entropy(s,y):\n    return -(y*sig(s).log()) + (1-y*(1-sig(s)).log())\n\n# or \n# sig = lambda s: 1 / (1 + torch.exp(-s))\n# binary_cross_entropy = lambda s, y: -(y * sig(s).log() + (1 - y)*(1-sig(s)).log())\n\n\n\nCode\nsig = lambda s: 1 / (1 + torch.exp(-s))\nbinary_cross_entropy = lambda s, y: -(y * sig(s).log() + (1 - y)*(1-sig(s)).log())\nfig, axarr = plot_loss(loss_fun = binary_cross_entropy, show_line = True)\n\n\n\n\n\n\n\n\nFigure 6: The binary cross-entropy loss function.\n\n\n\n\n\nThis function is also convex, and has the considerable benefit of being everywhere differentiable.\nWe intentionally formulated our definition of convexity for functions of many variables. Here is a convex function \\(f:\\mathbb{R}^2 \\rightarrow \\mathbb{R}\\).\n\n\nCode\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n\nx = torch.linspace(-1, 1, 1001)[:, None]\ny = torch.linspace(-1, 1, 1001)[None, :]\n\nz = x**2 + y**2\n\nax.plot_surface(x, y, z, cmap=\"inferno_r\",\n                       linewidth=0, antialiased=False)\n\nlabs = ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\n\n\n\n\n\n\n\nFigure 7: A convex quadratic function of two variables.\n\n\n\n\n\nYou could imagine trying to draw a straight line between two points on the graph of this function – the line would always be above the graph. When thinking about convexity in many variables, it is often sufficient to imagine a bowl-shaped function like this one.\n\n\n\nWe are now ready to define the primary framework in which we will conduct supervised machine learning: convex empirical risk minimization.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 3 (Empirical Risk Minimization) Given a loss function \\(\\ell:\\mathbb{R}\\times \\{0,1\\} \\rightarrow \\mathbb{R}\\), a feature matrix \\(\\mathbb{X} \\in \\mathbb{R}^{n\\times p}\\), a target vector \\(\\mathbf{y}\\), and a parameter vector \\(\\mathbf{w} \\in \\mathbb{R}^p\\), the empirical risk of \\(\\mathbf{w}\\) is\n\\[\n\\begin{aligned}\nL(\\mathbf{w}) = \\frac{1}{n}\\sum_{i = 1}^n \\ell(s_i, y_i), \\quad&\\text{where }s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle\\;.\n\\end{aligned}\n\\]\nThe empirical risk minimization problem is to find the value of \\(\\mathbf{w}\\) that makes \\(L(\\mathbf{w})\\) smallest:\n\\[\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\begin{aligned}\n\\hat{\\mathbf{w}} &= \\argmin_{\\mathbf{w}} L(\\mathbf{w})  \\\\\n                 &= \\argmin_{\\mathbf{w}} \\frac{1}{n}\\sum_{i = 1}^n \\ell(s_i, y_i) \\\\\n                 &= \\argmin_{\\mathbf{w}} \\frac{1}{n}\\sum_{i = 1}^n \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle, y_i)\\;.\n\\end{aligned}\n\\tag{1}\\]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nProposition 1 (Convex \\(\\ell\\) means convex \\(L\\)) If the per-observation loss function \\(\\ell:\\mathbb{R}\\times \\{0,1\\} \\rightarrow \\mathbb{R}\\) is convex in its first argument, then the empirical risk \\(L(\\mathbf{w})\\) is convex as a function of \\(\\mathbf{w}\\).\n\n\n\nThe proof of Proposition 1 involves some elementary properties of convex functions:\n\nIf \\(f(\\mathbf{z})\\) is convex as a function of \\(\\mathbf{z}\\), then \\(g(\\mathbf{z}) = f(\\mathbf{A}\\mathbf{z'})\\) is also convex as a function of \\(\\mathbf{z}'\\), provided that all the dimensions work out.\nAny finite sum of convex functions is convex.\n\nSo, we know that if we choose \\(\\ell\\) to be convex in the score function, then the entire empirical risk \\(L\\) will be convex as a function of the weight vector \\(\\mathbf{w}\\).\nWhy do we care?\n\n\n\nWe want to solve the empirical risk minimization problem:\n\\[\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\begin{aligned}\n\\hat{\\mathbf{w}} &= \\argmin_{\\mathbf{w}} L(\\mathbf{w}).\n\\end{aligned}\n\\]\nWe might ask ourselves a few questions about this problem:\n\nExistence: Does there exist any choice of \\(\\mathbf{w}\\) that achieves a minimizing value for this function?\nUniqueness: Is this choice of \\(\\mathbf{w}\\) unique, or are there multiple candidates?\nSearchability: are there algorithms which are guaranteed to (a) terminate and (b) not get “trapped” at a bad solution?\n\nAnswering these questions precisely requires a bit more math:\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 4 (Local and Global Minimizers) A point \\(\\mathbf{z}\\in S\\) is a global minimizer of the function \\(f:S \\rightarrow \\mathbb{R}\\) if \\(f(\\mathbf{z}) \\leq f(\\mathbf{z}')\\) for all \\(\\mathbf{z}' \\in S\\).\nA point \\(\\mathbf{z} \\in S\\) is a local minimizer of \\(f:S \\rightarrow \\mathbb{R}\\) if there exists a neighborhood \\(T \\subseteq S\\) containing \\(\\mathbf{z}\\) such that \\(\\mathbf{z}\\) is a global minimizer of \\(f\\) on \\(T\\).\n\n\n\nIt’s ok if you don’t know what it means for a set to be closed – all the convex functions we will care about in this class will either be defined on sets where this theorem holds or will be otherwise defined so that the conclusions apply.\n\n\n\n\n\n\nNote\n\n\n\n\nTheorem 1 (Properties of Convex Functions) Let \\(f:S \\rightarrow \\mathbb{R}\\) be a convex function. Then:\n\nIf \\(S\\) is closed and bounded, \\(f\\) has a minimizer \\(\\mathbf{z}^*\\) in \\(S\\).\nFurthermore, if \\(\\mathbf{z}^*\\) is a local minimizer of \\(f\\), then it is also a global minimizer.\nIf in addition \\(f\\) is strictly convex, then this minimizer is unique.\n\n\n\n\n\nProof. The proof of item 1 needs some tools from real analysis. The short version is:\n\nEvery convex function is continuous.\nIf \\(S\\subseteq \\mathbb{R}^n\\) is closed and bounded, then it is compact.\nContinuous functions achieve minimizers and maximizers on compact sets.\n\nIt’s ok if you didn’t follow this! Fortunately the second part of the proof is one we can do together. Suppose to contradiction that \\(\\mathbf{z}^*\\) is a local minimizer of \\(f\\), but that there is also a point \\(\\mathbf{z}'\\) such that \\(f(\\mathbf{z}') &lt; f(\\mathbf{z}^*)\\). Since \\(\\mathbf{z}^*\\) is a local minimizer, we can find some neighborhood \\(T\\) containing \\(\\mathbf{z}^*\\) such that \\(\\mathbf{z}^*\\) is a minimizer of \\(f\\) on \\(T\\). Let \\(\\lambda\\) be some very small number and consider the point \\(\\mathbf{z} = \\lambda \\mathbf{z}' + (1-\\lambda)\\mathbf{z}^*\\). Specifically, choose \\(\\lambda\\) small enough so that \\(\\mathbf{z} \\in T\\) (since this makes \\(\\mathbf{z}\\) close to \\(\\mathbf{z}^*\\)). We can evaluate\n\\[\n\\begin{align}\nf(\\mathbf{z}) &= f(\\lambda \\mathbf{z}' + (1-\\lambda)\\mathbf{z}^*) &\\quad \\text{(definition of $\\mathbf{z}$)}\\\\\n       &\\leq \\lambda f(\\mathbf{z}') + (1-\\lambda)f(\\mathbf{z}^*)  &\\quad \\text{($f$ is convex)} \\\\\n       &= f(\\mathbf{z}^*) + \\lambda (f(\\mathbf{z}') - f(\\mathbf{z}^*)) &\\quad \\text{(algebra)}\\\\\n       &&lt; f(\\mathbf{z}^*)\\;. &\\quad \\text{(assumption that $f(\\mathbf{z}') &lt; f(\\mathbf{z}^*)$)}\n\\end{align}\n\\]\nBut this is a contradiction, since we constructed \\(\\mathbf{z}\\) to be in the neighborhood \\(T\\) where \\(\\mathbf{z}^*\\) is a local minimizer. We conclude that there is no \\(\\mathbf{z}'\\) such that \\(f(\\mathbf{z}') &lt; f(\\mathbf{z}^*)\\), and therefore that \\(\\mathbf{z}^*\\) is a global minimizer.\nThe proof of the third part follows a very similar argument to the proof of the second part.\n\nThese properties of convex functions have very important implications for our fundamental questions on empirical risk minimization. If we choose a strictly convex per-observation loss function \\(\\ell\\), then our empirical risk \\(L\\) will also be strictly convex, and:\nExistence. The minimizer \\(\\hat{\\mathbf{w}} = \\argmin_{\\mathbf{w}}L(\\mathbf{w})\\) will exist.\nUniqueness: The minimizer \\(\\hat{\\mathbf{w}} = \\argmin_{\\mathbf{w}}L(\\mathbf{w})\\) will be unique: if we run a minimization algorithm repeatedly, we’ll get the same answer every time.\nSearchability: When \\(L\\) is convex, there are also no local minimizers other than the global minimizer. Algorithmically, this is the most important property of convexity. It means that if I manage to find any local minimizer at all, that point must be the global minimizer.  Performance: Convexity significantly reduces the difficulty of our task: instead of trying to find “the best” solution, it’s sufficient for us to find any local optimum. This means that we can design our algorithms to be “greedy local minimizer hunters.” There are lots of fast algorithms to do this. An especially important class of algorithms are gradient descent methods, which we’ll discuss soon.If you’ve taken an algorithms class, one way of thinking of convexity is that it guarantees that greedy methods work for solving minimization problems.\n\n\n\nYou may have heard of logistic regression in a course on statistics or data science. Logistic regression is simply binary classification using a linear model and the binary cross-entropy loss function which we saw above:\n\\[\n\\begin{aligned}\n\\ell(s, y) &=  -y \\log \\sigma(s) - (1-y)\\log (1-\\sigma(s))\\;,\n\\end{aligned}\n\\]\nAs can be proven with calculus, this function is convex as a function of \\(s\\). The logistic regression problem then becomes the problem of solving:\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{w}} &= \\argmin_\\mathbf{w} \\frac{1}{n} \\sum_{i = 1}^n \\ell(s_i, y_i)  \\\\\n&= \\argmin_\\mathbf{w} \\frac{1}{n} \\sum_{i = 1}^n \\left[-y_i \\log \\sigma(s_i) - (1-y_i)\\log (1-\\sigma(s_i))\\right] \\\\\n&= \\argmin_\\mathbf{w} \\frac{1}{n} \\sum_{i = 1}^n \\left[-y_i \\log \\sigma(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle) - (1-y_i)\\log (1-\\sigma(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle)\\right]\n\\end{aligned}\n\\]\nSo, let’s do convex empirical risk minimization! We’ll use the following data set. Note that this data is not linearly separable and therefore the perceptron algorithm would not converge.\n\n\nCode\nfig, ax = plt.subplots(1, 1)\nX, y = classification_data(noise = 0.5)\nplot_classification_data(X, y, ax)\n\n\n\n\n\n\n\n\nFigure 8: Data for logistic regression.\n\n\n\n\n\nLet’s go ahead and train a logistic regression model. For the purposes of today, we can do this in a very simple way that doesn’t even involve an explicit training loop. Next time, we’ll learn how to write an explicit training loop.\nFirst, we’ll define a complete function for calculating the empirical risk for a given value of \\(\\mathbf{w}\\). Since we already implemented binary_cross_entropy, this implementation is very quick:\n\ndef empirical_risk(w, X, y):\n    s = X@w #scores of feature matrix and weight vector w\n    return binary_cross_entropy(s, y).mean() # call on scores (s) and target vector y\n\nNow we’ll use the minimize function from scipy.optimize to find the value of \\(\\mathbf{w}\\) that makes this function smallest:\n\nfrom scipy.optimize import minimize #finds best w behind the scenes\n\nw0 = torch.tensor([1.0, 1.0, 1.0]) #initial guess\n#find w that minimizes impirical risk\nresult = minimize(lambda w: empirical_risk(w, X, y), x0 = w0)\nw = result.x\n\nprint(f\"\"\"Learned parameter vector w = {w}.\nThe empirical risk is {result.fun:.4f}.\"\"\")\n\nLearned parameter vector w = [ 4.09011877  4.18886441 -3.84455342].\nThe empirical risk is 0.1755.\n\n\nHow does it look?\n\n\nCode\ndef draw_line(w, X, y, x_min, x_max, ax, **kwargs):\n    fig, ax = plt.subplots(1, 1)\n    plot_classification_data(X, y, ax)\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w[0]*x + w[2])/w[1]\n    l = ax.plot(x, y, **kwargs)\n\ndraw_line(w, X, y, x_min = -0.5, x_max = 1.5, ax = ax, color = \"black\", linestyle = \"dashed\")\n\n# fig\n\n\n\n\n\n\n\n\nFigure 9: The separating line learned by logistic regression.\n\n\n\n\n\nPretty good! Yes, it’s as easy as that – provided that you don’t ask too many questions about how the minimize function works. Questions like that will be the topic of our next several sets of notes.\n\n\n\nIn this set of notes, we introduced a fundamental idea: convex empirical risk minimization. To do convex empirical risk minimization, all we need is a convex per-observation loss function. This gives us a convex empirical risk function, which is simply the mean of all the per-observation losses. Once we have that, the problem of classification reduces to the problem of finding a value of the parameter vector \\(\\mathbf{w}\\) that makes the empirical risk small. Convexity guarantees that this problem has exactly one solution. Today, we found this solution using a packaged optimizer. Starting next time, we’ll learn how to write our own optimization algorithms and explore how optimization techniques enable scalable machine learning.\n\n\nHow would we do this if we didn’t have access to the minimize function? We’ll soon discuss this question much more. For now, we can take a look at the code block below, which implements such a loop using a framework very similar to the one we learned for perceptron. This model also inherits from the LinearModel class that you previously started implementing. The training loop is also very similar to our training loop for the perceptron. The main difference is that the loss is calculated using the binary_cross_entropy function above, and the step function of the GradientDescentOptimizer works differently in a way that we will discuss in the following section.\nStarting with the code block below, you won’t be able to follow along in coding these notes unless you have sneakily implemented logistic regression in a hidden module.\n\n\n\nfrom hidden.logistic import LogisticRegression, GradientDescentOptimizer\n\n# instantiate a model and an optimizer\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\n# for keeping track of loss values\nloss_vec = []\n\nfor _ in range(100):\n\n    # not part of the update: just for tracking our progress    \n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n\n    # only this line actually changes the parameter value\n    opt.step(X, y, lr = 0.02)\n\nplt.plot(torch.arange(1, len(loss_vec)+1), loss_vec, color = \"black\")\nplt.semilogx()\nlabs = plt.gca().set(xlabel = \"Number of gradient descent iterations\", ylabel = \"Loss (binary cross entropy)\")\n\n\nFigure 10\n\n\n\nThe loss quickly levels out to a constant value (which is the same as we learned with scipy.optimize.minimize). Because our theory tells us that the loss function is convex, we know that the value of \\(\\mathbf{w}\\) we have found is the best possible, in the sense of minimizing the loss.\nLet’s take a look at the separating line we found:\n\ndraw_line(LR.w, X, y, \n          x_min = -0.5, \n          x_max = 1.5, \n          ax = ax, \n          color = \"black\", \n          linestyle = \"dashed\")\n\nYep, that’s the same line as we found earlier!\nAlthough our data is not linearly separable, the separating line we have learned appears to do a reasonable job of separating the points from each other. Let’s check our accuracy:\nNot too bad! In the next section, we’ll learn much, much more about what’s behind that opt.step() call."
  },
  {
    "objectID": "ClassNotes/22-convex-erm.html#modeling-choices",
    "href": "ClassNotes/22-convex-erm.html#modeling-choices",
    "title": "Convex Empirical Risk Minimization",
    "section": "",
    "text": "Once we have chosen linear models as our tool, we can specify a model for the binary classification task by making two additional choices:\n\nLoss: How will we measure the success of the model in distinguishing the two classes?\nOptimizer: What algorithm will we use in order to minimize the loss?\n\nWhat choices did we make in the context of the perceptron?\nThe loss function was the misclassification rate. If we let \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle\\), then we can write the loss like this: Here, the term \\(2y_i - 1\\) transforms a \\(y_i\\) with values in \\(\\{0,1\\}\\) into one with values in \\(\\{-1,1\\}\\).\n\\[\nL(\\mathbf{w}) = \\frac{1}{n}\\sum_{i = 1}^n \\mathbb{1}[s_i (2y_i-1) &lt; 0]\n\\]\nThe optimizer we used to minimize the loss was the perceptron update, in which we picked a random point \\(i\\) and then performed the update\n \\[\n\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} + \\mathbb{1}[s_i (2y_i-1) &lt; 0]y_i \\mathbf{x}_i\n\\]If \\(i\\) is correctly classified (i.e. if \\(s_i(2 y_i - 1) &gt; 0\\)), then the second term zeros out and nothing happens.\nHowever, as we saw, this doesn’t actually work that well. There are two problems:\n\nOur problem with the optimizer was that this update won’t actually converge if the data is not linearly separable. Maybe we could choose a better optimizer that would converge?\nUnfortunately not – as we saw last time, the very problem of minimizing \\(L(\\mathbf{w})\\) is NP-hard. This is a problem with the loss function itself.\n\nSo, how could we choose a better loss function that would allow us to create efficient algorithms?"
  },
  {
    "objectID": "ClassNotes/22-convex-erm.html#convex-functions",
    "href": "ClassNotes/22-convex-erm.html#convex-functions",
    "title": "Convex Empirical Risk Minimization",
    "section": "",
    "text": "Let’s start by visualizing a single term of the perceptron loss function. We’ll view this as a function of the score \\(s\\) and the true target value \\(y\\):\n\\[\n\\ell(s, y) = \\mathbb{1}[s (2y-1) &lt; 0]\\;.\n\\]\nWe’ll call this the 0-1 loss function. Here’s a plot of this function for each of the two possible values of \\(y\\):\n\n\n\n# or \n# hinge_loss = lambda s, y: 1*(s*(2*y-1) &lt; 0)\n\n\n\nCode\nfrom matplotlib import pyplot as plt \nplt.style.use('seaborn-v0_8-whitegrid')\n# plt.rcParams[\"figure.figsize\"] = (10, 4)\n\ndef plot_loss(loss_fun, show_line = False):\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n\n        fig, axarr = plt.subplots(1, 2, figsize = (6, 3)) \n        s = torch.linspace(-1, 1, 10001)\n\n        for j in range(2):\n            y = [0, 1][j]\n            axarr[j].set_title(f\"y = {y}\")\n            axarr[j].set(xlabel = r\"$s$\", \n                        ylabel = r\"$\\ell(s, y)$\")\n            \n            ix1 = s &lt; 0\n            axarr[j].plot(s[ix1], loss_fun(s[ix1], y), color = \"black\")\n            ix2 = s &gt; 0\n            axarr[j].plot(s[ix2], loss_fun(s[ix2], y), color = \"black\")\n\n            if show_line: \n                s1 = torch.tensor([-0.7])\n                s2 = torch.tensor([0.9])\n\n                axarr[j].plot([s1, s2], [loss_fun(s1, y), loss_fun(s2, y)], color = \"darkgrey\", linestyle = \"--\")\n\n        plt.tight_layout()\n        return fig, axarr\n\nfig, axarr = plot_loss(loss_fun = zero_one_loss, show_line = False)\n\n\n\n\n\n\n\n\nFigure 2: The 0-1 loss function.\n\n\n\n\n\nSurprsingly, the problem with this loss function \\(\\ell\\) is that we can “draw lines under the function.” What this means is that we can pick two points on the graph of the function, connect them with a line, and find that the line lies under the graph of the function in some regions:\n\n\nCode\nfig, axarr = plot_loss(loss_fun = zero_one_loss, show_line = True)\n\n\n\n\n\n\n\n\nFigure 3: The 0-1 loss function with a line demonstrating that this function is nonconvex.\n\n\n\n\n\nNot convex. this is why perceptron does not work. Convex definition: a function f that takes vector of R^n and scalarars of R, is strictly convex if for any scalar in interval (0, 1) and z if z is in R^n then f(lambda Z1 + (1-lambda) z2) &lt;= lambdaf(z1) + (1-lambda) f(z2)\n- line cannot be underneath the line\nSurprisingly, this specific geometric property is what’s blocking us from achieving performant searchability for the problem of finding \\(\\mathbf{w}\\)."
  },
  {
    "objectID": "ClassNotes/22-convex-erm.html#convex-loss-functions",
    "href": "ClassNotes/22-convex-erm.html#convex-loss-functions",
    "title": "Convex Empirical Risk Minimization",
    "section": "",
    "text": "In order to develop good properties of loss functions, we need to define two concepts: convex sets, which we mostly won’t need to worry about, and convex functions.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 1 A set \\(S \\subseteq \\mathbb{R}^n\\) is convex if, for any two points \\(\\mathbf{z}_1, \\mathbf{z}_2 \\in S\\) and for any \\(\\lambda \\in [0,1]\\), the point \\(\\mathbf{z} = \\lambda \\mathbf{z}_1 + (1-\\lambda) \\mathbf{z}_2\\) is also an element of \\(S\\).\n\n\n\nWe also need to define convex functions:\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 2 (Convex Functions) Let \\(S \\subseteq \\mathbb{R}^n\\) be convex. A function \\(f:S \\rightarrow \\mathbb{R}\\) is convex if, for any \\(\\lambda \\in \\mathbb{R}\\) and any two points \\(\\mathbf{z}_1, \\mathbf{z}_2 \\in S\\), we have\n\\[\nf(\\lambda \\mathbf{z}_1 + (1-\\lambda)\\mathbf{z}_2) \\leq \\lambda f( \\mathbf{z}_1 ) + (1-\\lambda)f(\\mathbf{z}_2)\\;.\n\\]\nThe function \\(f\\) is strictly convex if the inequality is strict: for all \\(\\lambda\\), \\(\\mathbf{z}_1\\), and \\(\\mathbf{z}_2\\),\n\\[\nf(\\lambda \\mathbf{z}_1 + (1-\\lambda)\\mathbf{z}_2) &lt; \\lambda f( \\mathbf{z}_1 ) + (1-\\lambda)f(\\mathbf{z}_2)\\;.\n\\]\n\n\n\nRoughly, a convex function is “bowl-shaped,” in the sense that any line connecting two points on its graph must lie above the graph. The most familiar example of a convex function is our good friend the convex parabola:\n\n\nCode\nx = torch.linspace(-1, 1, 10001)\ny = x**2\n\nplt.plot(x, y, color = \"black\")\nlabs = plt.gca().set(xlabel = r\"$x$\", ylabel = r\"$f(x)$\")\n\n\n\n\n\n\n\n\nFigure 4: The convex parabola \\(f(x) = x^2\\)\n\n\n\n\n\nNote that any straight line connecting two points on this graph always stays above the graph of the parabola. As we saw above, the 0-1 loss function \\(\\ell(s, y) = \\mathbb{1}[s(2y-1)&lt;0]\\) does not have this property.\nWe can also define convex functions to replace the nonconvex 0-1 loss function from earlier. Here’s an example, which is usually called the hinge loss, which is defined by the formula\n\\[\n\\ell(s, y) = y\\max\\{0, -s\\}  + (1 - y) \\max \\{0, s\\}\\;.\n\\]\n\ndef hinge_loss(s, y):\n    first_term = y*torch.max(torch.zeros_like(s), -s)\n    second_term = (1-y)*torch.max(torch.zeros_like(s), s)\n    return first_term + second_term\n\n\n\nCode\nfig, axarr = plot_loss(loss_fun = hinge_loss, show_line = True)\n\n\n\n\n\n\n\n\nFigure 5: The hinge loss function.\n\n\n\n\n\nThe hinge loss is not strictly convex and is not even everywhere differentiable! Despite this, the fact that it is convex has made it a modern workhorse of machine learning. The support vector machine (SVM) operates by minimizing the hinge loss. The “Rectified Linear Unit” (ReLU) is a mainstay of modern deep learning–and is just another name for the hinge loss.\nAn even handier loss function for our purposes is the sigmoid binary cross entropy, which is defined by the formula  \\[\n\\begin{aligned}\n\\ell(s, y) &=  -y \\log \\sigma(s) - (1-y)\\log (1-\\sigma(s))\\;,\n\\end{aligned}\n\\]In this formula, \\(\\sigma(s) = \\frac{1}{1 + e^{-s}}\\) is the logistic sigmoid function.\n\n#B4 and B5 on warmup\ndef sig(s):\n     return 1 / (1 + torch.exp(-s))\ndef binary_cross_entropy(s,y):\n    return -(y*sig(s).log()) + (1-y*(1-sig(s)).log())\n\n# or \n# sig = lambda s: 1 / (1 + torch.exp(-s))\n# binary_cross_entropy = lambda s, y: -(y * sig(s).log() + (1 - y)*(1-sig(s)).log())\n\n\n\nCode\nsig = lambda s: 1 / (1 + torch.exp(-s))\nbinary_cross_entropy = lambda s, y: -(y * sig(s).log() + (1 - y)*(1-sig(s)).log())\nfig, axarr = plot_loss(loss_fun = binary_cross_entropy, show_line = True)\n\n\n\n\n\n\n\n\nFigure 6: The binary cross-entropy loss function.\n\n\n\n\n\nThis function is also convex, and has the considerable benefit of being everywhere differentiable.\nWe intentionally formulated our definition of convexity for functions of many variables. Here is a convex function \\(f:\\mathbb{R}^2 \\rightarrow \\mathbb{R}\\).\n\n\nCode\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n\nx = torch.linspace(-1, 1, 1001)[:, None]\ny = torch.linspace(-1, 1, 1001)[None, :]\n\nz = x**2 + y**2\n\nax.plot_surface(x, y, z, cmap=\"inferno_r\",\n                       linewidth=0, antialiased=False)\n\nlabs = ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\n\n\n\n\n\n\n\nFigure 7: A convex quadratic function of two variables.\n\n\n\n\n\nYou could imagine trying to draw a straight line between two points on the graph of this function – the line would always be above the graph. When thinking about convexity in many variables, it is often sufficient to imagine a bowl-shaped function like this one."
  },
  {
    "objectID": "ClassNotes/22-convex-erm.html#convex-empirical-risk-minimization-1",
    "href": "ClassNotes/22-convex-erm.html#convex-empirical-risk-minimization-1",
    "title": "Convex Empirical Risk Minimization",
    "section": "",
    "text": "We are now ready to define the primary framework in which we will conduct supervised machine learning: convex empirical risk minimization.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 3 (Empirical Risk Minimization) Given a loss function \\(\\ell:\\mathbb{R}\\times \\{0,1\\} \\rightarrow \\mathbb{R}\\), a feature matrix \\(\\mathbb{X} \\in \\mathbb{R}^{n\\times p}\\), a target vector \\(\\mathbf{y}\\), and a parameter vector \\(\\mathbf{w} \\in \\mathbb{R}^p\\), the empirical risk of \\(\\mathbf{w}\\) is\n\\[\n\\begin{aligned}\nL(\\mathbf{w}) = \\frac{1}{n}\\sum_{i = 1}^n \\ell(s_i, y_i), \\quad&\\text{where }s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle\\;.\n\\end{aligned}\n\\]\nThe empirical risk minimization problem is to find the value of \\(\\mathbf{w}\\) that makes \\(L(\\mathbf{w})\\) smallest:\n\\[\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\begin{aligned}\n\\hat{\\mathbf{w}} &= \\argmin_{\\mathbf{w}} L(\\mathbf{w})  \\\\\n                 &= \\argmin_{\\mathbf{w}} \\frac{1}{n}\\sum_{i = 1}^n \\ell(s_i, y_i) \\\\\n                 &= \\argmin_{\\mathbf{w}} \\frac{1}{n}\\sum_{i = 1}^n \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle, y_i)\\;.\n\\end{aligned}\n\\tag{1}\\]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nProposition 1 (Convex \\(\\ell\\) means convex \\(L\\)) If the per-observation loss function \\(\\ell:\\mathbb{R}\\times \\{0,1\\} \\rightarrow \\mathbb{R}\\) is convex in its first argument, then the empirical risk \\(L(\\mathbf{w})\\) is convex as a function of \\(\\mathbf{w}\\).\n\n\n\nThe proof of Proposition 1 involves some elementary properties of convex functions:\n\nIf \\(f(\\mathbf{z})\\) is convex as a function of \\(\\mathbf{z}\\), then \\(g(\\mathbf{z}) = f(\\mathbf{A}\\mathbf{z'})\\) is also convex as a function of \\(\\mathbf{z}'\\), provided that all the dimensions work out.\nAny finite sum of convex functions is convex.\n\nSo, we know that if we choose \\(\\ell\\) to be convex in the score function, then the entire empirical risk \\(L\\) will be convex as a function of the weight vector \\(\\mathbf{w}\\).\nWhy do we care?"
  },
  {
    "objectID": "ClassNotes/22-convex-erm.html#convex-functions-have-global-minimizers",
    "href": "ClassNotes/22-convex-erm.html#convex-functions-have-global-minimizers",
    "title": "Convex Empirical Risk Minimization",
    "section": "",
    "text": "We want to solve the empirical risk minimization problem:\n\\[\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\begin{aligned}\n\\hat{\\mathbf{w}} &= \\argmin_{\\mathbf{w}} L(\\mathbf{w}).\n\\end{aligned}\n\\]\nWe might ask ourselves a few questions about this problem:\n\nExistence: Does there exist any choice of \\(\\mathbf{w}\\) that achieves a minimizing value for this function?\nUniqueness: Is this choice of \\(\\mathbf{w}\\) unique, or are there multiple candidates?\nSearchability: are there algorithms which are guaranteed to (a) terminate and (b) not get “trapped” at a bad solution?\n\nAnswering these questions precisely requires a bit more math:\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 4 (Local and Global Minimizers) A point \\(\\mathbf{z}\\in S\\) is a global minimizer of the function \\(f:S \\rightarrow \\mathbb{R}\\) if \\(f(\\mathbf{z}) \\leq f(\\mathbf{z}')\\) for all \\(\\mathbf{z}' \\in S\\).\nA point \\(\\mathbf{z} \\in S\\) is a local minimizer of \\(f:S \\rightarrow \\mathbb{R}\\) if there exists a neighborhood \\(T \\subseteq S\\) containing \\(\\mathbf{z}\\) such that \\(\\mathbf{z}\\) is a global minimizer of \\(f\\) on \\(T\\).\n\n\n\nIt’s ok if you don’t know what it means for a set to be closed – all the convex functions we will care about in this class will either be defined on sets where this theorem holds or will be otherwise defined so that the conclusions apply.\n\n\n\n\n\n\nNote\n\n\n\n\nTheorem 1 (Properties of Convex Functions) Let \\(f:S \\rightarrow \\mathbb{R}\\) be a convex function. Then:\n\nIf \\(S\\) is closed and bounded, \\(f\\) has a minimizer \\(\\mathbf{z}^*\\) in \\(S\\).\nFurthermore, if \\(\\mathbf{z}^*\\) is a local minimizer of \\(f\\), then it is also a global minimizer.\nIf in addition \\(f\\) is strictly convex, then this minimizer is unique.\n\n\n\n\n\nProof. The proof of item 1 needs some tools from real analysis. The short version is:\n\nEvery convex function is continuous.\nIf \\(S\\subseteq \\mathbb{R}^n\\) is closed and bounded, then it is compact.\nContinuous functions achieve minimizers and maximizers on compact sets.\n\nIt’s ok if you didn’t follow this! Fortunately the second part of the proof is one we can do together. Suppose to contradiction that \\(\\mathbf{z}^*\\) is a local minimizer of \\(f\\), but that there is also a point \\(\\mathbf{z}'\\) such that \\(f(\\mathbf{z}') &lt; f(\\mathbf{z}^*)\\). Since \\(\\mathbf{z}^*\\) is a local minimizer, we can find some neighborhood \\(T\\) containing \\(\\mathbf{z}^*\\) such that \\(\\mathbf{z}^*\\) is a minimizer of \\(f\\) on \\(T\\). Let \\(\\lambda\\) be some very small number and consider the point \\(\\mathbf{z} = \\lambda \\mathbf{z}' + (1-\\lambda)\\mathbf{z}^*\\). Specifically, choose \\(\\lambda\\) small enough so that \\(\\mathbf{z} \\in T\\) (since this makes \\(\\mathbf{z}\\) close to \\(\\mathbf{z}^*\\)). We can evaluate\n\\[\n\\begin{align}\nf(\\mathbf{z}) &= f(\\lambda \\mathbf{z}' + (1-\\lambda)\\mathbf{z}^*) &\\quad \\text{(definition of $\\mathbf{z}$)}\\\\\n       &\\leq \\lambda f(\\mathbf{z}') + (1-\\lambda)f(\\mathbf{z}^*)  &\\quad \\text{($f$ is convex)} \\\\\n       &= f(\\mathbf{z}^*) + \\lambda (f(\\mathbf{z}') - f(\\mathbf{z}^*)) &\\quad \\text{(algebra)}\\\\\n       &&lt; f(\\mathbf{z}^*)\\;. &\\quad \\text{(assumption that $f(\\mathbf{z}') &lt; f(\\mathbf{z}^*)$)}\n\\end{align}\n\\]\nBut this is a contradiction, since we constructed \\(\\mathbf{z}\\) to be in the neighborhood \\(T\\) where \\(\\mathbf{z}^*\\) is a local minimizer. We conclude that there is no \\(\\mathbf{z}'\\) such that \\(f(\\mathbf{z}') &lt; f(\\mathbf{z}^*)\\), and therefore that \\(\\mathbf{z}^*\\) is a global minimizer.\nThe proof of the third part follows a very similar argument to the proof of the second part.\n\nThese properties of convex functions have very important implications for our fundamental questions on empirical risk minimization. If we choose a strictly convex per-observation loss function \\(\\ell\\), then our empirical risk \\(L\\) will also be strictly convex, and:\nExistence. The minimizer \\(\\hat{\\mathbf{w}} = \\argmin_{\\mathbf{w}}L(\\mathbf{w})\\) will exist.\nUniqueness: The minimizer \\(\\hat{\\mathbf{w}} = \\argmin_{\\mathbf{w}}L(\\mathbf{w})\\) will be unique: if we run a minimization algorithm repeatedly, we’ll get the same answer every time.\nSearchability: When \\(L\\) is convex, there are also no local minimizers other than the global minimizer. Algorithmically, this is the most important property of convexity. It means that if I manage to find any local minimizer at all, that point must be the global minimizer.  Performance: Convexity significantly reduces the difficulty of our task: instead of trying to find “the best” solution, it’s sufficient for us to find any local optimum. This means that we can design our algorithms to be “greedy local minimizer hunters.” There are lots of fast algorithms to do this. An especially important class of algorithms are gradient descent methods, which we’ll discuss soon.If you’ve taken an algorithms class, one way of thinking of convexity is that it guarantees that greedy methods work for solving minimization problems."
  },
  {
    "objectID": "ClassNotes/22-convex-erm.html#demo-logistic-regression",
    "href": "ClassNotes/22-convex-erm.html#demo-logistic-regression",
    "title": "Convex Empirical Risk Minimization",
    "section": "",
    "text": "You may have heard of logistic regression in a course on statistics or data science. Logistic regression is simply binary classification using a linear model and the binary cross-entropy loss function which we saw above:\n\\[\n\\begin{aligned}\n\\ell(s, y) &=  -y \\log \\sigma(s) - (1-y)\\log (1-\\sigma(s))\\;,\n\\end{aligned}\n\\]\nAs can be proven with calculus, this function is convex as a function of \\(s\\). The logistic regression problem then becomes the problem of solving:\n\\[\n\\begin{aligned}\n\\hat{\\mathbf{w}} &= \\argmin_\\mathbf{w} \\frac{1}{n} \\sum_{i = 1}^n \\ell(s_i, y_i)  \\\\\n&= \\argmin_\\mathbf{w} \\frac{1}{n} \\sum_{i = 1}^n \\left[-y_i \\log \\sigma(s_i) - (1-y_i)\\log (1-\\sigma(s_i))\\right] \\\\\n&= \\argmin_\\mathbf{w} \\frac{1}{n} \\sum_{i = 1}^n \\left[-y_i \\log \\sigma(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle) - (1-y_i)\\log (1-\\sigma(\\langle \\mathbf{w}, \\mathbf{x}_i \\rangle)\\right]\n\\end{aligned}\n\\]\nSo, let’s do convex empirical risk minimization! We’ll use the following data set. Note that this data is not linearly separable and therefore the perceptron algorithm would not converge.\n\n\nCode\nfig, ax = plt.subplots(1, 1)\nX, y = classification_data(noise = 0.5)\nplot_classification_data(X, y, ax)\n\n\n\n\n\n\n\n\nFigure 8: Data for logistic regression.\n\n\n\n\n\nLet’s go ahead and train a logistic regression model. For the purposes of today, we can do this in a very simple way that doesn’t even involve an explicit training loop. Next time, we’ll learn how to write an explicit training loop.\nFirst, we’ll define a complete function for calculating the empirical risk for a given value of \\(\\mathbf{w}\\). Since we already implemented binary_cross_entropy, this implementation is very quick:\n\ndef empirical_risk(w, X, y):\n    s = X@w #scores of feature matrix and weight vector w\n    return binary_cross_entropy(s, y).mean() # call on scores (s) and target vector y\n\nNow we’ll use the minimize function from scipy.optimize to find the value of \\(\\mathbf{w}\\) that makes this function smallest:\n\nfrom scipy.optimize import minimize #finds best w behind the scenes\n\nw0 = torch.tensor([1.0, 1.0, 1.0]) #initial guess\n#find w that minimizes impirical risk\nresult = minimize(lambda w: empirical_risk(w, X, y), x0 = w0)\nw = result.x\n\nprint(f\"\"\"Learned parameter vector w = {w}.\nThe empirical risk is {result.fun:.4f}.\"\"\")\n\nLearned parameter vector w = [ 4.09011877  4.18886441 -3.84455342].\nThe empirical risk is 0.1755.\n\n\nHow does it look?\n\n\nCode\ndef draw_line(w, X, y, x_min, x_max, ax, **kwargs):\n    fig, ax = plt.subplots(1, 1)\n    plot_classification_data(X, y, ax)\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w[0]*x + w[2])/w[1]\n    l = ax.plot(x, y, **kwargs)\n\ndraw_line(w, X, y, x_min = -0.5, x_max = 1.5, ax = ax, color = \"black\", linestyle = \"dashed\")\n\n# fig\n\n\n\n\n\n\n\n\nFigure 9: The separating line learned by logistic regression.\n\n\n\n\n\nPretty good! Yes, it’s as easy as that – provided that you don’t ask too many questions about how the minimize function works. Questions like that will be the topic of our next several sets of notes."
  },
  {
    "objectID": "ClassNotes/22-convex-erm.html#recap",
    "href": "ClassNotes/22-convex-erm.html#recap",
    "title": "Convex Empirical Risk Minimization",
    "section": "",
    "text": "In this set of notes, we introduced a fundamental idea: convex empirical risk minimization. To do convex empirical risk minimization, all we need is a convex per-observation loss function. This gives us a convex empirical risk function, which is simply the mean of all the per-observation losses. Once we have that, the problem of classification reduces to the problem of finding a value of the parameter vector \\(\\mathbf{w}\\) that makes the empirical risk small. Convexity guarantees that this problem has exactly one solution. Today, we found this solution using a packaged optimizer. Starting next time, we’ll learn how to write our own optimization algorithms and explore how optimization techniques enable scalable machine learning.\n\n\nHow would we do this if we didn’t have access to the minimize function? We’ll soon discuss this question much more. For now, we can take a look at the code block below, which implements such a loop using a framework very similar to the one we learned for perceptron. This model also inherits from the LinearModel class that you previously started implementing. The training loop is also very similar to our training loop for the perceptron. The main difference is that the loss is calculated using the binary_cross_entropy function above, and the step function of the GradientDescentOptimizer works differently in a way that we will discuss in the following section.\nStarting with the code block below, you won’t be able to follow along in coding these notes unless you have sneakily implemented logistic regression in a hidden module.\n\n\n\nfrom hidden.logistic import LogisticRegression, GradientDescentOptimizer\n\n# instantiate a model and an optimizer\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\n# for keeping track of loss values\nloss_vec = []\n\nfor _ in range(100):\n\n    # not part of the update: just for tracking our progress    \n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n\n    # only this line actually changes the parameter value\n    opt.step(X, y, lr = 0.02)\n\nplt.plot(torch.arange(1, len(loss_vec)+1), loss_vec, color = \"black\")\nplt.semilogx()\nlabs = plt.gca().set(xlabel = \"Number of gradient descent iterations\", ylabel = \"Loss (binary cross entropy)\")\n\n\nFigure 10\n\n\n\nThe loss quickly levels out to a constant value (which is the same as we learned with scipy.optimize.minimize). Because our theory tells us that the loss function is convex, we know that the value of \\(\\mathbf{w}\\) we have found is the best possible, in the sense of minimizing the loss.\nLet’s take a look at the separating line we found:\n\ndraw_line(LR.w, X, y, \n          x_min = -0.5, \n          x_max = 1.5, \n          ax = ax, \n          color = \"black\", \n          linestyle = \"dashed\")\n\nYep, that’s the same line as we found earlier!\nAlthough our data is not linearly separable, the separating line we have learned appears to do a reasonable job of separating the points from each other. Let’s check our accuracy:\nNot too bad! In the next section, we’ll learn much, much more about what’s behind that opt.step() call."
  },
  {
    "objectID": "ClassNotes/goal-setting.html",
    "href": "ClassNotes/goal-setting.html",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Daniela Delgado\n\n\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI would really like to grow in the implementation and social responsibility areas as these are where my interests lie. I want to understand machine learning algorithms and be able to compare algorithms to know which ones work better for certain tasks. Additionally, even with this great technology, it falls in our hands to be able to go against biases and for these models to be ethical. As a POC woman in STEM, I am aware of the discrimination, stereotypes, and limitations women and people of color face in the field. Thus, I would like to understand where the faults lie in machine learning and be able to learn and think about ways to eliminate/improve the biases to avoid them growing through and because of technology.\n\n\n\n\n\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nFor the blog posts, I want to achieve at least five “No Revisions Suggested” posts and at least one post for each of the sections, except at least two for “Implementation” and “Social Responsibility” as these are the topics that most interest me.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions. We will also have a special opportunity this semester to engage with a renowned expert in machine learning, algorithmic bias, and the ethics of artificial intelligence.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI would like to use the “pass” option at most two times during the semester when it is my turn to present. Additionally, I would like to ask questions to whoever is presenting the warmup when I need more clarification, which might be often. I often struggle to ask questions out loud, so I hope this creates an added incentive for me to ask others for clarifying help. I will also attend student/peer help hours at least twice a week to ask clarifying/curious questions over the material. If there is a study group, I would like to attend a session (once a week at least if it is helpful the first time). I will complete all core readings prior to each class periods and take notes on them.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI will submit all of the project milestones on time. Additionally, when working in the group, we will set a regular time each week, multiple times a week as needed, to work with the group on the project. I will also communicate with my group in a clear and timely manner. I will write the sections assigned to me for the project report and present the portion assigned to me for the final presentation.\nThe topics I would like to explore in a project would be making predictions, classifying music or items, or a recognition projection (such as music or emotions or an image recognition)."
  },
  {
    "objectID": "ClassNotes/goal-setting.html#what-youll-learn",
    "href": "ClassNotes/goal-setting.html#what-youll-learn",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "The knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI would really like to grow in the implementation and social responsibility areas as these are where my interests lie. I want to understand machine learning algorithms and be able to compare algorithms to know which ones work better for certain tasks. Additionally, even with this great technology, it falls in our hands to be able to go against biases and for these models to be ethical. As a POC woman in STEM, I am aware of the discrimination, stereotypes, and limitations women and people of color face in the field. Thus, I would like to understand where the faults lie in machine learning and be able to learn and think about ways to eliminate/improve the biases to avoid them growing through and because of technology."
  },
  {
    "objectID": "ClassNotes/goal-setting.html#what-youll-achieve",
    "href": "ClassNotes/goal-setting.html#what-youll-achieve",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Most blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nFor the blog posts, I want to achieve at least five “No Revisions Suggested” posts and at least one post for each of the sections, except at least two for “Implementation” and “Social Responsibility” as these are the topics that most interest me.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions. We will also have a special opportunity this semester to engage with a renowned expert in machine learning, algorithmic bias, and the ethics of artificial intelligence.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI would like to use the “pass” option at most two times during the semester when it is my turn to present. Additionally, I would like to ask questions to whoever is presenting the warmup when I need more clarification, which might be often. I often struggle to ask questions out loud, so I hope this creates an added incentive for me to ask others for clarifying help. I will also attend student/peer help hours at least twice a week to ask clarifying/curious questions over the material. If there is a study group, I would like to attend a session (once a week at least if it is helpful the first time). I will complete all core readings prior to each class periods and take notes on them.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI will submit all of the project milestones on time. Additionally, when working in the group, we will set a regular time each week, multiple times a week as needed, to work with the group on the project. I will also communicate with my group in a clear and timely manner. I will write the sections assigned to me for the project report and present the portion assigned to me for the final presentation.\nThe topics I would like to explore in a project would be making predictions, classifying music or items, or a recognition projection (such as music or emotions or an image recognition)."
  },
  {
    "objectID": "ClassNotes/12-statistical-fairness.html",
    "href": "ClassNotes/12-statistical-fairness.html",
    "title": "Statistical Definitions of Fairness in Decision-Making",
    "section": "",
    "text": "In these notes, we’ll review three fundamental definitions of fairness for decision-making systems. While texts like @barocasFairnessMachineLearning2023 couch their definitions in the language of probability, our focus in these notes will be to relate the formal mathematical language to operational computations on data sets in Python. In doing so, we’ll review some computational techniques via pandas, numpy, and seaborn from last time. After reviewing these definitions, we’ll review a simple, famous result about the ability of decision systems to satisfy multiple definitions.\nFor this study, we’ll return to the COMPAS data that we studied last time.\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nsns.set_style(\"whitegrid\")\nnp.set_printoptions(precision = 3)\npd.set_option('display.precision', 3)\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/compas/compas.csv\"\ncompas = pd.read_csv(url)\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\nFor this discussion, we again only need to consider a subset of the columns, and we’ll focus exclusively on white (Caucasian) and Black (African-American) defendants:\n\ncols = [\"sex\", \"race\", \"decile_score\", \"two_year_recid\"]\ncompas = compas[cols]\n\n# using Angwin's definition\ncompas[\"predicted_high_risk\"] = 1*(compas[\"decile_score\"] &gt; 4)\n\n\nis_white = compas[\"race\"] == \"Caucasian\"\nis_black = compas[\"race\"] == \"African-American\"\n\ncompas = compas[is_white | is_black]\ncompas = compas.copy()\n\n# excerpt of the data\n\ncompas\n\n\n\n\n\n\n\n\nsex\nrace\ndecile_score\ntwo_year_recid\npredicted_high_risk\n\n\n\n\n1\nMale\nAfrican-American\n3\n1\n0\n\n\n2\nMale\nAfrican-American\n4\n1\n0\n\n\n3\nMale\nAfrican-American\n8\n0\n1\n\n\n6\nMale\nCaucasian\n6\n1\n1\n\n\n8\nFemale\nCaucasian\n1\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n\n\n7207\nMale\nAfrican-American\n2\n1\n0\n\n\n7208\nMale\nAfrican-American\n9\n0\n1\n\n\n7209\nMale\nAfrican-American\n7\n0\n1\n\n\n7210\nMale\nAfrican-American\n3\n0\n0\n\n\n7212\nFemale\nAfrican-American\n2\n0\n0\n\n\n\n\n6150 rows × 5 columns\n\n\n\n\n\nLast time, we introduced the idea that fairness in decision-making could be defined formally, and models could be audited to determine the extent to which those models conformed to a given definition. In this section, we’ll discuss some of the definitions in Chapter 3 of @barocasFairnessMachineLearning2023 and implement Python functions to measure the extent to which the COMPAS risk score conforms to those definitions.\nTo line ourselves up with the notation of @barocasFairnessMachineLearning2023, let’s define the following random variables: Let \\(A\\) be a random variable that describes the group membership of an individual. Let \\(Y\\) be the outcome we want to predict. Let \\(R\\) be the value of our risk score. Let \\(\\hat{Y}\\) be our model’s prediction about whether \\(Y\\) occurs.\nIn the case of COMPAS:\n\n\\(A\\) is the race of the individual (racial group of defendant), with possible values \\(A = a\\) and \\(A = b\\).\n\\(Y = 1\\) if the individual was arrested within two years after release, and \\(Y = 0\\) if not.\n\\(R\\) is the decile risk score.\n\\(\\hat{Y} = 1\\) if \\(R &gt; 4\\) and \\(\\hat{Y} = 0\\) otherwise.\n\nAcceptance rate parity (\\(\\hat{Y}\\)) is independednt from A Probability of getting a positive prediction (\\(\\hat{Y} = 1\\)) given A=a equals probability((\\(\\hat{Y} = 1\\)) given A=b)\n\n\nHere’s our first concept of fairness: independence. For our present purposes, we focus on the definition of independence for binary classifiers as given by @barocasFairnessMachineLearning2023.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 1 (Statistical Independence For Binary Classifiers)  The model predictions \\(\\hat{Y}\\) satisfy statistical independence if \\(\\mathbb{P}(\\hat{Y} = 1 | A = a) = {P}(\\hat{Y} = 1 | A = b)\\).\n\n\n\nRecall that \\(\\mathbb{P}(Y = 1|A = a)\\) is the probability that \\(Y = 1\\) given that \\(A=a\\). It can be computed using the formula \\(\\mathbb{P}(Y = 1|A = a) = \\frac{\\mathbb{P}(Y = 1, A = a)}{\\mathbb{P}(A = a)}\\).Colloquially, Definition 1 says that the probability of a positive prediction \\(\\hat{Y} = 1\\) does not depend on the group membership \\(A\\). In the COMPAS data, independence would require that the probability of the model predicting that an individual will be arrested within two years be the same for Black and white defendants.\nLet’s write a Python function to empirically check independence that will accept a data frame df and three additional arguments:\nFor independence, we don’t actually need the target column, but this approach will let us keep a consistent API for our more complicated implementations below.\n\ngroup_col, the name of the column describing group memberships.\ntarget, the name of the column holding the binary outcomes.\npred, the name of the column holding the predicted binary outcomes.\n\n\ndef test_independence(df, group_col, target, pred):\n    return df.groupby(group_col)[pred].aggregate([np.mean, len])\n\nLet’s run our function to check for independence:\n\ntest_independence(compas, \"race\", \"two_year_recid\", \"predicted_high_risk\")\n#acceptance rates are not the same--&gt; no statistical independence\n\n/var/folders/1j/mlsnh9t96n70j2n5mmm9h9780000gn/T/ipykernel_10489/3597676542.py:2: FutureWarning: The provided callable &lt;function mean at 0x7fe7108b6ee0&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  return df.groupby(group_col)[pred].aggregate([np.mean, len])\n\n\n\n\n\n\n\n\n\nmean\nlen\n\n\nrace\n\n\n\n\n\n\nAfrican-American\n0.588\n3696\n\n\nCaucasian\n0.348\n2454\n\n\n\n\n\n\n\nThe mean column gives the proportion of the time in which the predictor \\(\\hat{Y}\\) had value equal to 1, for each of the two groups. This is an empirical estimate of the probability \\(\\mathbb{P}(\\hat{Y} = 1 | A = a)\\). We can see that the two proportions are substantially different between groups, strongly suggesting that this model violates the independence criterion. Formally, statistical tests beyond the scope of this course would be needed to reject the hypothesis that the two proportions are different. In this case, you can take my word for it that the relevant test provides strong support for rejecting the null.\nAs discussed in @barocasFairnessMachineLearning2023, independence is a very strong expression of the idea that predictions, and therefore automated decisions, should be the same in aggregate across all groups present in the data. This idea sometimes accompanies another idea, that all groups are equally worthy, meritorious, or deserving of a given decision outcome.\n\n\n\n The primary finding of @angwin2022machine was, famously, that the COMPAS algorithm makes very different kinds of errors on Black and white defendants.This definition can be generalized from binary classifiers to score functions via the concept of separation, which is discussed in @barocasFairnessMachineLearning2023.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 2 (Error Rate Balance for Binary Classifiers) The model predictions \\(\\hat{Y}\\) satisfy error-rate balance if the following conditions both hold:\n\\[\n\\begin{aligned}\n    \\mathbb{P}(\\hat{Y} = 1 | Y = 1, A = a) &= \\mathbb{P}(\\hat{Y} =1  | Y = 1, A = b) & \\text{(balanced true positives/false negative rate)} \\\\\n    \\mathbb{P}(\\hat{Y} = 1 | Y = 0, A = a) &= \\mathbb{P}(\\hat{Y} =1  | Y = 0, A = b)\\;. & \\text{(balanced false positives/false positive rate)}\n\\end{aligned}\n\\]\n\n\n\nError rate balance requires that the true positive rate and false positive rates be equal on the two groups. Given some data in which we have \\(\\mathrm{TP}\\) instances of true positives, \\(\\mathrm{FP}\\) instances of false positives, \\(\\mathrm{TN}\\) instances of true negatives, and \\(\\mathrm{FN}\\) instances of false negatives, we can estimate the TPR and FPR via the formulas\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} \\\\  \n    \\mathrm{FPR} &= \\frac{\\mathrm{FP}}{\\mathrm{FP} + \\mathrm{TN}}\\\\\n    \\mathrm{FNR} &= \\frac{\\mathrm{FN}}{\\mathrm{TP} + \\mathrm{FN}} = 1 - TPR\\;.\n\\end{aligned}\n\\]\nLet’s write another function with the same API to give a summary of error rates between two groups using these formulas. As we know, it’s pretty convenient to do this with confusion matrices. It’s not much more difficult to do it “by hand” using vectorized Pandas computations:\n\ndef test_error_rate_balance(df, group_col, target, pred):\n    return df.groupby([group_col, target])[pred].mean().reset_index()\n\nWe can use this function to do an empirical test for error rate balance:\n\ntest_error_rate_balance(compas, 'race', 'two_year_recid', 'predicted_high_risk')\n\n\n\n\n\n\n\n\nrace\ntwo_year_recid\npredicted_high_risk\n\n\n\n\n0\nAfrican-American\n0\n0.448\n\n\n1\nAfrican-American\n1\n0.720\n\n\n2\nCaucasian\n0\n0.235\n\n\n3\nCaucasian\n1\n0.523\n\n\n\n\n\n\n\n The false positive rates are in the rows in which two_year_recid == 0, and the true positive rates are in the rows in which two_year_recid == 1.As before, before concluding that the COMPAS algorithm violates error rate balance as in Definition 2, it is technically necessary to perform a statistical test to reject the null hypothesis that the true population error rates are the same.\n\n\n\nFinally, as we mentioned last time, the analysis of @angwin2022machine received heavy pushback from @flores2016false and others, who argued that error rate balance wasn’t really the right thing to measure. Instead, we should check sufficiency, which we’ll define here for binary classifiers:\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 3 (Sufficiency) Model predictions \\(\\hat{Y}\\) satisfy sufficiency if the following two conditions hold: \\[\n\\begin{aligned}\n    \\mathbb{P}(Y = 1 | \\hat{Y} = 1, A = a) &= \\mathbb{P}(Y = 1 | \\hat{Y} = 1, A = b) = \\\\\n\\end{aligned}\n\\] = (prob of positive outcome given a positive prediction, does not depend on the group label) \\[\n\\begin{aligned}\n    \\mathbb{P}(Y = 0 | \\hat{Y} = 0, A = a) &= \\mathbb{P}(Y = 0 | \\hat{Y} = 0, A = b) = \\;\n\\end{aligned}\n\\] = (prob of seeing a negative outcome given a negative predition, and how does that vary between groups).\n\n\n\nThe quantity \\(\\mathbb{P}(Y = 1 | \\hat{Y} = 1, A = a)\\) is sometimes called the positive predictive value (PPV) of \\(\\hat{Y}\\) for group \\(a\\). You can think of it as the “value” of a positive prediction: given that the prediction is positive (\\(\\hat{Y} = 1\\)) for a member of group \\(a\\), how likely is it that the prediction is accurate? Similarly, \\(\\mathbb{P}(Y = 0 | \\hat{Y} = 0, A = a)\\) is sometimes called the negative predictive value (NPV) of \\(\\hat{Y}\\) for group \\(a\\). So, the sufficiency criterion demands that the positive and negative predictive values be equal across groups.\nGiven some data in which we have \\(\\mathrm{TP}\\) instances of true positives, \\(\\mathrm{FP}\\) instances of false positives, \\(\\mathrm{TN}\\) instances of true negatives, and \\(\\mathrm{FN}\\) instances of false negatives, we can estimate the PPV and NPV via the formulas\n\\[\n\\begin{aligned}\n    \\mathrm{PPV} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}} \\\\  \n    \\mathrm{NPV} &= \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FN}}\\;.\n\\end{aligned}\n\\]\nLet’s write a function to check for sufficiency in the COMPAS predictions. This function will compute the positive and negative predictive values by group:\n\ndef test_sufficiency(df, group_col, target, pred):\n    df_ = df.copy() #avoid python warning\n    df_['correct'] = df_[pred] == df_[target]\n    return df_.groupby([pred, group_col])['correct'].mean().reset_index()\n\n\ntest_sufficiency(compas, \"race\", \"two_year_recid\", \"predicted_high_risk\")\n#still bad, but slightly better. they are closer.\n\n\n\n\n\n\n\n\npredicted_high_risk\nrace\ncorrect\n\n\n\n\n0\n0\nAfrican-American\n0.650\n\n\n1\n0\nCaucasian\n0.712\n\n\n2\n1\nAfrican-American\n0.630\n\n\n3\n1\nCaucasian\n0.591\n\n\n\n\n\n\n\n\ncompas.groupby('race')['two_year_recid'].mean()\n#cannot have it all mathematically. have to choose what our definition of fairness is\n#can't just math it. we have to make a moral and political choice on which definition of fairness you want\n\nrace\nAfrican-American    0.514\nCaucasian           0.394\nName: two_year_recid, dtype: float64\n\n\nThe negative predictive values are in the rows in which predicted_high_risk == 0 and the positive predictive values are in the rows in which predicted_high_risk == 1. We observe that the negative predictive value is slightly higher for white defendants, while the positive predictive value is slightly higher for Black defendants. These differences, however, are much lower than the error rate disparity noted above.\n\n\n\n\nOk, well COMPAS isn’t an ideal algorithm by any means. But couldn’t we just define some more conceptions of fairness, pick the ones that we wanted to use, and then design an algorithm that satisfied all of them?\nSadly, no: we can’t even have error rate balance and sufficiency simultaneously.\n\n\n\n\n\n\nTip\n\n\n\n\nTheorem 1 (Incompatibility of Error Rate Balance and Sufficiency [@chouldechovaFairPredictionDisparate2017a]) If the true rates \\(p_a\\) and \\(p_b\\) of positive outcomes in the groups \\(a\\) and \\(b\\) are not equal (\\(p_a \\neq p_b\\)), then there does not exist a model that produces predictions which satisfy both error rate balance and sufficiency.\n\n\n\n\nProof. Our big-picture approach is proof by contrapositive. We’ll show that if there were a model that satisfied error rate balance and sufficiency, then \\(p_a = p_b\\).\nLet’s briefly forget about group labels – we’ll reintroduce them in a moment.\nFirst, the prevalence of positive outcomes is the fraction of positive outcomes. There are \\(\\mathrm{TP} + \\mathrm{FN}\\) total positive outcomes, and \\(\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}\\) outcomes overal, so we can write the prevalence as\n\\[\n\\begin{aligned}\n    p = \\frac{\\mathrm{TP} + \\mathrm{FN}}{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}};.\n\\end{aligned}\n\\]\nFrom above, the true and false positive rates are:\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} \\\\\n    \\mathrm{FPR} &= \\frac{\\mathrm{FP}}{\\mathrm{FP} + \\mathrm{TN}}\\;.  \n\\end{aligned}\n\\]\nThe PPV is: \\[\n\\begin{aligned}\n    \\mathrm{PPV} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}}\\;.\n\\end{aligned}\n\\]\nOk, now it’s time to do some algebra. Let’s start with the \\(\\mathrm{TPR}\\) and see if we can find an equation that relates it to the \\(\\mathrm{FPR}\\). First, we’ll multiply by \\(\\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\). If we do this and insert the definitions of these quantities, we’ll get\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FP}} \\frac{\\mathrm{TP} + \\mathrm{FP}}{\\mathrm{TP}} \\\\\n    &= \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FN}}\\;.\n\\end{aligned}\n\\]\nLet’s now also multiply by a factor of \\(\\frac{p}{1-p}\\):\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\frac{p}{1-p} &= \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FN}}\\frac{p}{1-p} \\\\\n    &= \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FN}} \\frac{\\mathrm{TP} + \\mathrm{FN}}{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}} \\frac{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}}{\\mathrm{FP} + \\mathrm{TN}} \\\\\n    &= \\frac{\\mathrm{FP}}{\\mathrm{FP} + \\mathrm{TN}} \\\\\n    &= \\mathrm{FPR}\\;.\n\\end{aligned}\n\\]\nSo, with some algebra, we have proven an equation for any classifier:\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\frac{p}{1-p} = \\mathrm{FPR}\\;.\n\\end{aligned}\n\\]\nIt’s convenient to rearrange this equation slightly:\n\\[\n\\begin{aligned}\n    \\frac{\\mathrm{TPR}}{\\mathrm{FPR}} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}} = \\frac{1-p}{p}\\;.\n\\end{aligned}\n\\]\nor\n\\[\n\\begin{aligned}\n    p = \\left(1 + \\frac{\\mathrm{TPR}}{\\mathrm{FPR}} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\right)^{-1}\\;.\n\\end{aligned}\n\\tag{1}\\]\nNow suppose that I want to enforce error rate balance and sufficiency for two groups \\(a\\) and \\(b\\), where \\(p_a \\neq p_b\\). So, from error rate balance I am going to require that \\(\\mathrm{TPR}_a = \\mathrm{TPR}_b\\), \\(\\mathrm{FPR}_a = \\mathrm{FPR}_b\\), and from sufficiency I am going to enforce that \\(\\mathrm{PPV}_a = \\mathrm{PPV}_b\\). Now, however, we have a problem: by Equation 1, it must also be the case that \\(p_a = p_b\\). This contradicts our assumption from the theorem. We cannot mathematically satisfy both error rate balance and sufficiency. This completes the proof.\n\n\n\n\n\n\n\nDiscussion\n\n\n\nDo you feel that it is more important for a recidivism prediction algorithm like COMPAS to satisfy error rate balance or sufficiency? Why?\n\n\n\n\n\nThe proof above shows that, when the prevalences of positive outcomes differ between groups, we have no hope of being able to have both balanced error rates and sufficiency. In Chapter 3, @barocasFairnessMachineLearning2023 give a few other examples of fairness definitions, as well as proofs that some of these definitions are incompatible with each other. We can’t just have it all – we have to choose.\nThe quantitative story of fairness in automated decision-making is not cut-and-dried – we need to make choices, which may be subject to politics. Let’s close this discussion with three increasingly difficult questions:\n\nWhat is the right definition of fairness by which to judge the operation of a decision-making algorithm?\nIs “fairness” even the right rubric for assessing the impact of a given algorithm?\nIs it legitimate to use automated decision-making at all for a given application context?\n\nWe’ll consider each of these questions soon."
  },
  {
    "objectID": "ClassNotes/12-statistical-fairness.html#three-statistical-definitions-of-fairness",
    "href": "ClassNotes/12-statistical-fairness.html#three-statistical-definitions-of-fairness",
    "title": "Statistical Definitions of Fairness in Decision-Making",
    "section": "",
    "text": "Last time, we introduced the idea that fairness in decision-making could be defined formally, and models could be audited to determine the extent to which those models conformed to a given definition. In this section, we’ll discuss some of the definitions in Chapter 3 of @barocasFairnessMachineLearning2023 and implement Python functions to measure the extent to which the COMPAS risk score conforms to those definitions.\nTo line ourselves up with the notation of @barocasFairnessMachineLearning2023, let’s define the following random variables: Let \\(A\\) be a random variable that describes the group membership of an individual. Let \\(Y\\) be the outcome we want to predict. Let \\(R\\) be the value of our risk score. Let \\(\\hat{Y}\\) be our model’s prediction about whether \\(Y\\) occurs.\nIn the case of COMPAS:\n\n\\(A\\) is the race of the individual (racial group of defendant), with possible values \\(A = a\\) and \\(A = b\\).\n\\(Y = 1\\) if the individual was arrested within two years after release, and \\(Y = 0\\) if not.\n\\(R\\) is the decile risk score.\n\\(\\hat{Y} = 1\\) if \\(R &gt; 4\\) and \\(\\hat{Y} = 0\\) otherwise.\n\nAcceptance rate parity (\\(\\hat{Y}\\)) is independednt from A Probability of getting a positive prediction (\\(\\hat{Y} = 1\\)) given A=a equals probability((\\(\\hat{Y} = 1\\)) given A=b)\n\n\nHere’s our first concept of fairness: independence. For our present purposes, we focus on the definition of independence for binary classifiers as given by @barocasFairnessMachineLearning2023.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 1 (Statistical Independence For Binary Classifiers)  The model predictions \\(\\hat{Y}\\) satisfy statistical independence if \\(\\mathbb{P}(\\hat{Y} = 1 | A = a) = {P}(\\hat{Y} = 1 | A = b)\\).\n\n\n\nRecall that \\(\\mathbb{P}(Y = 1|A = a)\\) is the probability that \\(Y = 1\\) given that \\(A=a\\). It can be computed using the formula \\(\\mathbb{P}(Y = 1|A = a) = \\frac{\\mathbb{P}(Y = 1, A = a)}{\\mathbb{P}(A = a)}\\).Colloquially, Definition 1 says that the probability of a positive prediction \\(\\hat{Y} = 1\\) does not depend on the group membership \\(A\\). In the COMPAS data, independence would require that the probability of the model predicting that an individual will be arrested within two years be the same for Black and white defendants.\nLet’s write a Python function to empirically check independence that will accept a data frame df and three additional arguments:\nFor independence, we don’t actually need the target column, but this approach will let us keep a consistent API for our more complicated implementations below.\n\ngroup_col, the name of the column describing group memberships.\ntarget, the name of the column holding the binary outcomes.\npred, the name of the column holding the predicted binary outcomes.\n\n\ndef test_independence(df, group_col, target, pred):\n    return df.groupby(group_col)[pred].aggregate([np.mean, len])\n\nLet’s run our function to check for independence:\n\ntest_independence(compas, \"race\", \"two_year_recid\", \"predicted_high_risk\")\n#acceptance rates are not the same--&gt; no statistical independence\n\n/var/folders/1j/mlsnh9t96n70j2n5mmm9h9780000gn/T/ipykernel_10489/3597676542.py:2: FutureWarning: The provided callable &lt;function mean at 0x7fe7108b6ee0&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  return df.groupby(group_col)[pred].aggregate([np.mean, len])\n\n\n\n\n\n\n\n\n\nmean\nlen\n\n\nrace\n\n\n\n\n\n\nAfrican-American\n0.588\n3696\n\n\nCaucasian\n0.348\n2454\n\n\n\n\n\n\n\nThe mean column gives the proportion of the time in which the predictor \\(\\hat{Y}\\) had value equal to 1, for each of the two groups. This is an empirical estimate of the probability \\(\\mathbb{P}(\\hat{Y} = 1 | A = a)\\). We can see that the two proportions are substantially different between groups, strongly suggesting that this model violates the independence criterion. Formally, statistical tests beyond the scope of this course would be needed to reject the hypothesis that the two proportions are different. In this case, you can take my word for it that the relevant test provides strong support for rejecting the null.\nAs discussed in @barocasFairnessMachineLearning2023, independence is a very strong expression of the idea that predictions, and therefore automated decisions, should be the same in aggregate across all groups present in the data. This idea sometimes accompanies another idea, that all groups are equally worthy, meritorious, or deserving of a given decision outcome.\n\n\n\n The primary finding of @angwin2022machine was, famously, that the COMPAS algorithm makes very different kinds of errors on Black and white defendants.This definition can be generalized from binary classifiers to score functions via the concept of separation, which is discussed in @barocasFairnessMachineLearning2023.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 2 (Error Rate Balance for Binary Classifiers) The model predictions \\(\\hat{Y}\\) satisfy error-rate balance if the following conditions both hold:\n\\[\n\\begin{aligned}\n    \\mathbb{P}(\\hat{Y} = 1 | Y = 1, A = a) &= \\mathbb{P}(\\hat{Y} =1  | Y = 1, A = b) & \\text{(balanced true positives/false negative rate)} \\\\\n    \\mathbb{P}(\\hat{Y} = 1 | Y = 0, A = a) &= \\mathbb{P}(\\hat{Y} =1  | Y = 0, A = b)\\;. & \\text{(balanced false positives/false positive rate)}\n\\end{aligned}\n\\]\n\n\n\nError rate balance requires that the true positive rate and false positive rates be equal on the two groups. Given some data in which we have \\(\\mathrm{TP}\\) instances of true positives, \\(\\mathrm{FP}\\) instances of false positives, \\(\\mathrm{TN}\\) instances of true negatives, and \\(\\mathrm{FN}\\) instances of false negatives, we can estimate the TPR and FPR via the formulas\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} \\\\  \n    \\mathrm{FPR} &= \\frac{\\mathrm{FP}}{\\mathrm{FP} + \\mathrm{TN}}\\\\\n    \\mathrm{FNR} &= \\frac{\\mathrm{FN}}{\\mathrm{TP} + \\mathrm{FN}} = 1 - TPR\\;.\n\\end{aligned}\n\\]\nLet’s write another function with the same API to give a summary of error rates between two groups using these formulas. As we know, it’s pretty convenient to do this with confusion matrices. It’s not much more difficult to do it “by hand” using vectorized Pandas computations:\n\ndef test_error_rate_balance(df, group_col, target, pred):\n    return df.groupby([group_col, target])[pred].mean().reset_index()\n\nWe can use this function to do an empirical test for error rate balance:\n\ntest_error_rate_balance(compas, 'race', 'two_year_recid', 'predicted_high_risk')\n\n\n\n\n\n\n\n\nrace\ntwo_year_recid\npredicted_high_risk\n\n\n\n\n0\nAfrican-American\n0\n0.448\n\n\n1\nAfrican-American\n1\n0.720\n\n\n2\nCaucasian\n0\n0.235\n\n\n3\nCaucasian\n1\n0.523\n\n\n\n\n\n\n\n The false positive rates are in the rows in which two_year_recid == 0, and the true positive rates are in the rows in which two_year_recid == 1.As before, before concluding that the COMPAS algorithm violates error rate balance as in Definition 2, it is technically necessary to perform a statistical test to reject the null hypothesis that the true population error rates are the same.\n\n\n\nFinally, as we mentioned last time, the analysis of @angwin2022machine received heavy pushback from @flores2016false and others, who argued that error rate balance wasn’t really the right thing to measure. Instead, we should check sufficiency, which we’ll define here for binary classifiers:\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 3 (Sufficiency) Model predictions \\(\\hat{Y}\\) satisfy sufficiency if the following two conditions hold: \\[\n\\begin{aligned}\n    \\mathbb{P}(Y = 1 | \\hat{Y} = 1, A = a) &= \\mathbb{P}(Y = 1 | \\hat{Y} = 1, A = b) = \\\\\n\\end{aligned}\n\\] = (prob of positive outcome given a positive prediction, does not depend on the group label) \\[\n\\begin{aligned}\n    \\mathbb{P}(Y = 0 | \\hat{Y} = 0, A = a) &= \\mathbb{P}(Y = 0 | \\hat{Y} = 0, A = b) = \\;\n\\end{aligned}\n\\] = (prob of seeing a negative outcome given a negative predition, and how does that vary between groups).\n\n\n\nThe quantity \\(\\mathbb{P}(Y = 1 | \\hat{Y} = 1, A = a)\\) is sometimes called the positive predictive value (PPV) of \\(\\hat{Y}\\) for group \\(a\\). You can think of it as the “value” of a positive prediction: given that the prediction is positive (\\(\\hat{Y} = 1\\)) for a member of group \\(a\\), how likely is it that the prediction is accurate? Similarly, \\(\\mathbb{P}(Y = 0 | \\hat{Y} = 0, A = a)\\) is sometimes called the negative predictive value (NPV) of \\(\\hat{Y}\\) for group \\(a\\). So, the sufficiency criterion demands that the positive and negative predictive values be equal across groups.\nGiven some data in which we have \\(\\mathrm{TP}\\) instances of true positives, \\(\\mathrm{FP}\\) instances of false positives, \\(\\mathrm{TN}\\) instances of true negatives, and \\(\\mathrm{FN}\\) instances of false negatives, we can estimate the PPV and NPV via the formulas\n\\[\n\\begin{aligned}\n    \\mathrm{PPV} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}} \\\\  \n    \\mathrm{NPV} &= \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FN}}\\;.\n\\end{aligned}\n\\]\nLet’s write a function to check for sufficiency in the COMPAS predictions. This function will compute the positive and negative predictive values by group:\n\ndef test_sufficiency(df, group_col, target, pred):\n    df_ = df.copy() #avoid python warning\n    df_['correct'] = df_[pred] == df_[target]\n    return df_.groupby([pred, group_col])['correct'].mean().reset_index()\n\n\ntest_sufficiency(compas, \"race\", \"two_year_recid\", \"predicted_high_risk\")\n#still bad, but slightly better. they are closer.\n\n\n\n\n\n\n\n\npredicted_high_risk\nrace\ncorrect\n\n\n\n\n0\n0\nAfrican-American\n0.650\n\n\n1\n0\nCaucasian\n0.712\n\n\n2\n1\nAfrican-American\n0.630\n\n\n3\n1\nCaucasian\n0.591\n\n\n\n\n\n\n\n\ncompas.groupby('race')['two_year_recid'].mean()\n#cannot have it all mathematically. have to choose what our definition of fairness is\n#can't just math it. we have to make a moral and political choice on which definition of fairness you want\n\nrace\nAfrican-American    0.514\nCaucasian           0.394\nName: two_year_recid, dtype: float64\n\n\nThe negative predictive values are in the rows in which predicted_high_risk == 0 and the positive predictive values are in the rows in which predicted_high_risk == 1. We observe that the negative predictive value is slightly higher for white defendants, while the positive predictive value is slightly higher for Black defendants. These differences, however, are much lower than the error rate disparity noted above."
  },
  {
    "objectID": "ClassNotes/12-statistical-fairness.html#can-we-have-it-all",
    "href": "ClassNotes/12-statistical-fairness.html#can-we-have-it-all",
    "title": "Statistical Definitions of Fairness in Decision-Making",
    "section": "",
    "text": "Ok, well COMPAS isn’t an ideal algorithm by any means. But couldn’t we just define some more conceptions of fairness, pick the ones that we wanted to use, and then design an algorithm that satisfied all of them?\nSadly, no: we can’t even have error rate balance and sufficiency simultaneously.\n\n\n\n\n\n\nTip\n\n\n\n\nTheorem 1 (Incompatibility of Error Rate Balance and Sufficiency [@chouldechovaFairPredictionDisparate2017a]) If the true rates \\(p_a\\) and \\(p_b\\) of positive outcomes in the groups \\(a\\) and \\(b\\) are not equal (\\(p_a \\neq p_b\\)), then there does not exist a model that produces predictions which satisfy both error rate balance and sufficiency.\n\n\n\n\nProof. Our big-picture approach is proof by contrapositive. We’ll show that if there were a model that satisfied error rate balance and sufficiency, then \\(p_a = p_b\\).\nLet’s briefly forget about group labels – we’ll reintroduce them in a moment.\nFirst, the prevalence of positive outcomes is the fraction of positive outcomes. There are \\(\\mathrm{TP} + \\mathrm{FN}\\) total positive outcomes, and \\(\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}\\) outcomes overal, so we can write the prevalence as\n\\[\n\\begin{aligned}\n    p = \\frac{\\mathrm{TP} + \\mathrm{FN}}{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}};.\n\\end{aligned}\n\\]\nFrom above, the true and false positive rates are:\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} \\\\\n    \\mathrm{FPR} &= \\frac{\\mathrm{FP}}{\\mathrm{FP} + \\mathrm{TN}}\\;.  \n\\end{aligned}\n\\]\nThe PPV is: \\[\n\\begin{aligned}\n    \\mathrm{PPV} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}}\\;.\n\\end{aligned}\n\\]\nOk, now it’s time to do some algebra. Let’s start with the \\(\\mathrm{TPR}\\) and see if we can find an equation that relates it to the \\(\\mathrm{FPR}\\). First, we’ll multiply by \\(\\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\). If we do this and insert the definitions of these quantities, we’ll get\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FP}} \\frac{\\mathrm{TP} + \\mathrm{FP}}{\\mathrm{TP}} \\\\\n    &= \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FN}}\\;.\n\\end{aligned}\n\\]\nLet’s now also multiply by a factor of \\(\\frac{p}{1-p}\\):\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\frac{p}{1-p} &= \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FN}}\\frac{p}{1-p} \\\\\n    &= \\frac{\\mathrm{FP}}{\\mathrm{TP} + \\mathrm{FN}} \\frac{\\mathrm{TP} + \\mathrm{FN}}{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}} \\frac{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{TN} + \\mathrm{FN}}{\\mathrm{FP} + \\mathrm{TN}} \\\\\n    &= \\frac{\\mathrm{FP}}{\\mathrm{FP} + \\mathrm{TN}} \\\\\n    &= \\mathrm{FPR}\\;.\n\\end{aligned}\n\\]\nSo, with some algebra, we have proven an equation for any classifier:\n\\[\n\\begin{aligned}\n    \\mathrm{TPR} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\frac{p}{1-p} = \\mathrm{FPR}\\;.\n\\end{aligned}\n\\]\nIt’s convenient to rearrange this equation slightly:\n\\[\n\\begin{aligned}\n    \\frac{\\mathrm{TPR}}{\\mathrm{FPR}} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}} = \\frac{1-p}{p}\\;.\n\\end{aligned}\n\\]\nor\n\\[\n\\begin{aligned}\n    p = \\left(1 + \\frac{\\mathrm{TPR}}{\\mathrm{FPR}} \\frac{1 - \\mathrm{PPV}}{\\mathrm{PPV}}\\right)^{-1}\\;.\n\\end{aligned}\n\\tag{1}\\]\nNow suppose that I want to enforce error rate balance and sufficiency for two groups \\(a\\) and \\(b\\), where \\(p_a \\neq p_b\\). So, from error rate balance I am going to require that \\(\\mathrm{TPR}_a = \\mathrm{TPR}_b\\), \\(\\mathrm{FPR}_a = \\mathrm{FPR}_b\\), and from sufficiency I am going to enforce that \\(\\mathrm{PPV}_a = \\mathrm{PPV}_b\\). Now, however, we have a problem: by Equation 1, it must also be the case that \\(p_a = p_b\\). This contradicts our assumption from the theorem. We cannot mathematically satisfy both error rate balance and sufficiency. This completes the proof.\n\n\n\n\n\n\n\nDiscussion\n\n\n\nDo you feel that it is more important for a recidivism prediction algorithm like COMPAS to satisfy error rate balance or sufficiency? Why?"
  },
  {
    "objectID": "ClassNotes/12-statistical-fairness.html#fairness-context-and-legitimacy",
    "href": "ClassNotes/12-statistical-fairness.html#fairness-context-and-legitimacy",
    "title": "Statistical Definitions of Fairness in Decision-Making",
    "section": "",
    "text": "The proof above shows that, when the prevalences of positive outcomes differ between groups, we have no hope of being able to have both balanced error rates and sufficiency. In Chapter 3, @barocasFairnessMachineLearning2023 give a few other examples of fairness definitions, as well as proofs that some of these definitions are incompatible with each other. We can’t just have it all – we have to choose.\nThe quantitative story of fairness in automated decision-making is not cut-and-dried – we need to make choices, which may be subject to politics. Let’s close this discussion with three increasingly difficult questions:\n\nWhat is the right definition of fairness by which to judge the operation of a decision-making algorithm?\nIs “fairness” even the right rubric for assessing the impact of a given algorithm?\nIs it legitimate to use automated decision-making at all for a given application context?\n\nWe’ll consider each of these questions soon."
  },
  {
    "objectID": "ClassNotes/20-perceptron.html",
    "href": "ClassNotes/20-perceptron.html",
    "title": "Introduction to Classification: The Perceptron",
    "section": "",
    "text": "In this lecture, we’ll study one of the oldest machine learning algorithms: the perceptron. Invented in 1943 but not actually implemented in hardware until 1958, the perceptron is still relevant today as a fundamental building-block of modern deep neural networks. Indeed, one of the implementations of neural networks in scikit-learn is still called the “multilayer perceptron.”\nWhen first announced, the perceptron algorithm also displayed one of the first examples of AI Hype®. The New York Times uncritically repeated claims by a Navy rep that the perceptron algorithm would be the “embryo” of a computer that would “walk, talk, see, write, reproduce itself, and be conscious of its existence.” As we study and implement the perceptron, you may wish to reflect on what you are doing and decide for yourself whether you believe that you are building the “embryo” of any such capabilities yourself.\n\n\n Early AI Hype.\n\n\nThe perceptron algorithm aims to find a rule for separating two distinct groups in some data. Here’s an example of some data on which we might aim to apply the perceptron:\n\n\nCode\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = perceptron_data()\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\nFigure 1: 300 data points in the 2d plane, each of which has one of two labels.\n\n\n\n\n\nThere are \\(n = 300\\) points of data. Each data point \\(i\\) has three pieces of information associated with it:\n\nA feature \\(x_{i1}\\). Think of a feature as a number you can measure, like a someone’s height or interest in studying machine learning on a scale.\nA second feature \\(x_{i2}\\). We often collect all the features associated with a data point \\(i\\) into a feature vector \\(\\mathbf{x}_i\\). In this case, \\(\\mathbf{x}_i = (x_{i1}, x_{i2}) \\in \\mathbb{R}^2\\). We often further collect all the feature vectors into a feature matrix \\(\\mathbf{X}\\), by stacking all the feature vectors on top of each other: \\[\n\\mathbf{X} = \\left[\\begin{matrix} & - & \\mathbf{x}_1 & - \\\\\n& - & \\mathbf{x}_2 & - \\\\\n& \\vdots & \\vdots & \\vdots \\\\\n& - & \\mathbf{x}_{n} & - \\end{matrix}\\right]\n\\]\nA target variable \\(y_i\\). In this data set, the target variable is has components equal to either \\(-1\\) or \\(1\\).  You can think of it as representing a piece of yes-no information like whether a student is a computer science major or not. The target variables can be collected into a target vector \\(\\mathbf{y} = (y_1, \\ldots, y_{n})^T \\in \\{-1,1\\}^{n}\\).\n\nIn many applications we assume that the target variable has values in \\(\\{0, 1\\}\\). For the perceptron, it turns out to be extra convenient to use \\(\\{-1, 1\\}\\) instead.More generally, supervised prediction problems with \\(n\\) data points and \\(k\\) features can be summarized in terms of a feature matrix \\(\\mathbf{X} \\in \\mathbb{R}^{n \\times p}\\) and a target vector \\(\\mathbf{y} \\in \\mathbb{R}^n\\).\n\n\n\nThe idea of a linear classifier is that we seek a hyperplane that approximately divides the data into its two classes. A hyperplane in \\(\\mathbb{R}^p\\) is an affine subspace of dimension \\(\\mathbb{R}^{p-1}\\). Such a hyperplane can be specified as the set of vectors \\(\\mathbf{x} \\in \\mathbb{R}^p\\) satisfying the equation\n\\[\n\\langle \\mathbf{w}, \\mathbf{x}\\rangle - b = \\sum_{i = 1}^{p-1} w_i x_i - b = 0\n\\tag{1}\\]\nfor some vector of weights \\(\\mathbf{w} \\in \\mathbb{R}^p\\) and bias \\(b \\in R\\). For mathematical convenience, it’s nicer to write this equation as\n\\[\n\\langle \\tilde{\\mathbf{w}}, \\tilde{\\mathbf{x}}\\rangle = 0\\;,\n\\tag{2}\\]\nwhere we have defined the new feature vectors \\(\\tilde{\\mathbf{x}} = (\\mathbf{x}, 1)\\) and \\(\\tilde{\\mathbf{w}} = (\\mathbf{w}, -b)\\).\n\n\n\n\n\n\nNote\n\n\n\nThroughout the remainder of these notes, we will assume that \\(\\mathbf{x}\\) has constant final feature value equal to 1. We’ll therefore just write \\(\\tilde{\\mathbf{x}}\\) and \\(\\tilde{\\mathbf{w}}\\) instead of \\(\\mathbf{x}\\) and \\(\\mathbf{w}\\).\n\n\nWhen \\(k = 2\\), a hyperplane is just a line. Here are two candidate hyperplanes that we could use to classify our data. Which one looks like it better separates the two classes?\nLinear score-based classifiction: compute s_i = inner product of w, x_i\npredict one iff s_i &gt; 0\nDecision boundary: inner product of w, w = 0\n\n\nCode\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nplot_perceptron_data(X, y, ax)\n\nw_0 = torch.Tensor([1, -1, 0])\nw_1 = torch.Tensor([1,  1, -1]) \n\ndraw_line(w_0, 0, 1, ax, color = \"black\", linestyle = \"dashed\", label = r\"$w^{(0)}$\")\ndraw_line(w_1, 0, 1, ax, color = \"black\", label = r\"$w^{(1)}$\")\n\nl = ax.legend(ncol = 2)\n\n\n\n\n\n\n\n\nFigure 2: Two candidate separating hyperplanes for our data. Which one would you choose?\n\n\n\n\n\nA good w makes a loss function small.\nWhereas the weight vector \\(\\mathbf{w}^{(0)}\\) generates a hyperplane that has data points from both classes on either side of it, the vector \\(\\mathbf{w}^{(1)}\\) exactly separates the two classes. What does it mean to exactly separate the two classes? It means that:\n\\[\n\\langle \\mathbf{w}^{(1)}, \\mathbf{x}_i\\rangle &gt; 0 \\Leftrightarrow y_i = 1\\;.\n\\tag{3}\\]\nThat is, if someone gave you the weight vector \\(\\mathbf{w}^{(1)}\\), you wouldn’t need to see the data labels: you could exactly recover them using Equation 3.\nLet’s make this a little more precise. For fixed \\(\\mathbf{w}\\), let \\(s_i \\triangleq \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\) by the score. The classification accuracy of the two-label perceptron with weight \\(\\mathbf{w}\\)is\nWe’ve used a little math trick here: take a moment to convince yourself that Equation 3 is equivalent to the statement that \\(s_i y_i &gt; 0\\).\n\\[A(\\mathbf{w}) \\triangleq \\frac{1}{n} \\sum_{i = 1}^n \\mathbb{1}[s_i y_i &gt; 0]\\;.\\]\nHigher accuracy means that the vector \\(\\mathbf{w}\\) predicts more correct labels via Equation 3. The loss (also called the empirical risk) is\n\\[\nR(\\mathbf{w}) \\triangleq 1 - A(\\mathbf{w})\\;.\n\\tag{4}\\]\nIt’s customary in machine learning to work with the loss. Since we want the accuracy to be high, we want the loss to be small. In other words, we want to minimize the function \\(R\\) with respect to the weight vector \\(\\mathbf{w}\\). This means that we want:\n\\[\n\\DeclareMathOperator*{\\argmin}{\\arg\\!\\min\\;}\n\\mathbf{w} = \\argmin_{\\mathbf{w}'} R(\\mathbf{w}')\n\\tag{5}\\]\nEquation 5 is our first example of the framework called empirical risk minimization, in which we define an empirical risk on the data and then seek a parameter vector that minimizes it.\n\n\n\nThe perceptron algorithm aims to find a good choice of \\(\\mathbf{w}\\) that makes the loss small using the following algorithm:\n\nStart with a random \\(\\mathbf{w}^{(0)}\\).\n“Until we’re done,” in each time-step \\(t\\), (while loss&gt;0 –&gt; L(w^t) &gt;0:) (while there are wrong points)\n\nPick a random data point \\(i \\in \\{1,\\ldots,n\\}\\).\nCompute score for the data point: \\(s^{(t)}_i = \\langle \\mathbf{w}^{(t)}, \\mathbf{x}_i \\rangle\\).\nDo a check if that individual point is classified (score matches): If \\(s^{(t)}_i y_i &gt; 0\\), then point \\(i\\) is currently correctly classified – do nothing!\nBut, if the point is not correctly classified, we change w by adding the sign of the target label (1 or -1) times the feature vector: Else, if \\(s^{(t)}_i y_i &lt; 0\\), then perform the update \\[\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} + y_i \\mathbf{x}_i\\;. \\tag{6}\\]\n\n\n\n\nNow let’s go ahead and run the perceptron algorithm on some data. First we should set up our feature matrix \\(\\mathbf{X}\\) and target vector \\(\\mathbf{y}\\).\n\ntorch.manual_seed(1234)\nX, y = perceptron_data(n_points = 50, noise = 0.3)\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 2), ylim = (-1, 2))\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\nYou may be able to eyeball the fact that this data is linearly separable: it is possible to draw a line that perfectly separates the two clusters. We can think of the perceptron algorithm as searching for such a line.\nLet’s start with a random guess for the weight vector \\(\\mathbf{w}\\):\n\nw = torch.Tensor([1, 1, 1]) #three entires in w bc you need a col of ones\n\n\n\nCode\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 2), ylim = (-1, 2))\nplot_perceptron_data(X, y, ax)\ndraw_line(w, -1, 2, ax, color = \"black\")\n\n\n\n\n\n\n\n\n\nWell, that doesn’t seem very promising. So, let’s do the perceptron update! First, we need to pick a random data point:\n\n\n&lt;torch._C.Generator at 0x7fc98066aa50&gt;\n\n\n\nn = X.shape[0] #compute num of data points\ni = torch.randint(n, size = (1,))\nx_i = X[[i],]\nx_i\n\ntensor([[0.0662, 0.0739, 1.0000]])\n\n\nNow we need to compute the score:\n\ns_i = x_i@w \ns_i\n\ntensor([1.1401])\n\n\nWe need to compare the score to the value of the target \\(y_i\\):\n\ny_i = y[i]\ns_i, y_i\n#posititve score, negative label --&gt; if we multiply both, we get something smaller than zero so we are in a try-hard branch with more work\n\n(tensor([1.1401]), tensor([-1]))\n\n\nIn this case, the score and the target have opposite signs, which means that we need to perform the perceptron update:\n\nw = w + y_i*x_i\n\nIf we now check the decision boundary again, it appears visually that it has improved slightly:\n\n\nCode\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 2), ylim = (-1, 2))\nplot_perceptron_data(X, y, ax)\ndraw_line(w, -1, 2, ax, color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow it’s time for us to introduce a training loop. In the training loop, we simply repeat the above procedure for a specified number of times (or until convergence). We’re going to illustrate this using a specific organization of our computational steps, which will stick with us throughout most of the rest of these notes.\nThe classes Perceptron and PerceptronOptimizer are defined in an external script. You’ll have the opportunity to implement and experiment with these classes in an upcoming assignment.\n\nfrom hidden.perceptron import Perceptron, PerceptronOptimizer\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\n\n# for keeping track of loss values\nloss_vec = []\n\nn = X.size()[0]\n\nwhile loss &gt; 0: # dangerous -- only terminates if data is linearly separable\n    \n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n    \n    # pick a random data point\n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n    \n    # perform a perceptron update using the random data point\n    opt.step(x_i, y_i) # this opt.step is the perceptron algorithm from class\n\nModuleNotFoundError: No module named 'hidden'\n\n\nWe can track the progress of our training by checking the values of the loss function over time:\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")\n\nWe can see that training completed with the achievement of zero loss; that is, perfect training accuracy.\n\n\n\nThe following figure illustrates the perceptron algorithm in action over several iterations.\n\n\n\n\nCode\ntorch.manual_seed(1234567)\n\n# initialize a perceptron \np = Perceptron()\nopt = PerceptronOptimizer(p)\np.loss(X, y)\n\n# set up the figure\nplt.rcParams[\"figure.figsize\"] = (7, 5)\nfig, axarr = plt.subplots(2, 3, sharex = True, sharey = True)\nmarkers = [\"o\", \",\"]\nmarker_map = {-1 : 0, 1 : 1}\n\n# initialize for main loop\ncurrent_ax = 0\nloss = 1\nloss_vec = []\n\nwhile loss &gt; 0:\n    ax = axarr.ravel()[current_ax]\n\n    # save the old value of w for plotting later\n    old_w = torch.clone(p.w)\n\n    # make an optimization step -- this is where the update actually happens\n    # now p.w is the new value \n    i, local_loss = opt.step(X, y)\n\n    # if a change was made, plot the old and new decision boundaries\n    # also add the new loss to loss_vec for plotting below\n    if local_loss &gt; 0:\n        plot_perceptron_data(X, y, ax)\n        draw_line(old_w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n        loss = p.loss(X, y).item()\n        loss_vec.append(loss)\n        draw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n        ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\", marker = markers[marker_map[y[i].item()]])\n        # draw_line(w, -10, 10, ax, color = \"black\")\n        ax.set_title(f\"loss = {loss:.3f}\")\n        ax.set(xlim = (-1, 2), ylim = (-1, 2))\n        current_ax += 1\nplt.tight_layout()\n\n\n\nFigure 3\n\n\n\n\n\n\nDoes the perceptron algorithm always improve our accuracy? Is it guaranteed to terminate? If it does terminate, is the result guaranteed to be a weight vector \\(\\mathbf{w}\\) that perfectly separates the two data classes?\n\n\nLet’s first check that the perceptron update in Equation 6 actually improves the prediction on data point \\(i\\) if there is currently a mistake on that point (i.e. if \\(s^{(t)}_i y_i &lt; 0\\)). We can do this by computing the new \\(s_i^{(t+1)}\\). Remember, what we want is for the sign of \\(s_i^{(t+1)}\\) to match \\(y_i\\).\n\\[\n\\begin{align}\ns_i^{(t+1)} &= \\langle \\mathbf{w}^{(t+1)}, \\mathbf{x}_i\\rangle  &\\text{(definition of $s_i^{(t+1)}$)}\\\\\n               &= \\langle \\mathbf{w}^{(t)} + y_i\\mathbf{x}_i, \\mathbf{x}_i\\rangle &\\text{(perceptron update)} \\\\\n               &= \\langle \\mathbf{w}^{(t)},\\mathbf{x}_i\\rangle + y_i\\langle \\mathbf{x}_i, \\mathbf{x}_i\\rangle &\\text{(linearity of $\\langle \\cdot\\rangle$)}\\\\\n               &= s_i^{(t)} + y_i \\lVert \\mathbf{x}_i\\rVert_2^2\\;. &\\text{(definition of $s_i^{(t)}$ and $\\lVert \\mathbf{x}_i\\rVert$)}\n\\end{align}\n\\]\n Since \\(\\lVert\\mathbf{x}_i\\rVert &gt; 0\\), we conclude that \\(s_i\\) always moves in the right direction: if \\(y_i = 1\\) then \\(s_i^{(t+1)} &gt; s_i^{(t)}\\), while if \\(y_i = -1\\) then \\(s_i^{(t+1)} &lt; s_i^{(t)}\\).Again, this is only if \\(s^{(t)}_i y_i &lt; 0\\); otherwise there is no change in \\(s_i^{(t)}\\) in the current iteration.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 1 (Linear Separability) A data set with feature matrix \\(\\mathbf{X} \\in \\mathbb{R}^{n\\times k}\\) and target vector \\(y\\in \\{-1, 1\\}\\) is linearly separable if there exists a weight vector \\(\\mathbf{w}\\) such that, for all \\(i \\in [n]\\),\n\\[\n\\langle\\mathbf{w}, \\mathbf{x}_i\\rangle &gt; 0 \\Leftrightarrow y = 1\\;.\n\\]\n\n\n\nTake a moment to convince yourself of the following:\n\n\n\n\n\n\nTip\n\n\n\n\nProposition 1 (Nonconvergence of perceptron for nonseparable data) Suppose that \\((\\mathbf{X}, \\mathbf{y})\\) is not linearly separable. Then, the perceptron update does not converge. Furthermore, at no iteration of the algorithm is it the case that \\(A(\\mathbf{w}) = 1\\).\n\n\n\nIt’s not as obvious that, if the data is linearly separable, then the perceptron algorithm will converge to a correct answer. Perhaps surprisingly, this is also true:\n\n\n\n\n\n\nTip\n\n\n\n\nTheorem 1 (Convergence of perceptron for separable data) Suppose that \\((\\mathbf{X}, \\mathbf{y})\\) is linearly separable. Then:\n\nThe perceptron algorithm converges in a finite number of iterations to a vector \\(\\mathbf{w}\\) that separates the data, so that \\(A(\\mathbf{w}) = 1\\).\n\nDuring the running of the perceptron algorithm, the total number of updates made is no more than \\[\\frac{2 + r(\\mathbf{X})^2}{\\gamma(\\mathbf{X}, \\mathbf{y})}\\;,\\]\n\nwhere \\(r(\\mathbf{X}) = \\max_{i \\in [n]} \\lVert \\mathbf{x}_i \\rVert\\) and \\(\\gamma(\\mathbf{X}, \\mathbf{y})\\) is a geometric measure called the margin of how far apart the two label classes are.\n\n\n\nFor a proof of Theorem 1, see p. 37-44 of @hardtPatternsPredictionsActions2022.\n\n\n\n\nWe have outlined the perceptron algorithm, which is able to find a separating hyperplane between two labeled groups of points when such a hyperplane exists.\nWe should, however, be troubled by the fact that the perceptron algorithm doesn’t converge when the data isn’t linearly separable. Maybe we could design a different algorithm that would allow us to find a parameter vector \\(\\mathbf{w}\\) that makes the empirical risk \\(R(\\mathbf{w}) = 1 - A(\\mathbf{w})\\) as small as possible?\nUnfortunately, we have a grave problem here:\n\n\n\n\n\n\nTip\n\n\n\n\nTheorem 2 (0-1 Minimization for Linear Classifiers is NP Hard (@kearnsEfficientAgnosticLearning1992)) Unless P = NP, there is no polynomial-time algorithm that can find a \\(\\mathbf{w}\\) that solves Equation 5 when \\(R(\\mathbf{w}) = 1 - A(\\mathbf{w})\\) is the rate of incorrect classifications.\n\n\n\nSo, if our data is not linearly separable, not only will the perceptron algorithm not converge, but no classical algorithm will solve the minimization problem in polynomial time.\nIn order to make progress towards practical algorithms, we will need to slightly change our approach. This will be the subject of our next several chapters."
  },
  {
    "objectID": "ClassNotes/20-perceptron.html#illustration",
    "href": "ClassNotes/20-perceptron.html#illustration",
    "title": "Introduction to Classification: The Perceptron",
    "section": "",
    "text": "The following figure illustrates the perceptron algorithm in action over several iterations.\n\n\n\n\nCode\ntorch.manual_seed(1234567)\n\n# initialize a perceptron \np = Perceptron()\nopt = PerceptronOptimizer(p)\np.loss(X, y)\n\n# set up the figure\nplt.rcParams[\"figure.figsize\"] = (7, 5)\nfig, axarr = plt.subplots(2, 3, sharex = True, sharey = True)\nmarkers = [\"o\", \",\"]\nmarker_map = {-1 : 0, 1 : 1}\n\n# initialize for main loop\ncurrent_ax = 0\nloss = 1\nloss_vec = []\n\nwhile loss &gt; 0:\n    ax = axarr.ravel()[current_ax]\n\n    # save the old value of w for plotting later\n    old_w = torch.clone(p.w)\n\n    # make an optimization step -- this is where the update actually happens\n    # now p.w is the new value \n    i, local_loss = opt.step(X, y)\n\n    # if a change was made, plot the old and new decision boundaries\n    # also add the new loss to loss_vec for plotting below\n    if local_loss &gt; 0:\n        plot_perceptron_data(X, y, ax)\n        draw_line(old_w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n        loss = p.loss(X, y).item()\n        loss_vec.append(loss)\n        draw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n        ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\", marker = markers[marker_map[y[i].item()]])\n        # draw_line(w, -10, 10, ax, color = \"black\")\n        ax.set_title(f\"loss = {loss:.3f}\")\n        ax.set(xlim = (-1, 2), ylim = (-1, 2))\n        current_ax += 1\nplt.tight_layout()\n\n\n\nFigure 3"
  },
  {
    "objectID": "ClassNotes/20-perceptron.html#theory-of-the-perceptron-algorithm",
    "href": "ClassNotes/20-perceptron.html#theory-of-the-perceptron-algorithm",
    "title": "Introduction to Classification: The Perceptron",
    "section": "",
    "text": "Does the perceptron algorithm always improve our accuracy? Is it guaranteed to terminate? If it does terminate, is the result guaranteed to be a weight vector \\(\\mathbf{w}\\) that perfectly separates the two data classes?\n\n\nLet’s first check that the perceptron update in Equation 6 actually improves the prediction on data point \\(i\\) if there is currently a mistake on that point (i.e. if \\(s^{(t)}_i y_i &lt; 0\\)). We can do this by computing the new \\(s_i^{(t+1)}\\). Remember, what we want is for the sign of \\(s_i^{(t+1)}\\) to match \\(y_i\\).\n\\[\n\\begin{align}\ns_i^{(t+1)} &= \\langle \\mathbf{w}^{(t+1)}, \\mathbf{x}_i\\rangle  &\\text{(definition of $s_i^{(t+1)}$)}\\\\\n               &= \\langle \\mathbf{w}^{(t)} + y_i\\mathbf{x}_i, \\mathbf{x}_i\\rangle &\\text{(perceptron update)} \\\\\n               &= \\langle \\mathbf{w}^{(t)},\\mathbf{x}_i\\rangle + y_i\\langle \\mathbf{x}_i, \\mathbf{x}_i\\rangle &\\text{(linearity of $\\langle \\cdot\\rangle$)}\\\\\n               &= s_i^{(t)} + y_i \\lVert \\mathbf{x}_i\\rVert_2^2\\;. &\\text{(definition of $s_i^{(t)}$ and $\\lVert \\mathbf{x}_i\\rVert$)}\n\\end{align}\n\\]\n Since \\(\\lVert\\mathbf{x}_i\\rVert &gt; 0\\), we conclude that \\(s_i\\) always moves in the right direction: if \\(y_i = 1\\) then \\(s_i^{(t+1)} &gt; s_i^{(t)}\\), while if \\(y_i = -1\\) then \\(s_i^{(t+1)} &lt; s_i^{(t)}\\).Again, this is only if \\(s^{(t)}_i y_i &lt; 0\\); otherwise there is no change in \\(s_i^{(t)}\\) in the current iteration.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 1 (Linear Separability) A data set with feature matrix \\(\\mathbf{X} \\in \\mathbb{R}^{n\\times k}\\) and target vector \\(y\\in \\{-1, 1\\}\\) is linearly separable if there exists a weight vector \\(\\mathbf{w}\\) such that, for all \\(i \\in [n]\\),\n\\[\n\\langle\\mathbf{w}, \\mathbf{x}_i\\rangle &gt; 0 \\Leftrightarrow y = 1\\;.\n\\]\n\n\n\nTake a moment to convince yourself of the following:\n\n\n\n\n\n\nTip\n\n\n\n\nProposition 1 (Nonconvergence of perceptron for nonseparable data) Suppose that \\((\\mathbf{X}, \\mathbf{y})\\) is not linearly separable. Then, the perceptron update does not converge. Furthermore, at no iteration of the algorithm is it the case that \\(A(\\mathbf{w}) = 1\\).\n\n\n\nIt’s not as obvious that, if the data is linearly separable, then the perceptron algorithm will converge to a correct answer. Perhaps surprisingly, this is also true:\n\n\n\n\n\n\nTip\n\n\n\n\nTheorem 1 (Convergence of perceptron for separable data) Suppose that \\((\\mathbf{X}, \\mathbf{y})\\) is linearly separable. Then:\n\nThe perceptron algorithm converges in a finite number of iterations to a vector \\(\\mathbf{w}\\) that separates the data, so that \\(A(\\mathbf{w}) = 1\\).\n\nDuring the running of the perceptron algorithm, the total number of updates made is no more than \\[\\frac{2 + r(\\mathbf{X})^2}{\\gamma(\\mathbf{X}, \\mathbf{y})}\\;,\\]\n\nwhere \\(r(\\mathbf{X}) = \\max_{i \\in [n]} \\lVert \\mathbf{x}_i \\rVert\\) and \\(\\gamma(\\mathbf{X}, \\mathbf{y})\\) is a geometric measure called the margin of how far apart the two label classes are.\n\n\n\nFor a proof of Theorem 1, see p. 37-44 of @hardtPatternsPredictionsActions2022."
  },
  {
    "objectID": "ClassNotes/20-perceptron.html#what-next",
    "href": "ClassNotes/20-perceptron.html#what-next",
    "title": "Introduction to Classification: The Perceptron",
    "section": "",
    "text": "We have outlined the perceptron algorithm, which is able to find a separating hyperplane between two labeled groups of points when such a hyperplane exists.\nWe should, however, be troubled by the fact that the perceptron algorithm doesn’t converge when the data isn’t linearly separable. Maybe we could design a different algorithm that would allow us to find a parameter vector \\(\\mathbf{w}\\) that makes the empirical risk \\(R(\\mathbf{w}) = 1 - A(\\mathbf{w})\\) as small as possible?\nUnfortunately, we have a grave problem here:\n\n\n\n\n\n\nTip\n\n\n\n\nTheorem 2 (0-1 Minimization for Linear Classifiers is NP Hard (@kearnsEfficientAgnosticLearning1992)) Unless P = NP, there is no polynomial-time algorithm that can find a \\(\\mathbf{w}\\) that solves Equation 5 when \\(R(\\mathbf{w}) = 1 - A(\\mathbf{w})\\) is the rate of incorrect classifications.\n\n\n\nSo, if our data is not linearly separable, not only will the perceptron algorithm not converge, but no classical algorithm will solve the minimization problem in polynomial time.\nIn order to make progress towards practical algorithms, we will need to slightly change our approach. This will be the subject of our next several chapters."
  },
  {
    "objectID": "WarmUps/23-gradient-descent.html",
    "href": "WarmUps/23-gradient-descent.html",
    "title": "Optimization with Gradient Descent",
    "section": "",
    "text": "Last time, we studied the empirical risk minimization (ERM). ERM casts the machine learning problem as an optimization problem: we want to find a vector of weights \\(\\mathbf{w}\\) such that\n\\[\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\begin{aligned}\n\\hat{\\mathbf{w}} &= \\argmin_{\\mathbf{w}} L(\\mathbf{w}) \\\\\n&= \\argmin_{\\mathbf{w}} \\frac{1}{n}\\sum_{i = 1}^n \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle, y_i)\\;.\n\\end{aligned}\n\\tag{1}\\]\nAs usual, \\(\\mathbf{X} \\in \\mathbb{R}^{n\\times p}\\) is the feature matrix\n\\[\n\\mathbf{X} = \\left[\\begin{matrix} & - & \\mathbf{x}_1 & - \\\\\n& - & \\mathbf{x}_2 & - \\\\\n& \\vdots & \\vdots & \\vdots \\\\\n& - & \\mathbf{x}_{n} & - \\end{matrix}\\right]\n\\]\nand \\(\\mathbf{y}\\) is the vector of targets, which we usually assume to be binary in the context of classification. The per-observation loss function \\(\\ell: \\mathbb{R}\\times \\mathbb{R}\\rightarrow \\mathbb{R}\\) measures the quality of the score \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\) assigned to data point \\(i\\) by comparing it to \\(y_i\\) and outputing a real number \\(\\ell(s_i, y_i)\\).\nSo, our mathematical task is to find a vector of weights \\(\\mathbf{w}\\) that solves Equation 1. How do we do it? The modern answer is gradient descent, and this set of lecture notes is about what that means and why it works.\n\n\nRecall the limit definition of a derivative of a single-variable function. Let \\(g:\\mathbb{R} \\rightarrow \\mathbb{R}\\). The derivative of \\(g\\) at point \\(w_0\\), if it exists, is\n\\[\n\\begin{aligned}\n\\frac{dg(w_0)}{dw} = \\lim_{\\delta w\\rightarrow 0}\\frac{g(w_0 + \\delta w) - g(w_0)}{\\delta w}\\;.\n\\end{aligned}\n\\]\nIf we imagine that \\(\\delta w\\) is very small but nonzero, we can interpret this equation a bit loosely as the statement that (removing the lim)\n\\[\n\\begin{aligned}\n\\frac{dg(w_0)}{dw} \\approx \\frac{g(w_0 + \\delta w) - g(w_0)}{\\delta w}\\;,\n\\end{aligned}\n\\]\nwhich upon some algebraic rearrangement says that\n\\[\ng(w_0 + \\delta w) \\approx g(w_0) + \\frac{dg(w_0)}{dw} \\delta w\\;.\n\\]\nTaylor’s theorem makes this statement precise:\n\n\n\n\n\n\nNote\n\n\n\n\nTheorem 1 (Taylor’s Theorem: Univariate Functions) Let \\(g:\\mathbb{R}\\rightarrow \\mathbb{R}\\) be differentiable at point \\(w_0\\). Then, there exists \\(a &gt; 0\\) such that, if \\(\\lvert\\delta w\\rvert &lt; a\\), then\n\\[\ng(w_0 + \\delta w) = g(w_0) + \\frac{dg(w_0)}{dw} \\delta w + o(\\vert\\delta w\\rvert)\\;.\n\\]\n\n\n\nHere, \\(o(\\lvert\\delta w\\rvert)\\) means “terms that grow small in comparison to \\(\\delta w\\) when \\(\\lvert\\delta w\\rvert\\) itself grows small.”\nAnother common way to write Taylor’s theorem is\n\\[\ng(w) = g(w_0) + \\frac{dg(w_0)}{dw} (w - w_0) + o(|w - w_0|)\\;,\n\\]\nwhich comes from substituting \\(\\delta w = w - w_0\\).\nTaylor’s theorem says that, in a neighborhood of \\(w_0\\), we can approximate \\(g(w)\\) with a linear function. Here’s an example of how that looks:\n\nimport torch \nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\nw = torch.linspace(-1, 1, 101)\n\ng = lambda w: w**2\n\nplt.plot(w, g(w), label = r\"$g(w)$\", color = \"black\")\nplt.gca().set(xlabel = r\"$w$\", ylim = (-0.2, 0.5))\n\ndef taylor (w, w0):\n    return g(w0) + 2*w0*(w - w0) # __ * derivative * ___\n\nw0 = 0.2\n\nplt.plot(w, taylor(w, w0), label = r\"1st-order Taylor approximation\", linestyle = \"--\")\nplt.legend()\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\n\n\n\n\n\n\n\nThis doesn’t really look like a very good approximation, but it looks better if you zoom in!\n\nplt.plot(w, g(w), label = r\"$g(w)$\", color = \"black\")\nplt.gca().set(xlabel = r\"$w$\", ylim = (-0.2, 0.5))\nplt.plot(w, taylor(w, w0), label = r\"1st-order Taylor approximation\", linestyle = \"--\")\nplt.gca().set(xlim = (w0 - 0.1, w0 + 0.1), ylim = (-0.00, 0.1))\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\nSuppose that we have a function \\(g\\) and we would like to solve the the optimization problem (find val that minimizes val of g) \\[\n\\begin{aligned}\n\\hat{w} = \\argmin _w g(w) \\;.\n\\end{aligned}\n\\]\nHow do we go about doing this? You might remember from calculus that one way starts with solving the equation\n\\[\n\\begin{aligned}\n\\frac{dg(\\hat{w})}{dw} = 0\\;,\n\\end{aligned}\n\\]\nto find critical points – under certain conditions, it is guaranteed that a minimum, if it exists, will be one of these critical points. However, it is not always feasible to solve this equation exactly in practice.\nIn iterative approaches, we instead imagine that we have a current guess \\(\\hat{w}\\) which we would like to improve by adding some \\(\\delta \\hat{w}\\) to it. To this end, consider the casual Taylor approximation In the rest of these notes, we will assume that term \\(o(\\lvert \\delta w\\rvert)\\) is small enough to be negligible.\n\\[\n\\begin{aligned}\ng(\\hat{w} + \\delta \\hat{w}) \\approx g(\\hat{w}) + \\frac{dg(\\hat{w})}{dw} \\delta \\hat{w}\\;.\n\\end{aligned}\n\\]\nSTRATEGY: 1) guess w 2) We’d like to update our estimate of \\(\\hat{w}\\). Suppose we make a strategic choice: \\(\\delta \\hat{w} = -\\alpha \\frac{dg(\\hat{w})}{dw}\\) for some small \\(\\alpha &gt; 0\\). We therefore decide that we will do the update\n\\[\n\\begin{aligned}\n    \\hat{w} \\gets \\hat{w} - \\alpha \\frac{dg(\\hat{w})}{dw}\\;.\n\\end{aligned}\n\\tag{2}\\]\nWhat does this update do to the value of \\(g\\)? (makes it smaller) Let’s check:\n\\[\n\\begin{aligned}\n    g(\\hat{w} + \\delta \\hat{w}) &\\approx g(\\hat{w}) + \\frac{dg(\\hat{w})}{dw} \\delta \\hat{w} \\\\\n    &= g(\\hat{w}) - \\frac{dg(\\hat{w})}{dw} \\alpha \\frac{dg(\\hat{w})}{dw}\\\\\n    &= g(\\hat{w}) - \\alpha\\left(\\frac{dg(\\hat{w})}{dw}\\right)^2\\;.   \n\\end{aligned}\n\\]\nThis is the big punchline. Let’s look at the second term. If \\(\\left(\\frac{dg(\\hat{w})}{dw}\\right)^2 = 0\\) then that must mean that \\(\\frac{dg(\\hat{w})}{dw}\\) and that we are at a critical point, which we could check for being a local minimum. On the other hand, if \\(\\frac{dg(\\hat{w})}{dw} \\neq 0\\), then \\(\\left(\\frac{dg(\\hat{w})}{dw}\\right)^2 &gt; 0\\). This means that\n\\[\n\\begin{aligned}\ng(\\hat{w} + \\delta \\hat{w}) &\\approx  g(\\hat{w}) - \\alpha\\left(\\frac{dg(\\hat{w})}{dw}\\right)^2 \\\\\n                            &&lt;  g(\\hat{w})\\;,\n\\end{aligned}\n\\]\nprovided that \\(\\alpha\\) is small enough for the error terms in Taylor’s Theorem to be small. We have informally derived the following fact:\n\n\n\n\n\n\nSingle-Variable Gradient-Descent Works\n\n\n\nLet \\(g:\\mathbb{R}\\rightarrow \\mathbb{R}\\) be differentiable and assume that \\(\\frac{dg(\\hat{w})}{dw} \\neq 0\\). Then, if \\(\\alpha\\) is sufficiently small, Equation 2 is guaranteed to reduce the value of \\(g\\).\n\n\nLet’s see an example of single-variable gradient descent in action:\n\nw_     = -0.7\ngrad  = lambda w: 2*w\nalpha = 0.1\nw_vec = [w_]\n\nfor i in range(100):\n    w_ = w_ - alpha*grad(w_) #update w by subtractng alpha by g (or grad)\n    w_vec.append(w_)\n\nw_vec = torch.tensor(w_vec)\n\nplt.plot(w, g(w), label = r\"$g(w)$\")\nplt.scatter(w_vec, g(w_vec), color = \"black\", label = r\"Gradient descent updates\", s = 10, zorder = 10)\nplt.gca().set(xlabel = r\"$w$\")\nplt.legend()\n\n\n\n\n\n\n\n\nWe can see the updates from gradient descent eventually converging to the point \\(w = 0\\), which is the global minimum of this function.\n\n\n\nOur empirical risk function \\(L\\) is not a single-variable function; indeed, \\(L: \\mathbb{R}^p \\rightarrow \\mathbb{R}\\). So, we can’t directly apply the results above. Fortunately, these results extend in a smooth way to this setting. The main thing we need is the definition of the gradient of a multivariate function.\n\n\n\nWe’re not going to talk much about what it means for a function to be multivariate differentiable. You can assume that all the functions we will deal with in this class are unless I highlight otherwise. For a more rigorous definition, you should check out a multivariable calculus class.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 1 (Gradient of a Multivariate Function) Let \\(g:\\mathbb{R}^p \\rightarrow \\mathbb{R}\\) be a multivariate differentiable function. The gradient of \\(g\\) evaluated at point \\(\\mathbf{w}\\in \\mathbb{R}^p\\) is written \\(\\nabla g(\\mathbf{w})\\), and has value\n\\[\n\\nabla g(\\mathbf{w}) \\triangleq\n\\left(\\begin{matrix}\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_1} \\\\\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_2} \\\\\n    \\cdots \\\\\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_p} \\\\\n\\end{matrix}\\right) \\in \\mathbb{R}^p\\;.\n\\]\nHere, \\(\\frac{\\partial g(\\mathbf{w})}{\\partial w_1}\\) is the partial derivative of \\(f\\) with respect to \\(z_1\\), evaluated at \\(\\mathbf{w}\\). It is the derivative og g at w, holding all variables except w_1 constant. To compute it:\n\nTake the derivative of \\(f\\) *with respect to variable \\(z_1\\), holding all other variables constant, and then evaluate the result at \\(\\mathbf{w}\\).\n\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet \\(p = 3\\). Let \\(g(\\mathbf{w}) = w_2\\sin w_1  + w_1e^{2w_3}\\). The partial derivatives we need are\n\\[\n\\begin{align}\n\\frac{\\partial g(\\mathbf{w})}{\\partial w_1} &= w_2 \\cos w_1 + e^{2w_3}\\\\\nderivative of sin is cos\\\\\n\\frac{\\partial g(\\mathbf{w})}{\\partial w_2} &= \\sin w_1\\\\\n\\frac{\\partial g(\\mathbf{w})}{\\partial w_3} &= 2w_1 e^{2w_3}\\;.\n\\end{align}\n\\]\nSo, the gradient of \\(g\\) evaluated at a point \\(\\mathbf{w}\\) is\n\\[\n\\nabla g(\\mathbf{w}) =\n\\left(\\begin{matrix}\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_1} \\\\\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_2} \\\\\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_3} \\\\\n\\end{matrix}\\right) =\n\\left(\\begin{matrix}\n    w_2 \\cos w_1 + e^{2w_3}\\\\\n    \\sin w_1\\\\\n    2w_1 e^{2w_3}\n\\end{matrix}\\right)\n\\]\n\n\nTaylor’s Theorem extends smoothly to this setting.\n\n\n\n\n\n\nNote\n\n\n\n\nTheorem 2 (Taylor’s Theorem: Multivariate Functions) Let \\(g:\\mathbb{R}^p\\rightarrow \\mathbb{R}\\) be differentiable at point \\(\\mathbf{w}_0 \\in \\mathbb{R}^p\\). Then, there exists \\(a &gt; 0\\) such that, if \\(\\lVert \\delta \\mathbf{w} \\rVert &lt; a\\), then \n\\[\ng(\\mathbf{w}_0 + \\delta \\mathbf{w}) = g(\\mathbf{w}_0) + \\langle \\nabla g(\\mathbf{w}_0), \\delta \\mathbf{w} \\rangle + o(\\lVert \\delta \\mathbf{w}\\rVert)\\;.\n\\]\n\n\n\n\\(\\lVert \\mathbf{\\delta} \\mathbf{w}\\rVert \\triangleq \\sqrt{\\sum_{i = 1}^p (\\delta w_i)^2}\\)The vector \\(\\nabla g(\\mathbf{w}_0)\\) plays the role of the single-variable derivative \\(\\frac{d g(w_0)}{dw}\\).\n\n\n\nguess w in R^P\nuntil done, repeat: In multiple dimensions, the gradient descent update is:\n\n\\[\n\\begin{aligned}\n    \\hat{\\mathbf{w}} \\gets \\hat{\\mathbf{w}} - \\alpha \\nabla g(\\hat{\\mathbf{w}})\\;.\n\\end{aligned}\n\\tag{3}\\]\nChecking why this works: Let’s check that a single update of gradient descent will reduce the value of \\(g\\) provided that \\(\\alpha\\) is small enough. Here, \\(\\delta \\hat{\\mathbf{w}} = -\\alpha \\nabla g(\\hat{\\mathbf{w}})\\).\n\\[\n\\begin{aligned}\n    g(\\hat{\\mathbf{w}} - \\delta \\hat{\\mathbf{w}}) &\\approx g(\\hat{\\mathbf{w}}) + \\langle \\nabla g(\\mathbf{w}_0), \\delta \\mathbf{w} \\rangle \\\\\n    &= g(\\hat{\\mathbf{w}}) + \\langle \\nabla g(\\hat{\\mathbf{w}}), -\\alpha \\nabla g(\\hat{\\mathbf{w}}) \\rangle \\\\\n    &= g(\\hat{\\mathbf{w}}) - \\alpha \\langle \\nabla g(\\hat{\\mathbf{w}}),  \\nabla g(\\hat{\\mathbf{w}}) \\rangle \\\\\n    &= g(\\hat{\\mathbf{w}}) - \\alpha \\lVert\\nabla g(\\hat{\\mathbf{w}}) \\rVert^2\\;.\n\\end{aligned}\n\\]\nSince \\(\\lVert\\nabla g(\\hat{\\mathbf{w}}) \\rVert^2 &gt; 0\\) whenever \\(\\nabla g(\\hat{\\mathbf{w}}) \\neq\\mathbf{0}\\), we conclude that, unless \\(\\hat{w}\\) is a critical point (where the gradient is zero), then\n\\[\n\\begin{aligned}\n    g(\\hat{\\mathbf{w}} - \\alpha \\nabla g(\\hat{\\mathbf{w}})) &lt; g(\\hat{\\mathbf{w}})\\;.\n\\end{aligned}\n\\]\nIn other words, provided that \\(\\alpha\\) is small enough for the Taylor approximation to be a good one, multivariate gradient descent also always reduces the value of the objective function.\n\n\n\n\nRemember that our big objective here was to solve Equation 1 using gradient descent. To do this, we need to be able to calculate \\(\\nabla L(\\mathbf{w})\\), where the gradient is with respect to the entries of \\(\\mathbf{w}\\). Fortunately, the specific linear structure of the score function \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\) makes this relatively simple: indeed, we actually only need to worry about the single variable derivatives of the per-observation loss \\(\\ell\\). To see this, we can compute\n\\[\n\\begin{align}\n\\nabla L(\\mathbf{w}) &= \\nabla \\left(\\frac{1}{n} \\sum_{i = 1}^n \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle , y_i)\\right) \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n \\nabla \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle , y_i) \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n  \\frac{d\\ell(s_i, y_i)}{ds} \\nabla \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle  &\\quad \\text{(multivariate chain rule)} \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n  \\frac{d\\ell(s_i, y_i)}{ds}  \\mathbf{x}_i &\\quad \\text{(gradient of a linear function)} \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n  \\frac{d\\ell(s_i, y_i)}{ds} \\mathbf{x}_i &\\quad \\text{($s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle$)} \\\\\n\\end{align}\n\\]\nThe good news here is that for linear models, we don’t actually need to be able to compute more gradients: we just need to be able to compute derivatives of the form \\(\\frac{d\\ell(s_i, y_i)}{ds}\\) and then plug in \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle\\).\nLet’s do an example with the logistic loss:\n\\[\\ell(s, y) = -y \\log \\sigma(s) - (1-y)\\log (1-\\sigma(s))\\;.\\]\nA useful fact to know about the logistic sigmoid function \\(\\sigma\\) is that \\(\\frac{d\\sigma(s) }{ds} = \\sigma(s) (1 - \\sigma(s))\\). So, using that and the chain rule, the derivative we need is\n\\[\n\\begin{align}\n\\frac{d\\ell(s, y)}{ds} &= -y \\frac{1}{\\sigma(s)}\\frac{d\\sigma(s) }{ds} - (1-y)\\frac{1}{1-\\sigma(s)}\\left(- \\frac{d\\sigma(s) }{ds}\\right) \\\\\n&= -y \\frac{1}{\\sigma(s)}\\sigma(s) (1 - \\sigma(s)) - (1-y)\\frac{1}{1-\\sigma(s)}\\left(- \\sigma(s) (1 - \\sigma(s))\\right) \\\\\n&= -y (1 - \\sigma(s)) + (1-y)\\sigma(s) \\\\\n&= \\sigma(s) - y\\;.\n\\end{align}\n\\]\nFinally, we need to plug this back in to our empirical risk, obtaining the gradient of the empirical risk for logistic regression:\n \\[\n\\begin{align}\n\\nabla L(\\mathbf{w}) &= \\frac{1}{n} \\sum_{i = 1}^n (\\sigma(s_i) - y_i)\\mathbf{x}_i \\\\\n              &=\\frac{1}{n} \\sum_{i = 1}^n (\\sigma(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle) - y_i)\\mathbf{x}_i\\;.\n\\end{align}\n\\tag{4}\\]An important note about this formula that can easily trip one up: this looks a bit like a matrix multiplication or dot product, but it isn’t!\nThis gives us all the math that we need in order to learn logistic regression by choosing a learning rate and iterating the update \\(\\mathbf{w}^{(t+1)} \\gets \\mathbf{w}^{(t)} - \\alpha \\nabla L(\\mathbf{w}^{(t)})\\) until convergence.\n\n\n\nLet’s see gradient-descent in action for logistic regression. Our computational approach is based on the LinearModel class that you previously started implementing. The training loop is also very similar to our training loop for the perceptron. The main difference is that the loss is calculated using the binary_cross_entropy function above, and the step function of the GradientDescentOptimizer works differently in a way that we will discuss below.\nStarting with the code block below, you won’t be able to follow along in coding these notes unless you have sneakily implemented logistic regression in a hidden module.\n\n\nCode\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(noise = 0.5)\n\n\nThe logistic regression training loop relies on a new implementation of opt.step. For gradient descent, here’s the complete implementation: just a quick Python version of the gradient descent update Equation 3.\n\ndef step(self, X, y, lr = 0.01):\n    self.model.w -= lr*self.model.grad(X, y)\n\nThe method model.grad() is the challenging part of the implementation: this is where we actually need to turn Equation 4 into code.\nHere’s the complete training loop. This loop is very similar to our perceptron training loop – we’re just using a different loss and a different implementation of grad.\n\n\n\nfrom hidden.logistic import LogisticRegression, GradientDescentOptimizer\n\n# instantiate a model and an optimizer\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\n# for keeping track of loss values\nloss_vec = []\n\nfor _ in range(100):\n\n    # not part of the update: just for tracking our progress    \n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n\n    # only this line actually changes the parameter value\n    # The whole definition is: \n    # self.model.w -= lr*self.model.grad(X, y)\n\n    opt.step(X, y, lr = 0.02)\n\nplt.plot(torch.arange(1, len(loss_vec)+1), loss_vec, color = \"black\")\nplt.semilogx()\nlabs = plt.gca().set(xlabel = \"Number of gradient descent iterations\", ylabel = \"Loss (binary cross entropy)\")\n\nModuleNotFoundError: No module named 'hidden'\n\n\n\nFigure 1\n\n\n\nThe loss quickly levels out to a constant value, which is our optimized weight vector \\(\\mathbf{w}\\). Because our theory tells us that the loss function is convex, we know that the value of \\(\\mathbf{w}\\) we have found is the best possible, in the sense of minimizing the loss.\nLet’s check our training accuracy:\n\n(1.0*(LR.predict(X) == y)).mean()\n\nNot too bad!\n\n\n\nIn these lecture notes, we introduced gradient descent as a method for minimizing functions, and showed an application of gradient descent for logistic regression. Gradient descent is especially useful when working with convex functions, since in this case it is guaranteed to converge to the global minimum of the empirical risk (provided that the learning rate \\(\\alpha\\) is sufficiently low). The idea of gradient descent – incremental improvement to the weight vector \\(\\mathbf{w}\\) using information about the derivatives of the loss function–is a fundamental one which has led to many variations and improvements."
  },
  {
    "objectID": "WarmUps/23-gradient-descent.html#linear-approximations-of-single-variable-functions",
    "href": "WarmUps/23-gradient-descent.html#linear-approximations-of-single-variable-functions",
    "title": "Optimization with Gradient Descent",
    "section": "",
    "text": "Recall the limit definition of a derivative of a single-variable function. Let \\(g:\\mathbb{R} \\rightarrow \\mathbb{R}\\). The derivative of \\(g\\) at point \\(w_0\\), if it exists, is\n\\[\n\\begin{aligned}\n\\frac{dg(w_0)}{dw} = \\lim_{\\delta w\\rightarrow 0}\\frac{g(w_0 + \\delta w) - g(w_0)}{\\delta w}\\;.\n\\end{aligned}\n\\]\nIf we imagine that \\(\\delta w\\) is very small but nonzero, we can interpret this equation a bit loosely as the statement that (removing the lim)\n\\[\n\\begin{aligned}\n\\frac{dg(w_0)}{dw} \\approx \\frac{g(w_0 + \\delta w) - g(w_0)}{\\delta w}\\;,\n\\end{aligned}\n\\]\nwhich upon some algebraic rearrangement says that\n\\[\ng(w_0 + \\delta w) \\approx g(w_0) + \\frac{dg(w_0)}{dw} \\delta w\\;.\n\\]\nTaylor’s theorem makes this statement precise:\n\n\n\n\n\n\nNote\n\n\n\n\nTheorem 1 (Taylor’s Theorem: Univariate Functions) Let \\(g:\\mathbb{R}\\rightarrow \\mathbb{R}\\) be differentiable at point \\(w_0\\). Then, there exists \\(a &gt; 0\\) such that, if \\(\\lvert\\delta w\\rvert &lt; a\\), then\n\\[\ng(w_0 + \\delta w) = g(w_0) + \\frac{dg(w_0)}{dw} \\delta w + o(\\vert\\delta w\\rvert)\\;.\n\\]\n\n\n\nHere, \\(o(\\lvert\\delta w\\rvert)\\) means “terms that grow small in comparison to \\(\\delta w\\) when \\(\\lvert\\delta w\\rvert\\) itself grows small.”\nAnother common way to write Taylor’s theorem is\n\\[\ng(w) = g(w_0) + \\frac{dg(w_0)}{dw} (w - w_0) + o(|w - w_0|)\\;,\n\\]\nwhich comes from substituting \\(\\delta w = w - w_0\\).\nTaylor’s theorem says that, in a neighborhood of \\(w_0\\), we can approximate \\(g(w)\\) with a linear function. Here’s an example of how that looks:\n\nimport torch \nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\nw = torch.linspace(-1, 1, 101)\n\ng = lambda w: w**2\n\nplt.plot(w, g(w), label = r\"$g(w)$\", color = \"black\")\nplt.gca().set(xlabel = r\"$w$\", ylim = (-0.2, 0.5))\n\ndef taylor (w, w0):\n    return g(w0) + 2*w0*(w - w0) # __ * derivative * ___\n\nw0 = 0.2\n\nplt.plot(w, taylor(w, w0), label = r\"1st-order Taylor approximation\", linestyle = \"--\")\nplt.legend()\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\n\n\n\n\n\n\n\nThis doesn’t really look like a very good approximation, but it looks better if you zoom in!\n\nplt.plot(w, g(w), label = r\"$g(w)$\", color = \"black\")\nplt.gca().set(xlabel = r\"$w$\", ylim = (-0.2, 0.5))\nplt.plot(w, taylor(w, w0), label = r\"1st-order Taylor approximation\", linestyle = \"--\")\nplt.gca().set(xlim = (w0 - 0.1, w0 + 0.1), ylim = (-0.00, 0.1))\nplt.legend()"
  },
  {
    "objectID": "WarmUps/23-gradient-descent.html#gradient-descent-in-1-dimension",
    "href": "WarmUps/23-gradient-descent.html#gradient-descent-in-1-dimension",
    "title": "Optimization with Gradient Descent",
    "section": "",
    "text": "Suppose that we have a function \\(g\\) and we would like to solve the the optimization problem (find val that minimizes val of g) \\[\n\\begin{aligned}\n\\hat{w} = \\argmin _w g(w) \\;.\n\\end{aligned}\n\\]\nHow do we go about doing this? You might remember from calculus that one way starts with solving the equation\n\\[\n\\begin{aligned}\n\\frac{dg(\\hat{w})}{dw} = 0\\;,\n\\end{aligned}\n\\]\nto find critical points – under certain conditions, it is guaranteed that a minimum, if it exists, will be one of these critical points. However, it is not always feasible to solve this equation exactly in practice.\nIn iterative approaches, we instead imagine that we have a current guess \\(\\hat{w}\\) which we would like to improve by adding some \\(\\delta \\hat{w}\\) to it. To this end, consider the casual Taylor approximation In the rest of these notes, we will assume that term \\(o(\\lvert \\delta w\\rvert)\\) is small enough to be negligible.\n\\[\n\\begin{aligned}\ng(\\hat{w} + \\delta \\hat{w}) \\approx g(\\hat{w}) + \\frac{dg(\\hat{w})}{dw} \\delta \\hat{w}\\;.\n\\end{aligned}\n\\]\nSTRATEGY: 1) guess w 2) We’d like to update our estimate of \\(\\hat{w}\\). Suppose we make a strategic choice: \\(\\delta \\hat{w} = -\\alpha \\frac{dg(\\hat{w})}{dw}\\) for some small \\(\\alpha &gt; 0\\). We therefore decide that we will do the update\n\\[\n\\begin{aligned}\n    \\hat{w} \\gets \\hat{w} - \\alpha \\frac{dg(\\hat{w})}{dw}\\;.\n\\end{aligned}\n\\tag{2}\\]\nWhat does this update do to the value of \\(g\\)? (makes it smaller) Let’s check:\n\\[\n\\begin{aligned}\n    g(\\hat{w} + \\delta \\hat{w}) &\\approx g(\\hat{w}) + \\frac{dg(\\hat{w})}{dw} \\delta \\hat{w} \\\\\n    &= g(\\hat{w}) - \\frac{dg(\\hat{w})}{dw} \\alpha \\frac{dg(\\hat{w})}{dw}\\\\\n    &= g(\\hat{w}) - \\alpha\\left(\\frac{dg(\\hat{w})}{dw}\\right)^2\\;.   \n\\end{aligned}\n\\]\nThis is the big punchline. Let’s look at the second term. If \\(\\left(\\frac{dg(\\hat{w})}{dw}\\right)^2 = 0\\) then that must mean that \\(\\frac{dg(\\hat{w})}{dw}\\) and that we are at a critical point, which we could check for being a local minimum. On the other hand, if \\(\\frac{dg(\\hat{w})}{dw} \\neq 0\\), then \\(\\left(\\frac{dg(\\hat{w})}{dw}\\right)^2 &gt; 0\\). This means that\n\\[\n\\begin{aligned}\ng(\\hat{w} + \\delta \\hat{w}) &\\approx  g(\\hat{w}) - \\alpha\\left(\\frac{dg(\\hat{w})}{dw}\\right)^2 \\\\\n                            &&lt;  g(\\hat{w})\\;,\n\\end{aligned}\n\\]\nprovided that \\(\\alpha\\) is small enough for the error terms in Taylor’s Theorem to be small. We have informally derived the following fact:\n\n\n\n\n\n\nSingle-Variable Gradient-Descent Works\n\n\n\nLet \\(g:\\mathbb{R}\\rightarrow \\mathbb{R}\\) be differentiable and assume that \\(\\frac{dg(\\hat{w})}{dw} \\neq 0\\). Then, if \\(\\alpha\\) is sufficiently small, Equation 2 is guaranteed to reduce the value of \\(g\\).\n\n\nLet’s see an example of single-variable gradient descent in action:\n\nw_     = -0.7\ngrad  = lambda w: 2*w\nalpha = 0.1\nw_vec = [w_]\n\nfor i in range(100):\n    w_ = w_ - alpha*grad(w_) #update w by subtractng alpha by g (or grad)\n    w_vec.append(w_)\n\nw_vec = torch.tensor(w_vec)\n\nplt.plot(w, g(w), label = r\"$g(w)$\")\nplt.scatter(w_vec, g(w_vec), color = \"black\", label = r\"Gradient descent updates\", s = 10, zorder = 10)\nplt.gca().set(xlabel = r\"$w$\")\nplt.legend()\n\n\n\n\n\n\n\n\nWe can see the updates from gradient descent eventually converging to the point \\(w = 0\\), which is the global minimum of this function."
  },
  {
    "objectID": "WarmUps/23-gradient-descent.html#gradient-descent-in-multiple-dimensions",
    "href": "WarmUps/23-gradient-descent.html#gradient-descent-in-multiple-dimensions",
    "title": "Optimization with Gradient Descent",
    "section": "",
    "text": "Our empirical risk function \\(L\\) is not a single-variable function; indeed, \\(L: \\mathbb{R}^p \\rightarrow \\mathbb{R}\\). So, we can’t directly apply the results above. Fortunately, these results extend in a smooth way to this setting. The main thing we need is the definition of the gradient of a multivariate function."
  },
  {
    "objectID": "WarmUps/23-gradient-descent.html#gradients",
    "href": "WarmUps/23-gradient-descent.html#gradients",
    "title": "Optimization with Gradient Descent",
    "section": "",
    "text": "We’re not going to talk much about what it means for a function to be multivariate differentiable. You can assume that all the functions we will deal with in this class are unless I highlight otherwise. For a more rigorous definition, you should check out a multivariable calculus class.\n\n\n\n\n\n\nNote\n\n\n\n\nDefinition 1 (Gradient of a Multivariate Function) Let \\(g:\\mathbb{R}^p \\rightarrow \\mathbb{R}\\) be a multivariate differentiable function. The gradient of \\(g\\) evaluated at point \\(\\mathbf{w}\\in \\mathbb{R}^p\\) is written \\(\\nabla g(\\mathbf{w})\\), and has value\n\\[\n\\nabla g(\\mathbf{w}) \\triangleq\n\\left(\\begin{matrix}\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_1} \\\\\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_2} \\\\\n    \\cdots \\\\\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_p} \\\\\n\\end{matrix}\\right) \\in \\mathbb{R}^p\\;.\n\\]\nHere, \\(\\frac{\\partial g(\\mathbf{w})}{\\partial w_1}\\) is the partial derivative of \\(f\\) with respect to \\(z_1\\), evaluated at \\(\\mathbf{w}\\). It is the derivative og g at w, holding all variables except w_1 constant. To compute it:\n\nTake the derivative of \\(f\\) *with respect to variable \\(z_1\\), holding all other variables constant, and then evaluate the result at \\(\\mathbf{w}\\).\n\n\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet \\(p = 3\\). Let \\(g(\\mathbf{w}) = w_2\\sin w_1  + w_1e^{2w_3}\\). The partial derivatives we need are\n\\[\n\\begin{align}\n\\frac{\\partial g(\\mathbf{w})}{\\partial w_1} &= w_2 \\cos w_1 + e^{2w_3}\\\\\nderivative of sin is cos\\\\\n\\frac{\\partial g(\\mathbf{w})}{\\partial w_2} &= \\sin w_1\\\\\n\\frac{\\partial g(\\mathbf{w})}{\\partial w_3} &= 2w_1 e^{2w_3}\\;.\n\\end{align}\n\\]\nSo, the gradient of \\(g\\) evaluated at a point \\(\\mathbf{w}\\) is\n\\[\n\\nabla g(\\mathbf{w}) =\n\\left(\\begin{matrix}\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_1} \\\\\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_2} \\\\\n    \\frac{\\partial g(\\mathbf{w})}{\\partial w_3} \\\\\n\\end{matrix}\\right) =\n\\left(\\begin{matrix}\n    w_2 \\cos w_1 + e^{2w_3}\\\\\n    \\sin w_1\\\\\n    2w_1 e^{2w_3}\n\\end{matrix}\\right)\n\\]\n\n\nTaylor’s Theorem extends smoothly to this setting.\n\n\n\n\n\n\nNote\n\n\n\n\nTheorem 2 (Taylor’s Theorem: Multivariate Functions) Let \\(g:\\mathbb{R}^p\\rightarrow \\mathbb{R}\\) be differentiable at point \\(\\mathbf{w}_0 \\in \\mathbb{R}^p\\). Then, there exists \\(a &gt; 0\\) such that, if \\(\\lVert \\delta \\mathbf{w} \\rVert &lt; a\\), then \n\\[\ng(\\mathbf{w}_0 + \\delta \\mathbf{w}) = g(\\mathbf{w}_0) + \\langle \\nabla g(\\mathbf{w}_0), \\delta \\mathbf{w} \\rangle + o(\\lVert \\delta \\mathbf{w}\\rVert)\\;.\n\\]\n\n\n\n\\(\\lVert \\mathbf{\\delta} \\mathbf{w}\\rVert \\triangleq \\sqrt{\\sum_{i = 1}^p (\\delta w_i)^2}\\)The vector \\(\\nabla g(\\mathbf{w}_0)\\) plays the role of the single-variable derivative \\(\\frac{d g(w_0)}{dw}\\).\n\n\n\nguess w in R^P\nuntil done, repeat: In multiple dimensions, the gradient descent update is:\n\n\\[\n\\begin{aligned}\n    \\hat{\\mathbf{w}} \\gets \\hat{\\mathbf{w}} - \\alpha \\nabla g(\\hat{\\mathbf{w}})\\;.\n\\end{aligned}\n\\tag{3}\\]\nChecking why this works: Let’s check that a single update of gradient descent will reduce the value of \\(g\\) provided that \\(\\alpha\\) is small enough. Here, \\(\\delta \\hat{\\mathbf{w}} = -\\alpha \\nabla g(\\hat{\\mathbf{w}})\\).\n\\[\n\\begin{aligned}\n    g(\\hat{\\mathbf{w}} - \\delta \\hat{\\mathbf{w}}) &\\approx g(\\hat{\\mathbf{w}}) + \\langle \\nabla g(\\mathbf{w}_0), \\delta \\mathbf{w} \\rangle \\\\\n    &= g(\\hat{\\mathbf{w}}) + \\langle \\nabla g(\\hat{\\mathbf{w}}), -\\alpha \\nabla g(\\hat{\\mathbf{w}}) \\rangle \\\\\n    &= g(\\hat{\\mathbf{w}}) - \\alpha \\langle \\nabla g(\\hat{\\mathbf{w}}),  \\nabla g(\\hat{\\mathbf{w}}) \\rangle \\\\\n    &= g(\\hat{\\mathbf{w}}) - \\alpha \\lVert\\nabla g(\\hat{\\mathbf{w}}) \\rVert^2\\;.\n\\end{aligned}\n\\]\nSince \\(\\lVert\\nabla g(\\hat{\\mathbf{w}}) \\rVert^2 &gt; 0\\) whenever \\(\\nabla g(\\hat{\\mathbf{w}}) \\neq\\mathbf{0}\\), we conclude that, unless \\(\\hat{w}\\) is a critical point (where the gradient is zero), then\n\\[\n\\begin{aligned}\n    g(\\hat{\\mathbf{w}} - \\alpha \\nabla g(\\hat{\\mathbf{w}})) &lt; g(\\hat{\\mathbf{w}})\\;.\n\\end{aligned}\n\\]\nIn other words, provided that \\(\\alpha\\) is small enough for the Taylor approximation to be a good one, multivariate gradient descent also always reduces the value of the objective function."
  },
  {
    "objectID": "WarmUps/23-gradient-descent.html#gradient-of-the-empirical-risk",
    "href": "WarmUps/23-gradient-descent.html#gradient-of-the-empirical-risk",
    "title": "Optimization with Gradient Descent",
    "section": "",
    "text": "Remember that our big objective here was to solve Equation 1 using gradient descent. To do this, we need to be able to calculate \\(\\nabla L(\\mathbf{w})\\), where the gradient is with respect to the entries of \\(\\mathbf{w}\\). Fortunately, the specific linear structure of the score function \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\) makes this relatively simple: indeed, we actually only need to worry about the single variable derivatives of the per-observation loss \\(\\ell\\). To see this, we can compute\n\\[\n\\begin{align}\n\\nabla L(\\mathbf{w}) &= \\nabla \\left(\\frac{1}{n} \\sum_{i = 1}^n \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle , y_i)\\right) \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n \\nabla \\ell(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle , y_i) \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n  \\frac{d\\ell(s_i, y_i)}{ds} \\nabla \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle  &\\quad \\text{(multivariate chain rule)} \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n  \\frac{d\\ell(s_i, y_i)}{ds}  \\mathbf{x}_i &\\quad \\text{(gradient of a linear function)} \\\\\n              &= \\frac{1}{n} \\sum_{i = 1}^n  \\frac{d\\ell(s_i, y_i)}{ds} \\mathbf{x}_i &\\quad \\text{($s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle$)} \\\\\n\\end{align}\n\\]\nThe good news here is that for linear models, we don’t actually need to be able to compute more gradients: we just need to be able to compute derivatives of the form \\(\\frac{d\\ell(s_i, y_i)}{ds}\\) and then plug in \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle\\).\nLet’s do an example with the logistic loss:\n\\[\\ell(s, y) = -y \\log \\sigma(s) - (1-y)\\log (1-\\sigma(s))\\;.\\]\nA useful fact to know about the logistic sigmoid function \\(\\sigma\\) is that \\(\\frac{d\\sigma(s) }{ds} = \\sigma(s) (1 - \\sigma(s))\\). So, using that and the chain rule, the derivative we need is\n\\[\n\\begin{align}\n\\frac{d\\ell(s, y)}{ds} &= -y \\frac{1}{\\sigma(s)}\\frac{d\\sigma(s) }{ds} - (1-y)\\frac{1}{1-\\sigma(s)}\\left(- \\frac{d\\sigma(s) }{ds}\\right) \\\\\n&= -y \\frac{1}{\\sigma(s)}\\sigma(s) (1 - \\sigma(s)) - (1-y)\\frac{1}{1-\\sigma(s)}\\left(- \\sigma(s) (1 - \\sigma(s))\\right) \\\\\n&= -y (1 - \\sigma(s)) + (1-y)\\sigma(s) \\\\\n&= \\sigma(s) - y\\;.\n\\end{align}\n\\]\nFinally, we need to plug this back in to our empirical risk, obtaining the gradient of the empirical risk for logistic regression:\n \\[\n\\begin{align}\n\\nabla L(\\mathbf{w}) &= \\frac{1}{n} \\sum_{i = 1}^n (\\sigma(s_i) - y_i)\\mathbf{x}_i \\\\\n              &=\\frac{1}{n} \\sum_{i = 1}^n (\\sigma(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle) - y_i)\\mathbf{x}_i\\;.\n\\end{align}\n\\tag{4}\\]An important note about this formula that can easily trip one up: this looks a bit like a matrix multiplication or dot product, but it isn’t!\nThis gives us all the math that we need in order to learn logistic regression by choosing a learning rate and iterating the update \\(\\mathbf{w}^{(t+1)} \\gets \\mathbf{w}^{(t)} - \\alpha \\nabla L(\\mathbf{w}^{(t)})\\) until convergence."
  },
  {
    "objectID": "WarmUps/23-gradient-descent.html#example-logistic-regression",
    "href": "WarmUps/23-gradient-descent.html#example-logistic-regression",
    "title": "Optimization with Gradient Descent",
    "section": "",
    "text": "Let’s see gradient-descent in action for logistic regression. Our computational approach is based on the LinearModel class that you previously started implementing. The training loop is also very similar to our training loop for the perceptron. The main difference is that the loss is calculated using the binary_cross_entropy function above, and the step function of the GradientDescentOptimizer works differently in a way that we will discuss below.\nStarting with the code block below, you won’t be able to follow along in coding these notes unless you have sneakily implemented logistic regression in a hidden module.\n\n\nCode\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(noise = 0.5)\n\n\nThe logistic regression training loop relies on a new implementation of opt.step. For gradient descent, here’s the complete implementation: just a quick Python version of the gradient descent update Equation 3.\n\ndef step(self, X, y, lr = 0.01):\n    self.model.w -= lr*self.model.grad(X, y)\n\nThe method model.grad() is the challenging part of the implementation: this is where we actually need to turn Equation 4 into code.\nHere’s the complete training loop. This loop is very similar to our perceptron training loop – we’re just using a different loss and a different implementation of grad.\n\n\n\nfrom hidden.logistic import LogisticRegression, GradientDescentOptimizer\n\n# instantiate a model and an optimizer\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\n# for keeping track of loss values\nloss_vec = []\n\nfor _ in range(100):\n\n    # not part of the update: just for tracking our progress    \n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n\n    # only this line actually changes the parameter value\n    # The whole definition is: \n    # self.model.w -= lr*self.model.grad(X, y)\n\n    opt.step(X, y, lr = 0.02)\n\nplt.plot(torch.arange(1, len(loss_vec)+1), loss_vec, color = \"black\")\nplt.semilogx()\nlabs = plt.gca().set(xlabel = \"Number of gradient descent iterations\", ylabel = \"Loss (binary cross entropy)\")\n\nModuleNotFoundError: No module named 'hidden'\n\n\n\nFigure 1\n\n\n\nThe loss quickly levels out to a constant value, which is our optimized weight vector \\(\\mathbf{w}\\). Because our theory tells us that the loss function is convex, we know that the value of \\(\\mathbf{w}\\) we have found is the best possible, in the sense of minimizing the loss.\nLet’s check our training accuracy:\n\n(1.0*(LR.predict(X) == y)).mean()\n\nNot too bad!"
  },
  {
    "objectID": "WarmUps/23-gradient-descent.html#recap",
    "href": "WarmUps/23-gradient-descent.html#recap",
    "title": "Optimization with Gradient Descent",
    "section": "",
    "text": "In these lecture notes, we introduced gradient descent as a method for minimizing functions, and showed an application of gradient descent for logistic regression. Gradient descent is especially useful when working with convex functions, since in this case it is guaranteed to converge to the global minimum of the empirical risk (provided that the learning rate \\(\\alpha\\) is sufficiently low). The idea of gradient descent – incremental improvement to the weight vector \\(\\mathbf{w}\\) using information about the derivatives of the loss function–is a fundamental one which has led to many variations and improvements."
  },
  {
    "objectID": "WarmUps/WarmUp14.html",
    "href": "WarmUps/WarmUp14.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "import torch\nfrom matplotlib import pyplot as plt \nplt.style.use('seaborn-v0_8-whitegrid')\n\ndef regression_data(n = 100, w = torch.Tensor([-0.7, 0.5]), x_max = 1):\n\n    x = torch.rand(n)*x_max\n    y = x*w[1] + w[0] + 0.05*torch.randn(n)\n    return x, y\n\nx, y = regression_data()\n\nplt.scatter(x, y, facecolors = \"none\", edgecolors = \"steelblue\")\nlabs = plt.gca().set(xlabel = r\"$x$\", ylabel = r\"$y$\")\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\n\n\n\n\n\n\n\n\ndef stochastic_gradient_descent (max_epoch, x, y, alpha):\n    w_0 = 0\n    w_1 = 0\n    alpha = 0.5\n    for epoch in range(1, max_epoch + 1):\n        epoch_rand_order = torch.random.permutation(len (x))\n        #i = torch.randint(0, x.shape[0], (batch_size,))\n\n\n        for i in epoch_rand_order:\n            w_0 = w_0 - (2*alpha / epoch) * w_0 * (y[i] - w_1*x[i] -w_0)\n            w_1 = w_1 - (2*alpha / epoch) * w_1 * (y[1] - w_1*x[i] -w_0) * x[i]\n\n    return w_0, w_1"
  },
  {
    "objectID": "WarmUps/WarmUp1.html",
    "href": "WarmUps/WarmUp1.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "import pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/palmer-penguins.csv\"\ndf = pd.read_csv(url)\n\n#show table\ndf\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/07\n39.1\n18.7\n181.0\n3750.0\nMALE\nNaN\nNaN\nNot enough blood for isotopes.\n\n\n1\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/07\n39.5\n17.4\n186.0\n3800.0\nFEMALE\n8.94956\n-24.69454\nNaN\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n11/16/07\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n3\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n11/16/07\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAdult not sampled.\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n11/16/07\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nPAL0910\n120\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A2\nNo\n12/1/09\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n340\nPAL0910\n121\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN39A1\nYes\n11/22/09\n46.8\n14.3\n215.0\n4850.0\nFEMALE\n8.41151\n-26.13832\nNaN\n\n\n341\nPAL0910\n122\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN39A2\nYes\n11/22/09\n50.4\n15.7\n222.0\n5750.0\nMALE\n8.30166\n-26.04117\nNaN\n\n\n342\nPAL0910\n123\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN43A1\nYes\n11/22/09\n45.2\n14.8\n212.0\n5200.0\nFEMALE\n8.24246\n-26.11969\nNaN\n\n\n343\nPAL0910\n124\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN43A2\nYes\n11/22/09\n49.9\n16.1\n213.0\n5400.0\nMALE\n8.36390\n-26.15531\nNaN\n\n\n\n\n344 rows × 17 columns\n\n\n\n\n#Warm-Up part A\n\n#group dataset based on sex and species to find mean mass\n\nmeanMassTable = df.groupby(['Species', 'Sex']).aggregate({'Body Mass (g)' : 'mean'}) #using dictionary to apply the mean function on the data\nprint(meanMassTable)\n\n                                                  Body Mass (g)\nSpecies                                   Sex                  \nAdelie Penguin (Pygoscelis adeliae)       FEMALE    3368.835616\n                                          MALE      4043.493151\nChinstrap penguin (Pygoscelis antarctica) FEMALE    3527.205882\n                                          MALE      3938.970588\nGentoo penguin (Pygoscelis papua)         .         4875.000000\n                                          FEMALE    4679.741379\n                                          MALE      5484.836066\n\n\n\n#Warm-up part B\n\n#Scatterplot of culmen length against culmen depth (bill dimensions), with the color of each point corresponding to the penguin species\n\n#creating scatterplot \nsns.scatterplot(data = df, x = 'Culmen Length (mm)', y = 'Culmen Depth (mm)', hue = 'Species')\n\n#labeling plot\nplt.title('Culmen Length vs. Culmen Depth Based on Penguin Species')\nplt.show()"
  },
  {
    "objectID": "WarmUps/WarmUp12.html",
    "href": "WarmUps/WarmUp12.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "import torch\nimport urllib.request\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\ndef read_image(url):\n    urllib.request.urlretrieve(url, \"maru.png\")\n    img = Image.open(\"maru.png\")\n    return torch.tensor(np.array(img)/255).float()\n\nurl = \"https://github.com/middlebury-csci-0451/CSCI-0451-s24/blob/main/assets/img/figs/maru.png?raw=true\"\n\nimg = read_image(url)\n\ndef to_greyscale(im):\n    v = torch.tensor([0.2989, 0.5870, 0.1140])\n    return 1 - img[:,:,:3]@v\n\nimg = to_greyscale(img)\n\nplt.imshow(img, cmap = \"Greys\")\nno_ax = plt.gca().axis(\"off\")\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\n\n\n\n\n\n\n\n\ndef convolve2d (X, K):\n    height, width = X.shape #assigning height and width\n    K_size = K.shape[0] #shape of both the height and width of kernel\n    padding_size = K_size\n    #zero padding ot input image\n    X_padding = torch.nn.functional.pad(X, padding_size)\n    zero_tensor = torch.zeros_like(X) \n    \n    for i in range(height):\n        for j in range(width):\n            \n            \n\n\nfrom scipy.signal import convolve2d\n\nkernel = torch.tensor([[-1, -1, -1], \n                       [-1,  8, -1], \n                       [-1, -1, -1]])\n\nconvd = convolve2d(img, kernel)\n\nplt.imshow(convd, cmap = \"Greys\", vmin = 0, vmax = 0.1)\nplt.gca().axis(\"off\")"
  },
  {
    "objectID": "WarmUps/WarmUp2.html",
    "href": "WarmUps/WarmUp2.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "Graphing Decision Boundaries\nPart A:\nWe use the dot product equation \\(w_i x_i + w_j x_j = b\\) and substitute the values for w and b: \\[(1) * x_i + -\\dfrac 1 2 * x_j = \\dfrac 1 2\\] We make the equation into \\(y = mx + b\\) to plot it: \\[ x_j = 2 * x_i - 1\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#making range for x\nx_vals = np.linspace(-5, 10, num = 10)\n\n#solving for x2\nx2_vals = 2 * x_vals - 1\n\nplt.plot(x_vals, x2_vals, color = 'pink')\n\nplt.xlabel = ('x1')\nplt.ylabel = ('x2')\nplt.title = (\"Graph of 1(x1) + (-1/2)x2 = 1/2\")\nplt.grid (True, linestyle = '--')\nplt.show()\n\n\n\n\n\n\n\n\n\nPart B:\nWrite a quick Python function called linear_classify(x, w, b). w and x should both be 1d numpy arrays of the same length, and b should be a scalar. The function np.dot(x, w) will compute the inner product of x and w. Argument b should be a scalar number. Your function should return 0 if dot product of w and x &lt; b and 1 if the dot product of w and x &gt;= b.\n\nimport numpy as np\ndef linear_classify(x, w, b):\n    if  np.dot(w, x) &lt; b: \n        return 0\n    elif (w@x) &gt;= b: \n        return 1\n    \n#testing\n    #should return 1 since dot prod &gt; b\nw = np.array([1, 2, 3, 4])\nx = np.array([2, 6, -1, 0])\nb = 3\n    #should return 0 since dot prod &lt; b\nw1 = np.array([1, 2, 3, 4])\nx1 = np.array([2, 6, -1, 0])\nb1 = 30\n\nw2 = np.array([2, -10, -5])\nx2 = np.array([2, -1, 0])\nb2 = 10\n\ntesting = linear_classify(w, x, b)\ntesting2 = linear_classify(w1, x1, b1)\ntesting3 = linear_classify(w2, x2, b2)\n\nprint('Test 1: ', testing)\nprint('Test 2: ', testing2)\nprint('Test 2: ', testing3)\n\n\nTest 1:  1\nTest 2:  0\nTest 2:  1\n\n\nPart C:\nMake a sketch of the curve in the nonnegative quadrant defined by the equation given.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#making range for x\nx_vals = np.linspace(0, 10)\nx1_val = np.sqrt(1 - 1/4 * (x_vals**2))\n\nplt.plot(x_vals, x1_val, color = 'pink')\nplt.xlabel = ('x')\nplt.ylabel = ('x1')\nplt.title = ('Curve in Nonnegative Quadrant')\nplt.grid (True, linestyle = '--')\nplt.show()\n\n/var/folders/33/b3h8vrcd0ss7_3q4gmmnscl80000gn/T/ipykernel_2446/4100891223.py:6: RuntimeWarning: invalid value encountered in sqrt\n  x1_val = np.sqrt(1 - 1/4 * (x_vals**2))"
  },
  {
    "objectID": "WarmUps/WarmUp11.html",
    "href": "WarmUps/WarmUp11.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "import math\n\ndef critical_point(a, epsilon, learning_rate_alpha, maxsteps):\n    \"'approximates the postitive square root of a real number (a)'\"\n    x = a\n    x_prime = 2*a\n    j = 0\n    while abs(x_prime - x) &gt; epsilon:\n        if j &gt; maxsteps:\n            break\n        x = x_prime\n        x_prime = x - (learning_rate_alpha * math.sqrt(a)) # or x - (a /x))\n        j = j + 1\n        return x_prime # or is it x?\n    \ncritical_point(a = 9, epsilon = 1e-8, learning_rate_alpha = 0.2, maxsteps = 100)\n\n17.4\n\n\nOne setting of alpha for which your function returns a real number very close to the exact value of x_a.\n\ncritical_point(a = 9, epsilon = 1e-8, learning_rate_alpha = 0.00001, maxsteps = 100)\n\n17.99997\n\n\nOne setting of alpha for which your function fails to return a real number close to the exact value of x_a within the maximum number of steps\n\ncritical_point(a = 9, epsilon = 1e-8, learning_rate_alpha = 0.9, maxsteps = 100)\n\n15.3\n\n\nPart D:\n\nYes it is possible: known as Newton’s method (also known as the Newton-Raphson method).\nFor finding the square root of a number a, we can use Newton’s method to solve the equation f(x)=x^2 − a = 0.\nstart with an initial guess, find the derivative using a formula and repeat until it gets as close as possible (what we coded above)"
  },
  {
    "objectID": "goals-setting/mid-course.html",
    "href": "goals-setting/mid-course.html",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "Daniela Delgado\n\n\nIn this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often have you attended class,” good answers include “almost always,” “I’ve missed three times,” “about 75% of the time,” “not as often as I want,” etc.\n\n\n\nHow often have you attended class? (e.g. “almost always,” “I missed three times,” etc.) I have only missed once.\nHow often have you taken notes on the core readings ahead of the class period? I have taken notes on every reading\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? I have been prepared every time, but also prepared to ask for help in certain parts.\nHow many times have you actually presented the daily warm-up to your team? I have presented every time my name has been listed, I believe it has been between 5-6 times.\nHow many times have you asked your team for help while presenting the daily warm-up? I have not asked for help.\nHow often have you learned something new from a teammate’s presentation of the daily warm-up? I have learned something new every time.\nHow often have you helped a teammate during the daily warm-up presentation? I have helped twice.\n\n\n\n\n\nHow often have you attended Student Hours or Peer Help? I have attended almost always.\nHow often have you asked for or received help from your fellow students? Never.\nHave you been regularly participating in a study group outside class? I have not.\nHow often have you posted questions or answers in Slack? I posted one question.\n\n\n\n\n\nHow many blog posts have you submitted? I have submitted 3 blog posts.\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: 0\nM: Revisions useful: 2\nR: Revisions encouraged: 1\nN: Incomplete: 0\n\nRoughly how many hours per week have you spent on this course outside of class? Between 10-13 hours a week\n\n\n\n\n\nAt the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\nI chose to focus on the implementation and social responsibility categories. I believe I have done more progress towards focusing on social responsibility as most of the work we have done so far has been focused towards seeing the biases in machine learning and towards women. The readings and warm-ups we have done so far, as well as the blog post for the Women in Data Science Conference, have all contributed to the social responsibility theme. In pursuing the implementation category, I feel like I have partially worked towards this interest. I have effectively coded one assignment, the training model on penguins one, but I did not effectively implement the optimal bank loan blog post.\n\n\n\nFor each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\n\n\nFor the blog posts, I believe I am on track to meet my goal of five blog posts to the E level by hopefully getting two blog posts to reach E with the two revisions I just submitted this week. I am also on track as part of the goals I have is to post at least two blog posts for each of the two categories of my interest, and I currently have one for each category. However, I am not on track with submitting five blog posts to the E level as I struggled a lot with the optimal decision algorithm and I fear I spent too much time on it, as well as revisions taking time in order to get them to meet the E standard. I fear that as the workload picks up with the project, more math being implemented, etc. I will not have enough time to focus on the blog posts, and thus, be behind on my goals of six blogs total with five to the E standard. The past few weeks have put into perspective that I might take longer to complete blog posts because I take longer to understand what is going on and debug.\n\n\n\n\n\nFor the course presence, I feel like I am on track as it is halfway through the semester and I have not used the pass option when I present. I am also on track for attending student and peer hours at least twice a week as I have attended at least twice a week to ask questions on what torch is, debugging questions, and math questions. Furthermore, I am on track in my reading and note taking goals as I have all of the readings to date and have highlighted important notes on them. I feel like I am not on track with asking questions when other group members present as I do not find myself asking questions. I fear asking questions because I believe everyone else understands the approach given, and I do not want to seem like the odd man out. I do know that not asking the questions hurts me more than caring wht others would think of me. I am also not on track for the goal on attending a peer study session as I am not sure if one exists or how I would form one if I do not really talk to people in the class as often.\n\n\n\n\n\nI am unsure if I am on track or not with the project. None of the goals I set, for example submitting the project milestones on time and meeting and communicating with my team, have happened as the group has not been formed. However, I am on track as I have been thinking on the ideas that interest me for a project and being open and excited to new ideas.\n\n\n\n\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\n\nI wanted to share that I had not done higher level math in a while, so I have been studying up on calculus and linear algebra as it has started to pick up. I believe this adds to my participation as it helps me be more prepared for the warm ups!\n\n\n\n\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course.\n\n\n\n\n\n\nMy goal was to complete six blog posts total, one for each category and then an extra one for the two categories I am most interested in, and complete 5 to the E level.\nFor the goal, I have turned in three blog posts, two of which each count towards the categories I am interested in. However, neither are at the E level.\nFor my revised goal, I would like to change to having five blog posts total where the themes I am interested in get two blog posts. However, instead of turning in at least 5 blog posts to be E level, I would change it to at least three or four as the course work for other classes is drastically picking up as well as the difficulty on the posts and the time I spend on them, especially thinking of the project coming up as well.\n\n\n\n\nTake 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\n\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of a C.\n\n\nA way in which I resonate with the soundbytes for that grade above is… that I was able to complete some new tasks related to the course content, but only with significant further guidance as I experienced with trying to find the bug in my optimal banking decision. However, I also resonate with the soundbyte from B that I am able to explain some new things or achieve new tasks as I believe I am understanding the biases and the recent math happening in the course.\n\n\n\n\n\nYou may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n\nI feel a little disappointed in where I am with my blog post goals as I feel like I am behind to where I wanted to be, and the grade I have been getting for the posts have not been what I hoped. I feel like I am struggling, especially because I do not have peers to reach out to for help as I do not know anyone in the class, so I rely on the times I can attend student and peer hours. I am also nervous on the final project as I do not know if I will end up working alone or with a group, so this is adding to my stress on being able to complete the blog posts. However, I might reach out to someone who comments an interesting or similar idea on the project ideas slack in hopes of working collaboratively."
  },
  {
    "objectID": "goals-setting/mid-course.html#the-data",
    "href": "goals-setting/mid-course.html#the-data",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "In this section I’ll ask you to fill in some data. You don’t have to give precise numbers – approximate, conversational responses are fine. For example, when I ask “how often have you attended class,” good answers include “almost always,” “I’ve missed three times,” “about 75% of the time,” “not as often as I want,” etc.\n\n\n\nHow often have you attended class? (e.g. “almost always,” “I missed three times,” etc.) I have only missed once.\nHow often have you taken notes on the core readings ahead of the class period? I have taken notes on every reading\nHow often have you been prepared to present the daily warm-up exercise to your team, even if you weren’t actually called? I have been prepared every time, but also prepared to ask for help in certain parts.\nHow many times have you actually presented the daily warm-up to your team? I have presented every time my name has been listed, I believe it has been between 5-6 times.\nHow many times have you asked your team for help while presenting the daily warm-up? I have not asked for help.\nHow often have you learned something new from a teammate’s presentation of the daily warm-up? I have learned something new every time.\nHow often have you helped a teammate during the daily warm-up presentation? I have helped twice.\n\n\n\n\n\nHow often have you attended Student Hours or Peer Help? I have attended almost always.\nHow often have you asked for or received help from your fellow students? Never.\nHave you been regularly participating in a study group outside class? I have not.\nHow often have you posted questions or answers in Slack? I posted one question.\n\n\n\n\n\nHow many blog posts have you submitted? I have submitted 3 blog posts.\nHow many of your submitted blog posts are at each of the following feedback stages?\n\nE: No revisions suggested: 0\nM: Revisions useful: 2\nR: Revisions encouraged: 1\nN: Incomplete: 0\n\nRoughly how many hours per week have you spent on this course outside of class? Between 10-13 hours a week"
  },
  {
    "objectID": "goals-setting/mid-course.html#what-youve-learned",
    "href": "goals-setting/mid-course.html#what-youve-learned",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "At the beginning of the course, you may have expressed an interest in focusing a little extra on one or two of the following four categories:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nDid you choose to focus on any of these categories? If so, what have you done in order to pursue your interest?\nI chose to focus on the implementation and social responsibility categories. I believe I have done more progress towards focusing on social responsibility as most of the work we have done so far has been focused towards seeing the biases in machine learning and towards women. The readings and warm-ups we have done so far, as well as the blog post for the Women in Data Science Conference, have all contributed to the social responsibility theme. In pursuing the implementation category, I feel like I have partially worked towards this interest. I have effectively coded one assignment, the training model on penguins one, but I did not effectively implement the optimal bank loan blog post."
  },
  {
    "objectID": "goals-setting/mid-course.html#reflecting-on-goals",
    "href": "goals-setting/mid-course.html#reflecting-on-goals",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "For each of the categories below, replace the “[your response here]” cell with 1-2 paragraphs in which you reflect on the following questions:\n\nIn what ways are you on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what you are doing in order to meet it.\nIn what ways are you not on track to meet your goals from the beginning of the course? Be specific: explain what the goal is and what gap you see between where you are and your goal.\nIf there’s any context you want to share about how you are faring relative to your goals, please do!\n\n\n\n\nFor the blog posts, I believe I am on track to meet my goal of five blog posts to the E level by hopefully getting two blog posts to reach E with the two revisions I just submitted this week. I am also on track as part of the goals I have is to post at least two blog posts for each of the two categories of my interest, and I currently have one for each category. However, I am not on track with submitting five blog posts to the E level as I struggled a lot with the optimal decision algorithm and I fear I spent too much time on it, as well as revisions taking time in order to get them to meet the E standard. I fear that as the workload picks up with the project, more math being implemented, etc. I will not have enough time to focus on the blog posts, and thus, be behind on my goals of six blogs total with five to the E standard. The past few weeks have put into perspective that I might take longer to complete blog posts because I take longer to understand what is going on and debug.\n\n\n\n\n\nFor the course presence, I feel like I am on track as it is halfway through the semester and I have not used the pass option when I present. I am also on track for attending student and peer hours at least twice a week as I have attended at least twice a week to ask questions on what torch is, debugging questions, and math questions. Furthermore, I am on track in my reading and note taking goals as I have all of the readings to date and have highlighted important notes on them. I feel like I am not on track with asking questions when other group members present as I do not find myself asking questions. I fear asking questions because I believe everyone else understands the approach given, and I do not want to seem like the odd man out. I do know that not asking the questions hurts me more than caring wht others would think of me. I am also not on track for the goal on attending a peer study session as I am not sure if one exists or how I would form one if I do not really talk to people in the class as often.\n\n\n\n\n\nI am unsure if I am on track or not with the project. None of the goals I set, for example submitting the project milestones on time and meeting and communicating with my team, have happened as the group has not been formed. However, I am on track as I have been thinking on the ideas that interest me for a project and being open and excited to new ideas.\n\n\n\n\nIs there anything else that you want to share with me about what you have learned, how you have participated, or what you have achieved in CSCI 0451?\n\nI wanted to share that I had not done higher level math in a while, so I have been studying up on calculus and linear algebra as it has started to pick up. I believe this adds to my participation as it helps me be more prepared for the warm ups!\n\n\n\n\nFrom your experience in CSCI 0451 and your other classes this semester, you may feel moved to make modifications to your goals. Are they still feasible? Too ambitious? Not ambitious enough? If you would like to revise any of your goals from your reflective goal-setting, you can do so below. For each goal you want to modify:\n\nClearly state what the goal was.\nClearly state how you’ve done on that goal so far.\nClearly state your proposed revised goal for the remainder of the course."
  },
  {
    "objectID": "goals-setting/mid-course.html#blog-posts-revision",
    "href": "goals-setting/mid-course.html#blog-posts-revision",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "My goal was to complete six blog posts total, one for each category and then an extra one for the two categories I am most interested in, and complete 5 to the E level.\nFor the goal, I have turned in three blog posts, two of which each count towards the categories I am interested in. However, neither are at the E level.\nFor my revised goal, I would like to change to having five blog posts total where the themes I am interested in get two blog posts. However, instead of turning in at least 5 blog posts to be E level, I would change it to at least three or four as the course work for other classes is drastically picking up as well as the difficulty on the posts and the time I spend on them, especially thinking of the project coming up as well."
  },
  {
    "objectID": "goals-setting/mid-course.html#grade-and-goals",
    "href": "goals-setting/mid-course.html#grade-and-goals",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "Take 15 minutes to look back on your responses in each of the sections above. Then, state the letter grade that you feel reflects your learning, participation, and achievement in CSCI 0451 so far, and contextualize it against some of the soundbytes below.\n\n\nAn A sounds like:\n\n“I am very proud of my time in this course.”\n“I have grown significantly in multiple ways that matter to me.”\n“I am ready to take the theory, techniques, and ideas of this course into my future classes, projects, hobbies, or career.”\n\nA B sounds like:\n\n“I had some opportunities to learn more, overall I feel good about my time in this course.”\n“I am able to explain some new things or achieve new tasks.”\n“I can see a few ideas from this course that will be relevant for my future classes, projects, hobbies, or career.”\n\nA C sounds like:\n\n“I often made a good effort, but I missed many opportunities to get more out of my time in this course.”\n“I might be able to complete some new tasks related to the course content, but only with significant further guidance.”\n“I don’t see any ways to take the contents of this course into my future classes, projects, hobbies, or career.”\n\nYou might find that some of these soundbytes resonate and other’s don’t! Take some time, see what feels right, and don’t be afraid to celebrate your achievements.\n\nUpon reflection, I feel that my learning, participation, and achievement in CSCI 0451 (so far) are best reflected by a grade of a C.\n\n\nA way in which I resonate with the soundbytes for that grade above is… that I was able to complete some new tasks related to the course content, but only with significant further guidance as I experienced with trying to find the bug in my optimal banking decision. However, I also resonate with the soundbyte from B that I am able to explain some new things or achieve new tasks as I believe I am understanding the biases and the recent math happening in the course."
  },
  {
    "objectID": "goals-setting/mid-course.html#optional-how-to-improve",
    "href": "goals-setting/mid-course.html#optional-how-to-improve",
    "title": "CSCI 0451: Mid-Course Reflection",
    "section": "",
    "text": "You may feel disappointed by your reflection. Sometimes we don’t achieve all our goals – it happens and it’s normal! If you are feeling disappointed by how you’ve learned, participated, or achieved in CSCI 0451, then feel free to write something about that below. Feel free to just write your feelings. If you have ideas for how to move forward, include those too! We’ll talk.\n\nI feel a little disappointed in where I am with my blog post goals as I feel like I am behind to where I wanted to be, and the grade I have been getting for the posts have not been what I hoped. I feel like I am struggling, especially because I do not have peers to reach out to for help as I do not know anyone in the class, so I rely on the times I can attend student and peer hours. I am also nervous on the final project as I do not know if I will end up working alone or with a group, so this is adding to my stress on being able to complete the blog posts. However, I might reach out to someone who comments an interesting or similar idea on the project ideas slack in hopes of working collaboratively."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Implementing Logistic Regression\n\n\n\n\n\nIn this blog post, I implemented several first-order methods: optimization algorithms based on the gradients of functions. I implemented simple gradient descent, a momentum method, and stochastic gradient descent, comparing their performance for training logistic regression. objectives: - Theory - Implementation - Experimentation\n\n\n\n\n\nApr 23, 2024\n\n\nDaniela Delgado\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Decision Making\n\n\n\n\n\nTraining data to predict if a person will default on a loan by finding a threshold using a LogisticRegression model!\n\n\n\n\n\nMar 26, 2024\n\n\nDaniela Delgado\n\n\n\n\n\n\n\n\n\n\n\n\nWomen in Data Science\n\n\n\n\n\nIn this blog post, we explore why there are fewer women in the data science field thorugh readings and analyzations. We also reflect and contexualize on the women who spoke on their careers in the data science field.\n\n\n\n\n\nMar 24, 2024\n\n\nDaniela Delgado\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins Post\n\n\n\n\n\nTraining data to accurately classify penguins using LogisticRegression and DecisionTreeClassifier models!\n\n\n\n\n\nFeb 20, 2024\n\n\nDaniela Delgado\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/women-in-DS/index.html",
    "href": "posts/women-in-DS/index.html",
    "title": "Women in Data Science",
    "section": "",
    "text": "Abstract\nIn this blog post, I explore why it is important to spotlight women in data science and analyze questions on why women are underrepresented in data science and STEM fields, why it is an issue, how it became an issue, and if there have been changes in representation since the 20th century. To answer these questions, I take information from some of the sections from the report “Solving the Equation: The Variables for Women’s Success in Engineering and Computing” written by Corbett and Hill (2015). Furthermore, I highlight a few women in STEM, specifically in data science, who came to talk at Middlebury College as part of the Middlebury Women in Data Science (WiDS) Conference and report their research. From these readings and the conference talks, my main takeaways are that women are limited in STEM fields based on the false ideas that society imposes on them and assumes of them, women in data science add to the creative and critical thinking skills needed to find solutions to world problems, and in order to increase female presence in STEM fields, we need to hold more spaces for women to see and hear the achievements of other women, such as this WiDS conference.\n\n\nWhy Spotlight Women in Data Science?\nWomen are underrepresented in computing, math, and engineering, and it is a problem for innovation. For example, problems that need solutions, such as climate change and water allocation, require the skills of computing, math and engineering fields. Having a smaller representation of women in the field limits the creative potential to solve these problems. Additionally, companies are also at a loss as, due to the gender biases, they often chose men to work for their company despite them scoring lower in math than some women. This places the company at a disadvantage as they are less globally competitive. Furthermore, the problem is also for women as they are missing out on high-quality job opportunities with high pay. These jobs are also more flexible, which women would be missing out on. Moreover, the continual under-representation of women in these fields leads to a perpetual cycle of living in the harmful stereotypes and gender biases that women do not belong in the computing, math, and engineering fields because they do not see themselves in those jobs.\nTo take this under-representation into perspective, the percent of women who are computing professionals was the same in 2013 as it was in the 1960s. Taking a walk through women in STEM history, a few number of women began to earn engineering degrees in the late 1800s and early 1900s. By the 1950s, women made up about 1% of the students in engineering programs in universities. Throughout the 1950s and into the 60s, male colleges began to admit women to increase the number of female students in the programs. However, because of male-dominated fields and gender norms, engineering was still considered to be for males.\nIn computing, women were more represented in the 1950s than men. For example, during Word War II, women made up most of the computer programmers. However, in the 1960s and 70s, men began to dominate the field due to hiring practices favoring men and because they did more gaming on personal computers so men began to be more attracted to the computing field. Men did more gaming as it was linked to the “hobbyist” culture and game playing in arcades that was usually dominated by males. Moreover, as computing became a more popular field to learn in colleges and universities, the departments had to place strict requirements to allow entry into the field. These requirements were disproportionately disadvantageous to women as they had less experience with programming and math than their counterparts. For all of these reasons, women today are still as underrepresented in the computing field today as they were in the 1950s and 60s.\nDespite the history of how this under-representation began, spotlighting women’s achievements can destroy some of the hurdles women face in deciding to join the STEM fields. For example, a barrier that can be eroded by spotlighting women’s achievements is the barrier of feeling isolated in the field, that is, lacking mentors to help women and feeling like the space is not safe to speak up. This can be eroded by seeing the achievements of women in STEM as they would show that it is possible to be valued and courageous as well as to know that there are other women that can substitute as their mentor and get advice from them and their story. This community of women in STEM fosters a supportive community where women can connect, learn from one another, and access mentorship opportunities to dismantle the feeling of isolation and lack of guidance. Additionally, another barrier faced is the gender stereotype that men are better than girls at math and physical sciences. This roadblock is detrimental to women’s representation in STEM fields as they feel less than and not as intelligent to pursue the fields in the first place. However, it can be destroyed by people seeing women succeeding in the STEM fields as it proves the gender stereotypes wrong. It illustrates that women are smart and do not fall short of men as can do anything they put their minds to. Seeing other women’s achievements allows women to chose to pursue STEM fields as they see themselves represented in that career path and realize that their gender does not limit their capabilities or potential for success. Moreover, with the accomplishments on display, women can combat the sexism found in these fields where women receive less challenging assignments, thus limiting their career advancements. This exhibit of women’s success in STEM can dismantle sexism in the department as it proves to department heads and women themselves that women can do impactful and vigorous work if given the challenge.\n\n\nLightning Talks\nIn the Women in Data Science Conference held at Middlebury College, there were three women who gave lightning talks of 15 minutes describing their research and work in data science. For the first lighting talk, Professor Amy Yuen spoke about addressing the question: Is the United Nations security council a democratic institution? In her findings, she found that the security council is not equal in the way we believe because some people have veto power, while others do not. Specifically, out of 15 members in the council, only five hold the power to veto. To answer the question, she looked at meetings, presidential statements, etc. to see who engages with the council while also looking at what regions are in the council. A surprising finding, at least for me, was that Japan and Brazil have the top two longest sittings in the council. However, as the results came to show, the average line is more flat, illustrating the inclusivity and representation of states in the council. The results came to be that the UN security council is somewhat democratic, but it could be worse in terms of states.\nOn the other hand, Dr. Jessica L’Roe, the second lightning round speaker, researches land use in conservation hotspots and livelihoods, and works with survey data, interview data, property data, land cover data, and more. During her presentation, she spoke on land registration in the Amazon Rainforest in Brazil. The problem she wanted to address was: does the environmental registrar discourage deforestation? To answer this question, she took data from registered property boundaries and found that people lied about where their property boundaries lie and often said they owned less land than they did. This highlights potential flaws in the current land registration system, which are a detriment in raising conservation efforts. Additionally, she also spoke on monitoring the change in tropical forest landscapes, specifically the land covered change in Uganda. Noticing more trees were being planted rather than food production increasing, she asked the question: who is planting these trees and why? She took data from surveys connected to field-mapped woodlot polygons where the woodlots are owned by non-local people. Professor L’Roe tied in this research to a related problem of: as competition for land increases what happens to local youth? To answer this related question, she took quantitative and qualitative surveys over periods of time and found that mothers would rather invest in education rather than land because it was a safer bet for the success and future of their children. Finally, in her presentation, she had an overarching theme that women make big and important contributions to data science and conservation with data. She also emphasized the importance of women role models in the field and how the lack of women in data science and STEM should not discourage women from taking part in it. I especially took away how she mentioned that anything can be data because I did not imagine data science could be taken to the work of land conservation.\nFor the final lightning talk, Professor Laura Biester spoke on her study on computational linguistics models for mental health. She needed to collect text data for mental health research, but it was a huge challenge due to privacy. Thus, she had to rely on using “self-reports.” In her work, she found that self-reports give hints on when the user was first diagnosed with depression, so she turned to Reddit to collect data files from 2006 to 2019 from people who self-reported. She collected statistics from users and then collected all of their posts from Reddit. In the end, she had about 20,500 diagnosed users and nine controls per user. After getting the data, she worked to normalize the models and classify it with a linear model. She found that model weights for pre-diagnosis models correspond more to symptoms while weights for all-encompassing models correspond more to mental health discussion. In her presentation, I learned that computational linguistics models can provide valuable insights into mental health trends, and there are always ways to get access to the data you need for your research.\n\n\nKeynote Presentation by Dr. Sarah M. Brown\nFollowed by the lightning talks, a keynote presentation was given by Dr. Sarah M. Brown. She started by talking about how data science skills can be found in unexpected places, which is true as proven by the professors who gave the three lightning talks. She also spoke on making machine learning more fair, which is something we have been analyzing and discussing in our Machine Learning 451 course at Middlebury College. For this, she mentioned thinking of machine learning as a sociotechnical system and growing our toolbox in data science. To grow the tool box, she spoke on three different projects she has worked on that gave her more tools to add into her toolbox. These three tools, which she calls keys, she explained during her talk and said they were helpful in solving problems in data science.\nThe first project she spoke on used the skill from 2004 which included using context to understand primary sources and importantly mentioned that data is a primary source. This project took place in 2012 that consisted of a patient and clinician seeing if the patient has PTSD, but instead of the clinician diagnosing, it would be the computer. There were scores to differentiate between the people who had PTSD and they were ranked on a scale. The key taken from this project was to understand the data’s context as it can enhance the accuracy and reliability of computational models. The second project’s skill is from her experience in 2009 where, within a given field, the same work can have different meanings in other fields. The key taken away is that disciplines are communities. The third project’s skill is tied to the second where everyone has different rules and ways of running things at the national, regional and chapter level. Thus, the key is to meet people where they are. With this third project, she needed a model to quantify fairness. She wanted to maximize what the feature says about the value variable and minimize the features with what is being fitted, in her research case it is accuracy compared to fairness.\nShe says data is biased because the world is biased, which is the reason biased models exist and why machine learning can be biased. She says choosing data to retrain data makes better data and, in order to solve these biases, creative thinking is a requirement. I really took away from these points as it is true that data is biased and it is those who are affected by the models, usually marginalized people, who want to work to fix the biased models.\n\n\nConclusion and Reflection\nFrom this blog post, I learned that women believe they cannot succeed in math-heavy fields, such as engineering and computing, because society falsely tells them they are not as intelligent as men when it comes to mathematics. I did not know there was such an extensive history behind the reasons the under representation exists in the first place, such as gaming being the reason men decided to take up computing and because of the head start on education men had in the 1800s. Learning about the different barriers deterring women from getting a degree in a STEM field made me reflect and become aware that these were also things I found myself telling myself in order to not pursue computer science as a major, and thoughts I find myself thinking of now at times. However, reading about why it is important for women to be represented and noting everything I and the world would be missing out on in regards to growth opportunities from women partaking in computing and learning about the important work women are doing in data science, it makes me proud of the work I am doing. Moreover, I also learned that all things can be data and data can be found anywhere. My biggest takeaway was the mention of bias in data and how that creates biased machines. I never thought that data was biased as data is science and science has proof behind it. However, after listening to Dr. Brown’s talk and connecting it to the discussions and readings we have done in class, I realized we do live in a biased world where we have to question and be skeptical of the way and the data was gathered and the methods used. This being said, I am interested in learning more on the collection of data and finding ways to make is as less biased as possible."
  },
  {
    "objectID": "posts/optimal-decision-making/index.html",
    "href": "posts/optimal-decision-making/index.html",
    "title": "Optimal Decision Making",
    "section": "",
    "text": "Introduction\n\nIn this blog post, I start off by making different graphs and tables to see if there is any correlation and patterns between a person’s information and seeing how the interest rate is affected by this information. Then, I used logistic regression to construct a score function and threshold for predicting whether a prospective borrower is likely to default on a given loan. Looping through the max and min scores, I found the best threshold to maximize the bank’s profit by calculating how much the bank will gain or lose based on if the person with that score defaults or not from paying the loan. In my test results, I got that the best threshold was about -0.175 with the bank’s expected profit per borrower to be about $1168.39.\nIn seeing if certain groups have more difficulty than others in getting a loan because of defaulting based on the threshold proposed from the system, all of the borrowers have a decision, or probability, of defaulting based on the threshold. There might be an error or missing step in my calculations.\n\n\n\nPart A: Grab the Data\n\n# downloading training data\n\nimport pandas as pd\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n\ndf_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n\n\n\n\n\n\n\nPart B: Explore The Data\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nsns.scatterplot(data = df_train, x = 'loan_int_rate', y = 'loan_percent_income', hue = 'cb_person_default_on_file')\nplt.title(\"Loan interest rate and loan percent income based on person defaulting\")\nplt.show()\n\n\n\n\n\n\n\n\nIn this scatterplot, we can see the how the loan interest rate is affected by seeing if the person defaulted previously on a loan and the person’s percent income. The loan interest rate increases if the person has a record of defaulting on a loan.\n\nsns.boxplot(data = df_train, x = 'person_home_ownership', y = 'loan_int_rate')\nplt.title(\"Interest Rate Based on a Person's Home Ownership\")\nplt.show()\n\n\n\n\n\n\n\n\nThis graph further explores how the loan interest rate differs and compares based on a person’s home ownership. We can see that a person who has a mortgage has a lower mean for the interest rate, while a person renting and those with other forms of home ownership have higher loan interest rates on average.\n\nmeanTable = df_train.groupby(['loan_intent', 'cb_person_default_on_file']).aggregate({'person_age': ['mean', 'std'], 'person_income' : ['mean', 'std'], 'cb_person_cred_hist_length' : ['mean', 'std'], 'loan_int_rate': ['mean', 'std']})\nmeanTable\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\ncb_person_cred_hist_length\nloan_int_rate\n\n\n\n\nmean\nstd\nmean\nstd\nmean\nstd\nmean\nstd\n\n\nloan_intent\ncb_person_default_on_file\n\n\n\n\n\n\n\n\n\n\n\n\nDEBTCONSOLIDATION\nN\n27.523949\n5.822429\n66504.540596\n54849.658619\n5.644276\n3.915509\n10.216206\n3.008325\n\n\nY\n27.883289\n6.379513\n67551.327586\n58425.810386\n5.928382\n4.121033\n14.565023\n1.758878\n\n\nEDUCATION\nN\n26.505755\n6.058923\n64403.688983\n40406.252292\n5.074231\n3.572837\n10.273948\n2.967930\n\n\nY\n27.047126\n6.009493\n61127.258621\n35589.171553\n5.471264\n3.910798\n14.357234\n1.650609\n\n\nHOMEIMPROVEMENT\nN\n29.088624\n5.637893\n72891.920750\n49281.092741\n6.512995\n3.964697\n10.358453\n3.158075\n\n\nY\n28.529730\n5.966250\n73886.228829\n52241.077202\n6.079279\n3.974765\n14.576099\n1.739466\n\n\nMEDICAL\nN\n27.927044\n6.376993\n61528.271447\n48179.985735\n5.912201\n4.004978\n10.281730\n2.989114\n\n\nY\n28.061628\n6.322874\n60326.900000\n59500.584963\n5.919767\n4.109030\n14.531599\n1.718297\n\n\nPERSONAL\nN\n28.361028\n7.562245\n68244.272206\n113892.066168\n6.190763\n4.709577\n10.280876\n2.981917\n\n\nY\n27.933244\n6.696901\n67221.606142\n57537.660727\n5.958611\n4.295520\n14.536935\n1.737584\n\n\nVENTURE\nN\n27.589281\n6.216285\n65544.232157\n46928.520701\n5.745882\n3.957178\n10.189561\n2.935957\n\n\nY\n27.585551\n5.808216\n68787.400507\n82746.627032\n5.735108\n4.021774\n14.544407\n1.740218\n\n\n\n\n\n\n\nIn this table, part of the data is summarized by finding the mean and the standard deviation of a person’s age, their income, their credit history length, and their given loan interest rate based on their loan intent and whether or not they defaulted previously on a loan. This table is helpful as we can see what factors play into having a higher interest rate, and we can see how age, income, or their credit history length varies based on defaulting on a loan and their loan intent. The standard deviation is important to see how much of the data falls into or out of the calculated mean.\n\n\nPart C: Building a Model:\nConstruct a score function and threshold for predicting whether a prospective borrower is likely to default on a given loan. You may use all the features in the data except loan_grade and the target variable loan_status.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(df_train[\"loan_status\"]) #fit encoder on 'loan_status'\n\ndef prepare_data(df):\n  #removing columns that are not needed\n  df = df.drop([\"loan_grade\"], axis = 1)\n  #removing N/A labels\n  df = df.dropna()\n  #print(df)\n  #turns the labels in 'loan_status' to a number\n  y = le.transform(df[\"loan_status\"])\n  #print(y)\n  #removing 'loan_status' col bc now held by y\n  df = df.drop([\"loan_status\"], axis = 1)\n  #converted into “one-hot encoded” 0-1 columns\n  df = pd.get_dummies(df)\n  return df, y\n\n\nX_train, y_train = prepare_data(df_train)\n\n\n\ny_train\n\narray([0, 0, 1, ..., 0, 0, 1])\n\n\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score #use this isntead of for-loop\nfrom sklearn.linear_model import LogisticRegression\nimport random\n\nquant_cols = ['person_income', 'loan_amnt', 'loan_int_rate']\n\nscore_counter = 0\n\nLR = LogisticRegression()\n\n#using cross validation on LR to avoid overfitting\ncv_scores_LR = cross_val_score(LR, X_train[quant_cols], y_train, cv = 5) #training on remaining 80% of data\nif cv_scores_LR.mean() &gt; score_counter:\n      #updating the best score and columns of that score\n      score_counter = cv_scores_LR.mean()\n\nprint('Best Score: ', score_counter)\n\nBest Score:  0.8117172718507574\n\n\n\nX_train\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_percent_income\ncb_person_cred_hist_length\nperson_home_ownership_MORTGAGE\nperson_home_ownership_OTHER\nperson_home_ownership_OWN\n...\nloan_intent_HOMEIMPROVEMENT\nloan_intent_MEDICAL\nloan_intent_PERSONAL\nloan_intent_VENTURE\ncb_person_default_on_file_N\ncb_person_default_on_file_Y\npaid_gain\ndefault_loss\nScores\ndecision\n\n\n\n\n1\n27\n98000\n3.0\n11750\n13.47\n0.12\n6\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n4613.567568\n-6997.533847\n-2.724145\nFalse\n\n\n2\n22\n36996\n5.0\n10000\n7.51\n0.27\n4\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n2044.334031\n-6426.108799\n-0.435472\nFalse\n\n\n3\n24\n26000\n2.0\n1325\n12.87\n0.05\n4\nFalse\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\n493.650464\n-795.445199\n-0.913722\nFalse\n\n\n4\n29\n53004\n2.0\n15000\n9.63\n0.28\n10\nTrue\nFalse\nFalse\n...\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n4028.690420\n-9390.333437\n-0.552180\nFalse\n\n\n6\n21\n21700\n2.0\n5500\n14.91\n0.25\n2\nFalse\nFalse\nFalse\n...\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n2430.522429\n-3211.752128\n-0.294372\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n26059\n36\n150000\n8.0\n3000\n7.29\n0.02\n17\nTrue\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n593.840622\n-1932.967484\n-5.766362\nFalse\n\n\n26060\n23\n48000\n1.0\n4325\n5.42\n0.09\n4\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\n623.093432\n-2849.295748\n-1.486665\nFalse\n\n\n26061\n22\n60000\n0.0\n15000\n11.71\n0.25\n4\nFalse\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nTrue\nFalse\n5017.300210\n-9143.682505\n-0.836032\nFalse\n\n\n26062\n30\n144000\n12.0\n35000\n12.68\n0.24\n8\nTrue\nFalse\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\n12819.204794\n-21064.871625\n-2.113038\nFalse\n\n\n26063\n25\n60000\n5.0\n21450\n7.29\n0.36\n4\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n4245.960448\n-13820.717511\n-0.148728\nFalse\n\n\n\n\n22907 rows × 23 columns\n\n\n\n\ny_train\n\narray([0, 0, 1, ..., 0, 0, 1])\n\n\n\nLR.fit(X_train[quant_cols], y_train)\nw = LR.coef_\nLR.score(X_train[quant_cols], y_train)\n\n\n0.8080062862880342\n\n\n\nw\n\narray([[-4.05735976e-05,  1.06558819e-04,  9.49045880e-08]])\n\n\n\n#finding the scores\nx = X_train[quant_cols]\nx\n\n\n\n\n\n\n\n\nperson_income\nloan_amnt\nloan_int_rate\n\n\n\n\n1\n98000\n11750\n13.47\n\n\n2\n36996\n10000\n7.51\n\n\n3\n26000\n1325\n12.87\n\n\n4\n53004\n15000\n9.63\n\n\n6\n21700\n5500\n14.91\n\n\n...\n...\n...\n...\n\n\n26059\n150000\n3000\n7.29\n\n\n26060\n48000\n4325\n5.42\n\n\n26061\n60000\n15000\n11.71\n\n\n26062\n144000\n35000\n12.68\n\n\n26063\n60000\n21450\n7.29\n\n\n\n\n22907 rows × 3 columns\n\n\n\n\nscores = x@w.T\nscores\n\n\n\n\n\n\n\n\n0\n\n\n\n\n1\n-2.724145\n\n\n2\n-0.435472\n\n\n3\n-0.913722\n\n\n4\n-0.552180\n\n\n6\n-0.294372\n\n\n...\n...\n\n\n26059\n-5.766362\n\n\n26060\n-1.486665\n\n\n26061\n-0.836032\n\n\n26062\n-2.113038\n\n\n26063\n-0.148728\n\n\n\n\n22907 rows × 1 columns\n\n\n\n\n\nPart D: Finding a Threshold\nFind a threshold that maximizes the bank’s profit.\n\nimport numpy as np\n\n#calculate paid gain and loss here and add these array values in the columns of the table\n#vectorization\nint_rate_decimal = np.divide(X_train['loan_int_rate'], 100)\nX_train['paid_gain'] = X_train['loan_amnt'] * (1 + 0.25 * int_rate_decimal)**10 - X_train['loan_amnt']\nX_train['default_loss'] = X_train['loan_amnt'] * (1 + 0.25 * int_rate_decimal)** - 1.7 * X_train['loan_amnt']\nX_train['Scores'] = scores\n\n\nX_train['Scores']\n\n1       -2.724145\n2       -0.435472\n3       -0.913722\n4       -0.552180\n6       -0.294372\n           ...   \n26059   -5.766362\n26060   -1.486665\n26061   -0.836032\n26062   -2.113038\n26063   -0.148728\nName: Scores, Length: 22907, dtype: float64\n\n\n\nall_total_profit = []\nbest_profit = 0\ntotal_t_profit = 0\n\nfor threshold in np.linspace(scores.min(), scores.max(), 100): #np.linspace(scores.min(), scores.max(), 100)\n    #new col in for loop that makes the decision \"decision col\" checks if score is larger than threshold\n    X_train['decision'] = X_train['Scores'] &gt;= threshold[0] #returns bool threshold[0] with np.linspace\n\n\n    t_profit = (1 - X_train['decision']) * (X_train['paid_gain'] * (1 - y_train) + X_train['default_loss'] * (y_train))\n\n    # t_profit = (1-threshold) * (X_train['paid_gain'] + threshold * X_train['default_loss'])\n    \n    # print(f\"{X_train['paid_gain']= }\")\n    # print(f\"{X_train['default_loss']= }\")\n\n    #calculating mean profit\n    all_total_profit.append(t_profit.mean())\n\n    #return highest threshold based on highest gain\n    if t_profit.mean() &gt; best_profit:\n        best_profit = t_profit.mean()\n        best_t = threshold[0] #threshold[0] with np.linspace\n        profit_per_borrower = t_profit.mean()\n\n\n        #find probability and loop through thresholds\nprint(total_t_profit)\nprint('highest profit: ', best_profit)\nprint('best threshold that optimizes profit for the bank: ', best_t)\nprint('bank’s expected profit per borrower: ', profit_per_borrower)\n\n0\nhighest profit:  1158.6189787929175\nbest threshold that optimizes profit for the bank:  -0.9466451695144542\nbank’s expected profit per borrower:  1158.6189787929175\n\n\n\n#threshold vs profit (all_total_profit)\nplt.plot(np.linspace(scores.min(), scores.max(), 100), all_total_profit)\nplt.gca().set(xlim=(-7,None))\nplt.grid(True)\nplt.axvline(x = best_t, color = 'red', linestyle = '--', lw = 1)\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Total Profit\")\nplt.title(\"Threshold vs. Total Profit\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPart E: Evaluate Your Model from the Bank’s Perspective\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\nX_test, y_test = prepare_data(df_test)\nLR.score(X_test[quant_cols], y_test)\nx = X_test[quant_cols]\ntest_scores = x@w.T\n\nFinding threshold of testing set:\n\nimport numpy as np\n\n#calculate paid gain and loss here and add these array values in the columns of the table\n#vectorization\nint_rate_decimal = np.divide(X_test['loan_int_rate'], 100)\nX_test['paid_gain'] = X_test['loan_amnt'] * (1 + 0.25 * int_rate_decimal)**10 - X_test['loan_amnt']\nX_test['default_loss'] = X_test['loan_amnt'] * (1 + 0.25 * int_rate_decimal)**3 - 1.7 * X_test['loan_amnt']\nX_test['Scores'] = test_scores\n\n\nall_total_profit = []\nbest_profit = 0\ntotal_t_profit = 0\n\nfor threshold in np.linspace(test_scores.min(), test_scores.max(), 100):\n    #new col in for loop that makes the decision \"decision col\" checks if score is larger than threshold\n    X_test['decision'] = X_test['Scores'] &gt; threshold[0] #returns bool threshold[0] with np.linspace\n\n    t_profit = (1 - X_test['decision']) * (X_test['paid_gain'] * (1 - y_test) + X_test['default_loss'] * (y_test))    \n\n    #calculating mean profit\n    all_total_profit.append(t_profit.mean())\n\n    #return highest threshold based on highest gain\n    if t_profit.mean() &gt; best_profit:\n        best_profit = t_profit.mean()\n        best_t = threshold[0] #threshold[0] with np.linspace\n        profit_per_borrower = t_profit.mean()\n\n\n        #find probability and loop through thresholds\nprint(total_t_profit)\nprint('highest profit: ', best_profit)\nprint('best threshold that optimizes profit for the bank: ', best_t)\nprint('bank’s expected profit per borrower: ', profit_per_borrower)\n\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0       True\n1       True\n2       True\n3       True\n4       True\n        ... \n6511    True\n6513    True\n6514    True\n6515    True\n6516    True\nName: decision, Length: 5731, dtype: bool\n0        True\n1        True\n2       False\n3        True\n4       False\n        ...  \n6511     True\n6513     True\n6514     True\n6515    False\n6516     True\nName: decision, Length: 5731, dtype: bool\n0       False\n1        True\n2       False\n3       False\n4       False\n        ...  \n6511    False\n6513     True\n6514     True\n6515    False\n6516    False\nName: decision, Length: 5731, dtype: bool\n0       False\n1       False\n2       False\n3       False\n4       False\n        ...  \n6511    False\n6513    False\n6514    False\n6515    False\n6516    False\nName: decision, Length: 5731, dtype: bool\n0       False\n1       False\n2       False\n3       False\n4       False\n        ...  \n6511    False\n6513    False\n6514    False\n6515    False\n6516    False\nName: decision, Length: 5731, dtype: bool\n0       False\n1       False\n2       False\n3       False\n4       False\n        ...  \n6511    False\n6513    False\n6514    False\n6515    False\n6516    False\nName: decision, Length: 5731, dtype: bool\n0\nhighest profit:  1168.3899694144973\nbest threshold that optimizes profit for the bank:  -0.17519863260740465\nbank’s expected profit per borrower:  1168.3899694144973\n\n\n\n#threshold vs profit (all_total_profit)\nplt.plot(np.linspace(test_scores.min(), test_scores.max(), 100), all_total_profit)\nplt.gca().set(xlim=(-7,None))\nplt.grid(True)\nplt.axvline(x = best_t, color = 'red', linestyle = '--', lw = 1)\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Total Profit\")\nplt.title(\"Threshold vs. Total Profit\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPart F: Evaluate Your Model From the Borrower’s Perspective\nIs it more difficult for people in certain age groups to access credit under your proposed system?\n\nimport seaborn as sns\n\nX_test['age_cat'] = pd.cut(X_test['person_age'], range(0,70, 10))\n\napproval_rate_percent = X_test.groupby('age_cat')['decision'].mean() * 100\nplt.figure(figsize=(11,5))\nsns.barplot(X_test, x = approval_rate_percent.index, y = approval_rate_percent.values)\nplt.xlabel('Age Group')\nplt.ylabel('Approval Rate Percent')\nplt.grid(True)\nplt.show()\n#(X_test['person_age'], y_test)\n\n/var/folders/1j/mlsnh9t96n70j2n5mmm9h9780000gn/T/ipykernel_11168/2421308665.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  approval_rate_percent = X_test.groupby('age_cat')['decision'].mean() * 100\n/Users/ddelgado/anaconda3/envs/ml-0451/lib/python3.9/site-packages/seaborn/categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grouped_vals = vals.groupby(grouper)\n\n\n\n\n\n\n\n\n\nSince, all of my decision column has the boolean true, they are all 0.0 floats. Therefore, no one age group has more difficulty in getting a loan in the proposed system.\nIs it more difficult for people to get loans in order to pay for medical expenses? How does this compare with the actual rate of default in that group? What about people seeking loans for business ventures or education?\n\nloan_intent_rate = X_test.groupby(['loan_intent_EDUCATION', 'loan_intent_MEDICAL', 'loan_intent_VENTURE']).aggregate({'decision' : 'mean', 'cb_person_default_on_file_N' : 'mean', 'cb_person_default_on_file_Y' : 'mean'})\nprint(loan_intent_rate)\n\n                                                               decision  \\\nloan_intent_EDUCATION loan_intent_MEDICAL loan_intent_VENTURE             \nFalse                 False               False                     0.0   \n                                          True                      0.0   \n                      True                False                     0.0   \nTrue                  False               False                     0.0   \n\n                                                               cb_person_default_on_file_N  \\\nloan_intent_EDUCATION loan_intent_MEDICAL loan_intent_VENTURE                                \nFalse                 False               False                                   0.809770   \n                                          True                                    0.816390   \n                      True                False                                   0.835974   \nTrue                  False               False                                   0.816327   \n\n                                                               cb_person_default_on_file_Y  \nloan_intent_EDUCATION loan_intent_MEDICAL loan_intent_VENTURE                               \nFalse                 False               False                                   0.190230  \n                                          True                                    0.183610  \n                      True                False                                   0.164026  \nTrue                  False               False                                   0.183673  \n\n\nSince the decision column is all zeros, the comparison here is that the approval rate, or the decision, is less than the actual default rate for each education, medical and venture groups.\nHow does a person’s income level impact the ease with which they can access credit under your decision system?\n\n#income_groups = pd.cut(X_test['person_income'], range(4800,1782000, 10))\napproval_rate_income = X_test.groupby(pd.cut(X_test['person_income'], 25))['decision'].mean()\nprint(approval_rate_income)\n\nperson_income\n(3022.8, 75888.0]         0.0\n(75888.0, 146976.0]       0.0\n(146976.0, 218064.0]      0.0\n(218064.0, 289152.0]      0.0\n(289152.0, 360240.0]      0.0\n(360240.0, 431328.0]      0.0\n(431328.0, 502416.0]      0.0\n(502416.0, 573504.0]      0.0\n(573504.0, 644592.0]      NaN\n(644592.0, 715680.0]      0.0\n(715680.0, 786768.0]      0.0\n(786768.0, 857856.0]      0.0\n(857856.0, 928944.0]      NaN\n(928944.0, 1000032.0]     NaN\n(1000032.0, 1071120.0]    NaN\n(1071120.0, 1142208.0]    NaN\n(1142208.0, 1213296.0]    0.0\n(1213296.0, 1284384.0]    NaN\n(1284384.0, 1355472.0]    NaN\n(1355472.0, 1426560.0]    NaN\n(1426560.0, 1497648.0]    NaN\n(1497648.0, 1568736.0]    NaN\n(1568736.0, 1639824.0]    NaN\n(1639824.0, 1710912.0]    NaN\n(1710912.0, 1782000.0]    0.0\nName: decision, dtype: float64\n\n\n/var/folders/1j/mlsnh9t96n70j2n5mmm9h9780000gn/T/ipykernel_11168/4155170202.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  approval_rate_income = X_test.groupby(pd.cut(X_test['person_income'], 25))['decision'].mean()\n\n\nA person’s income level does not impact the ease in which a person can access credit under the decision system as the decision says the mean is 0.0\n\n\nConclusion\n\nIn this blog post, what I learned was that something in my decisions might be calculated wrong or I might be missing something as all of my decisions say they are True for defaulting. If everything is correct, I learned that everyone is set to default on the loan, so there really is no difference between groups of people.\n\nConsidering that people seeking loans for medical expense have high rates of default, is it fair that it is more difficult for them to obtain access to credit?\n\nAssuming my data showed that people seeking loans for medical expenses have higher rates of defaulting, I believe that it is fair for them to have more difficulty in obtaining access to credit. In this sense, it is fair because the bank has to think in terms of itself and if the people who seek medical expenses cannot pay the loan back, it is fair for the bank to deny their loan as it is money the bank will be losing. If something is fair, it does not mean it is morally correct. In this case, fairness is based on the system proposed and if a borrower falls into the given threshold for loan acceptance based on different factors. However, I would say it is not fair according to morals to deny the loan for their medical expenses as they need the money to get treatment/medication in order to remain alive."
  },
  {
    "objectID": "posts/classifying-penguins/index.html",
    "href": "posts/classifying-penguins/index.html",
    "title": "Classifying Palmer Penguins Post",
    "section": "",
    "text": "Abstract\nIn this blog post, we will predict the species of a penguin based on its measurements and aim to achieve 100% testing accuracy with my select choice in model. First, I will do data preparation where I will clean the dataset by removing unnecessary columns, labels, and, of course, the species column. Then, by looking at this new dataset, I will make graphs using seaborn based on the information given to see if I can spot any patterns that can help identify a penguin’s species. In my graphs, I look at flipper length in relation to body mass, culmen depth and length in relation to the penguin’s sex, and the correlation between the penguin’s culmen depth and lengh with the flipper length. Then I made a summary table where I found the mean and the standard deviation of the culmen length and depth, the flipper length, and the body mass of the penguins on each island based on their sex to see the areas where penguins had a closer correlation to. Then, using LogisticRegression and DecisionTreeClassifier, we will find the best mean score and its corresponding column out of every set of 3 features- two quantitative and one qualitative features. We will also test this on our testing data. Afterwards, we will plot a graph panel of decision regions for the classifiers where we will see the DTC predictions for the penguin species based on the best column we got from finding the best mean with the DTC. Finally, we will see the errors our prediction model made in comparison to the actual data by looking at a color-coded confusion matrix.\nAs the results will show, the DecisionTreeClassifier model worked better than the LogisticRegression model yet, in the test data, LogisticRegression returned a better output with 100% while DTC returned about 98.5% accuracy. This can be due to the depth limit placed on the DTC in comparison to no limit set on the LR model. Additionally, the confusion matrix showed the DTC made a very small margin error with one penguin being mislabeled. The prediction DTC classified this penguin as Chinstrap when it was actually a Gentoo penguin. Overall, the prediction model was accurate.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\nIn the code above, I am first getting the data.\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nDown below, I am beginning to clean the data by getting rid of unnecessary columns and data, and creating my training sets.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"]) #fit encoder on 'Species'\n\ndef prepare_data(df):\n  #removing columns that are not needed\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  #removing when sex = .\n  df = df[df[\"Sex\"] != \".\"]\n  #removing N/A labels\n  df = df.dropna()\n  #turns the labels in 'Species' to a number\n  y = le.transform(df[\"Species\"])\n  #print(y)\n  #removing 'Species' col bc now held by y\n  df = df.drop([\"Species\"], axis = 1)\n  #converted into “one-hot encoded” 0-1 columns\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\nPart 1: Exploring the data:\nHere, I constructed three interesting displayed figures and one summary table that will help draw conclusions about what features I can use for the model (DTC model).\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nsns.scatterplot(data = X_train, x = 'Flipper Length (mm)', y = 'Body Mass (g)', hue = 'Flipper Length (mm)')\n\nplt.title('Scatterplot of Flipper Length in Relation to Body Mass')\nplt.show()\n\n\n\n\n\n\n\n\nIn this graph, we see the correlation between the flipper length and the body mass of penguins as the data is grouped by the flipper length. In the graph, the correlation between both seems to be positive as the longer the flipper length, the higher the body mass. This can help define a species as maybe some penguin species are smaller, which would allow us to know their body mass is lighter, thus their flipper length is smaller as well. This can be used in my model as it can use the weigths/sizes of penguins to possibibly help distinguish the species, along with the help of looking at other features to understand the outlier points in this set.\n\nsns.scatterplot(data = X_train, x = 'Culmen Length (mm)', y = 'Culmen Depth (mm)', hue = 'Sex_FEMALE')\nplt.title('Culmen Length and Depth Based on Gender')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIn this graph, we can see the culmen depth and length in relation to the penguin’s sex. The female culmens tend to be on the lower half of the graph. There also seems to be three different clusters: one on the middle left averaging on the point (40,18), another one starting at (45,16) and expanding upwards right to (50,20), and the final one being on the mid-lower part of the graph at about (45,14) to (50,16). In these three clusters, the female’s culmen dimensions are smaller than the men’s. This can tell us that the species of penguins all have different culmen lengths and depths, and they vary by sex. Thus, the penguin species can be distinguishable by their culmen sizes. This information can be useful in modeling as we can see if the culmen length and culmen depth compared to the gender play a role in distinguishing the species.\n\nsns.scatterplot(data = X_train, x = 'Culmen Length (mm)', y = 'Culmen Depth (mm)', hue = 'Flipper Length (mm)')\nplt.title('Correlation Between Culmen Length and Depth, and Flipper Length')\nplt.show()\n\n\n\n\n\n\n\n\nIn this graph, we can see the correlation between the flipper length and the culmen depth/length. We can see how the deeper the culmen depth goes, the smaller the flipper and culmen lengths are. If the penguin has a medium to high range in culmen length with a lower depth, then the flipper lenght is longer. However, if both the culmen length and depth are high, then the flipper length is in about the middle size. This information can be used in modeling as we can see if the species of the penguins are identifiable based on the different correlations between the culmen dimensions and the flipper length.\n\nmeanTable = X_train.groupby(['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Sex_MALE', 'Sex_FEMALE']).aggregate(\n    {'Culmen Length (mm)' : ['mean', 'std'], 'Culmen Depth (mm)' : ['mean', 'std'], 'Flipper Length (mm)' : ['mean', 'std'], 'Body Mass (g)' : ['mean', 'std']})\nmeanTable\n\n\n\n\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\n\n\n\n\n\n\n\nmean\nstd\nmean\nstd\nmean\nstd\nmean\nstd\n\n\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nSex_MALE\nSex_FEMALE\n\n\n\n\n\n\n\n\n\n\n\n\nFalse\nFalse\nTrue\nFalse\nTrue\n37.537500\n2.111200\n17.475000\n0.863713\n188.000000\n4.661902\n3309.375000\n251.143219\n\n\nTrue\nFalse\n40.961111\n3.273268\n19.300000\n1.058856\n196.000000\n5.455704\n4100.000000\n370.611577\n\n\nTrue\nFalse\nFalse\nTrue\n43.041176\n5.368843\n17.629412\n0.767670\n190.784314\n5.923896\n3471.078431\n267.225212\n\n\nTrue\nFalse\n46.176087\n5.930081\n19.058696\n0.971271\n196.782609\n7.828475\n4027.173913\n328.541647\n\n\nTrue\nFalse\nFalse\nFalse\nTrue\n43.423077\n4.061703\n15.093846\n1.727795\n206.507692\n11.936189\n4356.538462\n655.569244\n\n\nTrue\nFalse\n46.595000\n4.511583\n16.696667\n1.738007\n212.366667\n15.248192\n5076.250000\n721.116498\n\n\n\n\n\n\n\nIn this table, we can see the mean and standard deviation values for the culmen length and depth, the flipper length, and the body mass of the penguins on each island based on their sex. This table can be helpful as we can see the how the dimensions differ based on the island the penguins are on and their sex. These can be a telling factor on the kind of species they are by seeing the grouping they fall into and if the standard deviation is too big, then we know there are more outliers that are not close to the mean. Thus, this shows that there might not be a correlatioin with that said data.\nPart 2: Choosing Features\nThe code below is a modified version of the code Phil provided in the notes of this assignment. What is going on in this block of code is that I first chose the qualitative and quantitative columns that I wanted to compare and look into. Then, I created unique pairs of the quantitative columns and added a qualitative column to the pairings, so I formed groups of three, and ran the logistic regression model on the columns. When thinking of the approach in choosing the final three features, I used cross validation on the training data to account for overfitting. If the CR mean score was greater than the score counter, then I updated the score counter to be the value of the CR mean. I then got the column names that were associated with the best score and returned them.\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score #use this isntead of for-loop\nfrom sklearn.linear_model import LogisticRegression\nimport warnings\n\nwarnings.filterwarnings('ignore')\n#warnings.filterwarnings('ignore', category = FutureWarning)\n\n\nscore_counter = 0\n# these are not actually all the columns: you'll\n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\", \"Egg Stage\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = list(pair) + qual_cols\n    print(cols)\n    # training LR model and scoring it\n    LR = LogisticRegression()\n    #using cross validation on LR to avoid overfitting\n    cv_scores_LR = cross_val_score(LR, X_train[cols], y_train, cv = 5) #training on remaining 80% of data\n\n    if cv_scores_LR.mean() &gt; score_counter:\n      #updating the best score and columns of that score\n      score_counter = cv_scores_LR.mean()\n      col_best = cols\n\nprint('Best Score: ', score_counter)\nprint('Best Three Columns: ', col_best)\n\n\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Length (mm)', 'Flipper Length (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Length (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Depth (mm)', 'Flipper Length (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Depth (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Flipper Length (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Length (mm)', 'Flipper Length (mm)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Length (mm)', 'Body Mass (g)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Depth (mm)', 'Flipper Length (mm)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Depth (mm)', 'Body Mass (g)', 'Sex_FEMALE', 'Sex_MALE']\n['Flipper Length (mm)', 'Body Mass (g)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Length (mm)', 'Flipper Length (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Length (mm)', 'Body Mass (g)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Depth (mm)', 'Flipper Length (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Depth (mm)', 'Body Mass (g)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Flipper Length (mm)', 'Body Mass (g)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Stage_Adult, 1 Egg Stage']\n['Culmen Length (mm)', 'Flipper Length (mm)', 'Stage_Adult, 1 Egg Stage']\n['Culmen Length (mm)', 'Body Mass (g)', 'Stage_Adult, 1 Egg Stage']\n['Culmen Depth (mm)', 'Flipper Length (mm)', 'Stage_Adult, 1 Egg Stage']\n['Culmen Depth (mm)', 'Body Mass (g)', 'Stage_Adult, 1 Egg Stage']\n['Flipper Length (mm)', 'Body Mass (g)', 'Stage_Adult, 1 Egg Stage']\nBest Score:  0.9961538461538462\nBest Three Columns:  ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n\n\nHere, I fit the data of the final columns chosen from the code above using logistic regression to calculate the score.\n\n# LR with the selected better columns from the code above\ncols = col_best\n\nLR = LogisticRegression()\nLR.fit(X_train[cols], y_train)\nLR.score(X_train[cols], y_train)\n\n0.99609375\n\n\nNow to test LogisticRegression:\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nLR.score(X_test[cols], y_test)\n\n1.0\n\n\nOn the test set, logistic regression returned a 100% accuracy!\nUsing DecisionTreeClassifier instead of Logistic Regression, here is another model choice:\n\nSimilar to the code blocks above where I worked with the LR model, the code below uses the modified version of the code Phil provided in the notes of this assignment. Additionally, I took unique pairs of quantitative columns and a random qualitative column (three features total) that I chose to make the comparisons. On these groupings, I ran the decision tree classifier model where I set the depth to be a range between 1 and 19 to test it. I used cross validation on the model and testing set once again to avoid overfitting. To figure out the best grouping of features to look at, I saw if the mean of the CR score was greater than the score counter, and it it was, I updated the score counter to be the value of the CR mean. I then got the column names that were associated with the best score and returned them.\n\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score #use this isntead of for-loop\nfrom sklearn.tree import DecisionTreeClassifier\n\nscore_counter = 0\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island\", \"Egg Stage\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nfor qual in all_qual_cols:\n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols =  list(pair) + qual_cols\n    print(cols)\n\n    for i in range(1,20):\n      #setting the max depth to be between 1-19 and iterating through each one\n      DTC = DecisionTreeClassifier(max_depth=i)\n      #using cross validation on DTC to avoid overfitting\n      cv_scores_DTC = cross_val_score(DTC, X_train[cols], y_train, cv = 5)\n      #updating the best score and columns of that score\n      if cv_scores_DTC.mean() &gt; score_counter:\n        score_counter = cv_scores_DTC.mean()\n        col_best = cols\n    \nprint('Best Score: ', score_counter)\nprint('Best Three Columns: ', col_best)\nprint('At depth: ', i)\n\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Length (mm)', 'Flipper Length (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Length (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Depth (mm)', 'Flipper Length (mm)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Depth (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Flipper Length (mm)', 'Body Mass (g)', 'Clutch Completion_No', 'Clutch Completion_Yes']\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Length (mm)', 'Flipper Length (mm)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Length (mm)', 'Body Mass (g)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Depth (mm)', 'Flipper Length (mm)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Depth (mm)', 'Body Mass (g)', 'Sex_FEMALE', 'Sex_MALE']\n['Flipper Length (mm)', 'Body Mass (g)', 'Sex_FEMALE', 'Sex_MALE']\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Length (mm)', 'Flipper Length (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Length (mm)', 'Body Mass (g)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Depth (mm)', 'Flipper Length (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Depth (mm)', 'Body Mass (g)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Flipper Length (mm)', 'Body Mass (g)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Stage_Adult, 1 Egg Stage']\n['Culmen Length (mm)', 'Flipper Length (mm)', 'Stage_Adult, 1 Egg Stage']\n['Culmen Length (mm)', 'Body Mass (g)', 'Stage_Adult, 1 Egg Stage']\n['Culmen Depth (mm)', 'Flipper Length (mm)', 'Stage_Adult, 1 Egg Stage']\n['Culmen Depth (mm)', 'Body Mass (g)', 'Stage_Adult, 1 Egg Stage']\n['Flipper Length (mm)', 'Body Mass (g)', 'Stage_Adult, 1 Egg Stage']\nBest Score:  0.9765460030165913\nBest Three Columns:  ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Sex_FEMALE', 'Sex_MALE']\nAt depth:  19\n\n\nHere, I fit the training data with the final features using the decision tree classifier model.\n\n#Feeding the best cols\ncols = col_best\n\nDTC = DecisionTreeClassifier(max_depth=i)\nDTC.fit(X_train[cols], y_train)\nDTC.score(X_train[cols], y_train)\n\n1.0\n\n\nFor the training set, it returns a 100% accuracy rate!\nNow to test the data we do:\n\n#download the test data set \ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n#prepping data\nX_test, y_test = prepare_data(test)\nDTC.score(X_test[cols], y_test)\n\n0.9852941176470589\n\n\n\nThe testing data did not reach 100% with the decision tree classifier model.\n\nNow we are going to plot a panel of decision regions for the classifiers:\n\nThis code was provided by Phil in the assignment notes as well.\n\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    #sets first two columns, which are quantitative, of X_train[cols]\n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    #says remaining columns are one-hot qualitative columns\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\nplot_regions(DTC, X_train[cols], y_train)\n\n\n\n\n\n\n\n\nFinally, we will show a confusion matrix on the DTC model, which will be evaluated on the test set.\n\nfrom sklearn.metrics import confusion_matrix\n\nactual = y_test\npredict = DTC.predict(X_test[cols])\n\nconf_matrix = confusion_matrix(actual, predict)\n\nprint(conf_matrix)\n\n[[31  0  0]\n [ 0 10  1]\n [ 0  0 26]]\n\n\nIn this confusion matrix, we see the error is low, but it is seen with the Gentoo and Chinstrap penguins. The data predicted one penguin to be Chinstrap when it was actually a Gentoo penguin. With this information, I do not believe there was an error greater than others as that seems to be the only error.\nDiscussion\nIn this blog post, I found that using a DecisionTreeClassifier model worked better than the LogisticRegression model as seen by the best score prints, yet, in the test data, LogisticRegression returned a better output with 100% while DTC returned about 98.5% accuracy. I believe this is because LR does not have a limit on the iterations while DTC has a set depth, which can limit it from getting to 100% accuracy. Furthermore, the graphs explored in the beginning did help classify the data to guess the correct species, specifically the penguin’s culmen dimensions correlating to its sex as that ended up being the best column outcome for the DTC! The three clusters I saw in that graph also proved to help identify the species as seen in the plotted graph panel of decision regions for the species classifiers. Lastly, as we can see from the confusion matrix, we can conclude the DTC prediction model is accurate.\nThrough the coding process, I learned and felt more comfortable in working with seaborn and the different graphs available to make since, in part one, I originally created about seven different graphs from pairplots, to boxplots, to bar graphs before deciding on my final three. Additionally, I learned what the DecisionTreeClassifies does and the different methods it has to help with prediction and other needs. One more thing I learned was what a confusion matrix was. I had to do research on it as I had no idea what the purpose of it was nor how to use the data I had to create it. However, with the help of Geeks4Geeks and the scikitlearn website on confusion matrices, I understood the purpose and what data to look at."
  },
  {
    "objectID": "posts/logistic_regression_optimization/index.html",
    "href": "posts/logistic_regression_optimization/index.html",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "Logistic Regression implementation logistic.py file: https://github.com/ddelgado8090/ddelgado8090.github.io/blob/main/posts/logistic_regression_optimization/logistic.py"
  },
  {
    "objectID": "posts/logistic_regression_optimization/index.html#experiments",
    "href": "posts/logistic_regression_optimization/index.html#experiments",
    "title": "Implementing Logistic Regression",
    "section": "Experiments",
    "text": "Experiments\n\nVanilla Gradient Descent\nIn this first experiment, I tested to see that when \\(p_dim = 2\\), \\(\\alpha\\) is sufficiently small, and \\(\\beta = 0\\), then the gradient descent for logistic regression converges to a weight vector \\(\\mathbf{w}\\) that looks visually correct. I showed this by plotting the decision boundary with the data and graphing the plot the loss over iterations.\nThis code was provided by Phil in his assignment notes! This code creates classification data with noise.\n\nimport torch\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(noise = 0.5)\n\nThe code below was taken from Phil’s class notes on perceptron. It was modified to adjust the target to be the y values of this data.\nThis code creates the graph to show the classification_data through a graph. There are 300 points graphed where the x-axis (x_1) is a number you can measure and the y-axis (x_2) is another feature vector.\n\nimport matplotlib.pyplot as plt\n\ndef plot_classification_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = classification_data()\nplot_classification_data(X, y, ax)\nplt.grid(True)\n\n\n\n\n\n\n\n\nNow, to show the decision boundary, we draw the line by editing the code from the perceptron notes:\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\nfig, ax = plt.subplots(1, 1)\nplot_classification_data(X, y, ax)\n\nw_1 = torch.Tensor([1,  1, -1]) \n\ndraw_line(w_1, x_min = -1, x_max = 1.5, ax = ax, color = \"black\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nAs we can see, the line exactly separates the two classes.\nNext, I am plotting the loss over iterations, 5000 in my case, to show the loss decreasing monotonically. Part of the set-up code was provided in the assignment, but the code to keep track of the loss and the graph was created by me.\n\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\n\ntotal_loss = []\nfor _ in range(5000):\n    # keeps track of the loss over time\n    loss = LR.loss(X, y)\n    total_loss.append(loss)\n    opt.step(X, y, alpha = 0.1, beta = 0.0)\n\nplt.plot(total_loss)\nplt.grid(True)\nplt.title(\"Loss Over Iterations\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\n#plt.text(0.2, 0.2, f'Total Loss: {loss:.3f}')\nplt.show()\n\n\n\n\n\n\n\n\nThis graph shows the loss decreasing monotonically. It shows the loss over iterations when alpha is small and beta is 0.0, and as seen, it begins to flatten out consistently at bout 2,800 iterations.\n\n\nBenefits of Momentum\nIn this experiment, I used the same data that shows classification_data through a graph, but with momentum as the beta was increased to be 0.9.\n\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\n\ntotal_loss_m = []\nfor _ in range(5000):\n    # keeps track of the momentum loss over time\n    loss = LR.loss(X, y)\n    total_loss_m.append(loss)\n    opt.step(X, y, alpha = 0.1, beta = 0.0)\n\nfig, ax = plt.subplots(1, 1)\nplot_classification_data(X, y, ax)\nplt.grid(True)\n\n\n\n\n\n\n\n\nTo show the decision boundary, we draw the line by editing the code from the same perceptron notes where the line exactly separates the two classes:\n\nfig, ax = plt.subplots(1, 1)\nplot_classification_data(X, y, ax)\n\nw_1 = torch.Tensor([1,  1, -1]) \n\ndraw_line(w_1, x_min = -1, x_max = 1.5, ax = ax, color = \"black\")\nplt.grid(True)\n\n\n\n\n\n\n\n\nNext, I am plotting the loss over iterations, 300 in this case as seen in the first code block of this experiment, to show the loss decreasing monotonically. Part of the set-up code was provided in the assignment, but the code to keep track of the loss and the graph was created by me.\n\nplt.plot(total_loss_m)\nplt.grid(True)\nplt.title(\"Momentum Loss Over Iterations\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\n#plt.text(0.2, 0.2, f'Total Loss: {loss:.4f}')\nplt.show()\n\n\n\n\n\n\n\n\nAs seen, the loss over iterations reaches a consistent flattening at around 50 iterations. Much quicker than Vanilla Gradient Descent!\nNext, I graphed the loss over iterations for each method, vanilla optimizer at a range of 6000 iterations while the momentum optimizer at 4000 iterations, to compare the two and see the speedup due to momentum:\n\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\n\n#vanilla\ntotal_loss = []\nfor _ in range(6000):\n    # keeping track of the loss over time\n    loss = LR.loss(X, y)\n    total_loss.append(loss)\n    opt.step(X, y, alpha = 0.1, beta = 0.0)\n\n\n#momentum\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\ntotal_m_loss = []\nfor _ in range(4000):\n    # keeping track of the loss over time\n    loss_m = LR.loss(X, y)\n    total_m_loss.append(loss_m)\n    \n    opt.step(X, y, alpha = 0.2, beta = 0.9)\n\n\nplt.plot(total_loss, label='Without Momentum', color = 'purple')\nplt.plot(total_m_loss, label='With Momentum', color = 'green')\nplt.grid(True)\nplt.title(\"Loss Over Iterations: No Momentum vs. Momentum\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\n\n\n\n\n\n\n\nAs seen, with momentum (the green line), a faster convergence is achieved. At 4000 iterations, it seems like the line with momentum was able to achieve a lower loss than the line without momentum (the purple line) as the green line is closer to the 0.0 loss value compared to the purple line that is above the green line. If the iterations were increased to 8000, we would see the purple line grow closer to the 0.0 loss like the green line is.\n\n\nOverfitting\nIn this experiment, I generate data where p_dim &gt; n_points as seen with n_points = 50 and p_dims = 100. I do this twice, first on the dataset X_train, y_train and the second time on the dataset X_test, y_test. Then, I fit a logistic regression model to the data X_train, y_train where the goal was to obtain 100% accuracy on the training data, which is achieved as seen in the output.\n\nX_train, y_train = classification_data(n_points = 50, noise = 0.6, p_dims = 100)\n\n\nLR = LogisticRegression()\nopt = GradientDescentOptimizer(LR)\n\nlosses = []\nchange = float('inf') #change in losses\nloss = LR.loss(X_train, y_train)\nlosses.append(loss)\nopt.step(X_train, y_train, alpha = 0.2, beta = 0.9)\n\nwhile change &gt; 10**(-6):\n    #change is how much better it is getting\n\n    #old loss is current loss\n    new_loss = LR.loss(X_train, y_train)\n    losses.append(new_loss)\n    \n    opt.step(X_train, y_train, alpha = 0.2, beta = 0.9)\n    change = abs(new_loss - loss)\n    loss = new_loss\n\n#predicting \npred_train = LR.predict(X_train)\npred_accuracy = torch.mean((pred_train == y_train).float())\nprint(\"Training predicting accuracy\", float(pred_accuracy))\n\nTraining predicting accuracy 1.0\n\n\nTo show the change in loss during training, I graphed the loss over iterations with the values of the loss function at that iteration plotted. In the graph, we can see a decreasing trend, indicating that the model is improving its performance and converging towards an optimal solution.\n\n# Plotting change in losses during training\nplt.plot(range(len(losses)), losses, marker='o', linestyle='-')\nplt.title('Loss Over Iterations during Training')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\nFinally, I used the training model and ran it on the testing data where I got a lower accuracy rating. This shows the negative effects of overfitting a model on the training data.\n\nX_test, y_test = classification_data(n_points = 50, noise = 0.6, p_dims = 100)\n\n#predicting\npred_test = LR.predict(X_test)\npred_accuracy = torch.mean((pred_test == y_test).float())\nprint(\"Testing prediction accuracy\", float(pred_accuracy))\n\nTesting prediction accuracy 0.8799999952316284"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Daniela Delgado\nMachine Learning: Course Blog Posts\nMiddlebury College ’24"
  },
  {
    "objectID": "goals-setting/goal-setting.html",
    "href": "goals-setting/goal-setting.html",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Daniela Delgado\n\n\nThe knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI would really like to grow in the implementation and social responsibility areas as these are where my interests lie. I want to understand machine learning algorithms and be able to compare algorithms to know which ones work better for certain tasks. Additionally, even with this great technology, it falls in our hands to be able to go against biases and for these models to be ethical. As a POC woman in STEM, I am aware of the discrimination, stereotypes, and limitations women and people of color face in the field. Thus, I would like to understand where the faults lie in machine learning and be able to learn and think about ways to eliminate/improve the biases to avoid them growing through and because of technology.\n\n\n\n\n\nMost blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nFor the blog posts, I want to achieve at least five “No Revisions Suggested” posts and at least one post for each of the sections, except at least two for “Implementation” and “Social Responsibility” as these are the topics that most interest me.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions. We will also have a special opportunity this semester to engage with a renowned expert in machine learning, algorithmic bias, and the ethics of artificial intelligence.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI would like to use the “pass” option at most two times during the semester when it is my turn to present. Additionally, I would like to ask questions to whoever is presenting the warmup when I need more clarification, which might be often. I often struggle to ask questions out loud, so I hope this creates an added incentive for me to ask others for clarifying help. I will also attend student/peer help hours at least twice a week to ask clarifying/curious questions over the material. If there is a study group, I would like to attend a session (once a week at least if it is helpful the first time). I will complete all core readings prior to each class periods and take notes on them.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI will submit all of the project milestones on time. Additionally, when working in the group, we will set a regular time each week, multiple times a week as needed, to work with the group on the project. I will also communicate with my group in a clear and timely manner. I will write the sections assigned to me for the project report and present the portion assigned to me for the final presentation.\nThe topics I would like to explore in a project would be making predictions, classifying music or items, or a recognition projection (such as music or emotions or an image recognition)."
  },
  {
    "objectID": "goals-setting/goal-setting.html#what-youll-learn",
    "href": "goals-setting/goal-setting.html#what-youll-learn",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "The knowledge we’ll develop in CSCI 0451 can be broadly divided into four main areas:\n\nTheory: mathematical descriptions of frameworks and algorithms.\nImplementation: effective coding and use of tools in order to implement efficient machine learning algorithms.\nExperimentation: performing experiments to assess the performance of algorithms and clearly communicating about the results.\nSocial responsibility: critical analysis of sources of bias and harm in machine learning algorithms; theoretical formulations of fairness and bias\n\nEvery student should grow toward each of these areas, but you can choose to specialize if you’d like! If there are one or two of these categories on which you’d especially like to focus, list them below. Feel free to include any details that you’d like – this can help me tailor the course content to your interests.\nI would really like to grow in the implementation and social responsibility areas as these are where my interests lie. I want to understand machine learning algorithms and be able to compare algorithms to know which ones work better for certain tasks. Additionally, even with this great technology, it falls in our hands to be able to go against biases and for these models to be ethical. As a POC woman in STEM, I am aware of the discrimination, stereotypes, and limitations women and people of color face in the field. Thus, I would like to understand where the faults lie in machine learning and be able to learn and think about ways to eliminate/improve the biases to avoid them growing through and because of technology."
  },
  {
    "objectID": "goals-setting/goal-setting.html#what-youll-achieve",
    "href": "goals-setting/goal-setting.html#what-youll-achieve",
    "title": "CSCI 0451: Reflective Goal-Setting",
    "section": "",
    "text": "Most blog posts will require around 5-8 hours on average to complete, plus time for revisions in response to feedback. Blog posts will most frequently involve a mix of mathematical problem-solving, coding, experimentation, and written discussion. Some blog posts will ask you to critically discuss recent readings in an essay-like format.\nFor the blog posts, I want to achieve at least five “No Revisions Suggested” posts and at least one post for each of the sections, except at least two for “Implementation” and “Social Responsibility” as these are the topics that most interest me.\n\n\n\nYou make a choice each day about how to show up for class: whether you’ll be prepared, whether you’ll engage with me and your peers in a constructive manner; and whether you’ll be active during lecture and discussions. We will also have a special opportunity this semester to engage with a renowned expert in machine learning, algorithmic bias, and the ethics of artificial intelligence.\nAn especially important form of course presence is the daily warmup. We’ll spend the first 10-15 minutes of most class periods on warmup activities. You’re expected to have prepared the warmup activity ahead of time (this means you’ll need to have completed the readings as well). Each time, we’ll sort into groups of 5-6 students, and one of you (randomly selected) will be responsible for presenting the activity on the whiteboard. If you’re not feeling prepared to present the activity, you can “pass” to the next person, or ask for help along the way.\nI would like to use the “pass” option at most two times during the semester when it is my turn to present. Additionally, I would like to ask questions to whoever is presenting the warmup when I need more clarification, which might be often. I often struggle to ask questions out loud, so I hope this creates an added incentive for me to ask others for clarifying help. I will also attend student/peer help hours at least twice a week to ask clarifying/curious questions over the material. If there is a study group, I would like to attend a session (once a week at least if it is helpful the first time). I will complete all core readings prior to each class periods and take notes on them.\n\n\n\nTo finish off the course, you’ll complete a long-term project that showcases your interests and skills. You’ll be free to propose and pursue a topic. My expectation is that most projects will move significantly beyond the content covered in class in some way: you might implement a new algorithm, study a complex data set in depth, or conduct a series of experiments related to assessing algorithmic bias in a certain class of algorithm. You’ll be expected to complete this project in small groups (of your choosing), and update us at a few milestones along the way.\nPlease share a bit about what kind of topic might excite you, and set a few goals about how you plan to show up as a constructive team-member and co-inquirer (see the ideas for some inspiration).\nI will submit all of the project milestones on time. Additionally, when working in the group, we will set a regular time each week, multiple times a week as needed, to work with the group on the project. I will also communicate with my group in a clear and timely manner. I will write the sections assigned to me for the project report and present the portion assigned to me for the final presentation.\nThe topics I would like to explore in a project would be making predictions, classifying music or items, or a recognition projection (such as music or emotions or an image recognition)."
  },
  {
    "objectID": "WarmUps/WarmUp13.html",
    "href": "WarmUps/WarmUp13.html",
    "title": "Introducing Kernels",
    "section": "",
    "text": "import torch \nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\nn_points = 100\nx = torch.rand(n_points)\ny = 1*((x + 0.3*(torch.rand(n_points) - 0.5)) &gt; 0.5 )\n\ndef plot_1d_classification_data(x, y, ax):\n    \n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(x[ix], torch.zeros_like(x[ix]), s = 40,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -1, vmax = 2, alpha = 0.6, marker = markers[i], )\n    ax.set(xlabel = r\"$x$\")\n    \nfig, ax = plt.subplots(figsize = (10, 1))\nplot_1d_classification_data(x, y, ax)\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\n\n\n\n\n\n\n\n\ndef compute_score(x, y, gamma, x_space):\n    diffs = x_space[:, None] - x\n    s = torch.mean(y * torch.exp(-gamma * diffs**2), dim = 1)\n    return s\n\ngamma = 10000\nx_space = torch.linspace(0, 1, 1001)\ns = compute_score(x, y, gamma, x_space)\n\n\n\nfig, ax = plt.subplots(2, 1, figsize = (5, 4), height_ratios= (0.8, 0.2))\nax[0].plot(x_space, s, color = \"slategrey\")\nax[0].set(ylabel = \"Kernel score\")\nplot_1d_classification_data(x, y, ax[1])"
  },
  {
    "objectID": "WarmUps/WarmUp13.html#introducing-kernels",
    "href": "WarmUps/WarmUp13.html#introducing-kernels",
    "title": "Introducing Kernels",
    "section": "",
    "text": "import torch \nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\nn_points = 100\nx = torch.rand(n_points)\ny = 1*((x + 0.3*(torch.rand(n_points) - 0.5)) &gt; 0.5 )\n\ndef plot_1d_classification_data(x, y, ax):\n    \n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(x[ix], torch.zeros_like(x[ix]), s = 40,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -1, vmax = 2, alpha = 0.6, marker = markers[i], )\n    ax.set(xlabel = r\"$x$\")\n    \nfig, ax = plt.subplots(figsize = (10, 1))\nplot_1d_classification_data(x, y, ax)\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\n\n\n\n\n\n\n\n\ndef compute_score(x, y, gamma, x_space):\n    diffs = x_space[:, None] - x\n    s = torch.mean(y * torch.exp(-gamma * diffs**2), dim = 1)\n    return s\n\ngamma = 10000\nx_space = torch.linspace(0, 1, 1001)\ns = compute_score(x, y, gamma, x_space)\n\n\n\nfig, ax = plt.subplots(2, 1, figsize = (5, 4), height_ratios= (0.8, 0.2))\nax[0].plot(x_space, s, color = \"slategrey\")\nax[0].set(ylabel = \"Kernel score\")\nplot_1d_classification_data(x, y, ax[1])"
  },
  {
    "objectID": "WarmUps/WarmUp4.html",
    "href": "WarmUps/WarmUp4.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "When was a time in your life in which you felt that you were the subject of an unfair decision? What was it about that decision that made it feel unfair, rather than just bad, disappointing, or surprising?\n- A decision that was made unfairly was that when I was bout 6 or 7, my family was going to watch the Astros play in the stadium, but then my sister and I got into an argument. We were fighting and calling each other names, but in my defense, she started it. As a consequence, my parents cancelled the plans they made. It was unfair because I also got in trouble for something I was only defending myself in and it was disappointing because we loved going to baseball games and that was always a fun time for everyone. I also was sad I missed out on getting an ice cream hat. \nConsider Figure 4 in the Introduction of BHN. In this figure, there are blue dots and green dots, where the colors correspond to hypothetical demographic attributes. We as the reader can choose what the colors mean.\nSuggest one possible meaning for the blue and green dots in which you would say that the classifier depicted in the figure is unproblematic from the perspective of fairness. - Previous experience or not Suggest one possible meaning for the blue and green dots in which you would say that the classifier depicted in the figure is concerning from the perspective of fairness. - Sex: Male or female - This is concerning because there would be an unequal amount of sexes being accepted into colleges. It is also unfair to compare based on sex. What is the relevant difference between the two cases? - The difference between both is that one looks at something that would not apply to the job and you can’t control, while with having experience or not, that applies to the job and it is something you can improve."
  },
  {
    "objectID": "WarmUps/WarmUp3.html",
    "href": "WarmUps/WarmUp3.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "Part B:\nLet’s now imagine that the rapid COVID test does not just give a yes/no answer, but actually a score describing the patient’s likelihood of COVID on a scale from 0 to 1. What score is high enough to merit you staying home, according to your costs from Part A?\n\nimport numpy as np\n\nNUM_CASES  = 1000\nPREVALENCE = 0.1\nNOISE      = 2\n\ncases  = 1*(np.random.rand(NUM_CASES) &lt; PREVALENCE)\nscores = np.exp(cases + NOISE*(np.random.rand(NUM_CASES))) / np.exp(NOISE+1)\n\n\ndef t_cost (t):\n    cost_a = 0\n    cost_b = 0\n\n    for i in cases:\n        for j in scores:\n            if j &gt; t: #if false positive\n                if i == 0:\n                    cost_a += 1\n            elif j &lt; t: #if false negative\n                if i == 1:\n                    cost_b += 1\n    total_cost = 1 * cost_a + cost_b * 5\n    return total_cost\n\n#Using a for-loop or any other technique, conduct a search to find the value of t that minimizes the total cost\nmin_cost = float('inf')\nmin_t = None\n\nfor i in range(0, 1001):\n    tresh = i/1000 #divides the number by 100 to get a num between 0 and 1\n    cost = t_cost(tresh)\n    if cost &lt; min_cost:\n        min_cost = cost\n        min_t = tresh\nmin_t\n\n\n\n0.997"
  },
  {
    "objectID": "WarmUps/WarmUp10.html",
    "href": "WarmUps/WarmUp10.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "Part B.1\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef logistic_sigmoid (z):\n    sig_x = 1 / (1 + np.exp(-z))\n    return sig_x\nz_val = np.linspace(-1, 1, 100)\nsig_function = logistic_sigmoid(z_val)\n\nplt.plot(z_val, sig_function)\nplt.xlabel('z values')\nplt.ylabel('sigmoid(z)')\nplt.show()"
  },
  {
    "objectID": "WarmUps/WarmUp9.html",
    "href": "WarmUps/WarmUp9.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "import torch\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,2))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\n\nimport torch\n\nclass LinearModel:\n\n    def __init__(self):\n        self.w = None \n\n    def score(self, X):\n        \"\"\"\n        Compute the scores for each data point in the feature matrix X. \n        The formula for the ith entry of s is s[i] = &lt;self.w, x[i]&gt;. \n\n        If self.w currently has value None, then it is necessary to first initialize self.w to a random value. \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n        RETURNS: \n            s torch.Tensor: vector of scores. s.size() = (n,)\n        \"\"\"\n        if self.w is None: \n            self.w = torch.rand((X.size()[1]))\n         # your computation here: compute the vector of scores s\n\n        scores = (X@self.w)\n        return scores\n\n    def predict(self, X):\n        \"\"\"\n        Compute the predictions for each data point in the feature matrix X. The prediction for the ith data point is either 0 or 1. \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n        RETURNS: \n            y_hat, torch.Tensor: vector predictions in {0.0, 1.0}. y_hat.size() = (n,)\n        \"\"\"\n        scores = self.score(X)\n        y_hat = torch.where(scores &gt;= 0, torch.tensor(1.0), torch.tensor(0.0))\n        # or y_hat = (scores &lt; 0) * (1.0)\n        return y_hat \n\n\n\nclass Perceptron(LinearModel):\n\n    def loss(self, X, y):\n        \"\"\"\n        Compute the misclassification rate. A point i is classified correctly if it holds that s_i*y_i_ &gt; 0, \n        where y_i_ is the *modified label* that has values in {-1, 1} (rather than {0, 1}). \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n            y, torch.Tensor: the target vector.  y.size() = (n,). The possible labels for y are {0, 1}\n        \n        HINT: In order to use the math formulas in the lecture, \n        you are going to need to construct a modified set of targets and predictions \n        that have entries in {-1, 1} -- otherwise none of the formulas will work right! \n        An easy to to make this conversion is: \n        \n        y_ = 2*y - 1\n        \"\"\"\n\n        # replace with your implementation\n        #converting [0,1] to [-1, 1]\n        y_ = 2*y - 1\n        #find misclassified\n        missclassified = y_ * self.score(X) &lt;= 0\n        missclass_rate = torch.mean(1.0*missclassified)\n        return missclass_rate\n\n\n    def grad(self, X, y):\n        pass \n\n\n\np = Perceptron()\ns = p.score(X)\nl = p.loss(X, y)\nprint(l == 0.5)\n\ntensor(True)\n\n\n\nclass PerceptronOptimizer:\n\n    def __init__(self, model):\n        self.model = model \n    \n    def step(self, X, y):\n        \"\"\"\n        Compute one step of the perceptron update using the feature matrix X \n        and target vector y. \n        \"\"\"\n        pass"
  },
  {
    "objectID": "ClassNotes/MLtestCode.html",
    "href": "ClassNotes/MLtestCode.html",
    "title": "Daniela's CSCI 0451 Blog",
    "section": "",
    "text": "import sklearn as sk\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport torch\nprint(\"I did it!\")\n\nI did it!"
  },
  {
    "objectID": "ClassNotes/02-black-box-classification.html",
    "href": "ClassNotes/02-black-box-classification.html",
    "title": "Classification as a Black Box",
    "section": "",
    "text": "In these notes, we’ll make a lightning tour through the “standard workflow” for users of predictive machine learning technologies. Our focus will be on out-of-the-box Python tools for acquiring, visualizing, and analyzing tabular data sets.\nWe’re going to move pretty quickly through some big topics in practical data science: acquiring data, data visualization, data manipulation, and prediction using the Scikit-Learn package. Throughout these notes, I’ve sprinkled references to the Python Data Science Handbook [@vanderplasPythonDataScience2016], which treats many of these practical considerations in much greater detail.\n\n\n\n\n\nImage source: @allisonhorst\n\n\nOur data set for these notes is Palmer Penguins. This data set contains physiological measurements and species labels for several populations of Adelie, Chinstrap, and Gentoo penguins.\n.The Palmer Penguins data was originally collected by @gormanEcologicalSexualDimorphism2014 and was nicely packaged and released for use in the data science community by @horstAllisonhorstPalmerpenguinsV02020. You can find a very concise summary of the main workflow using a similar data set in @vanderplasPythonDataScience2016.\nLet’s go ahead and acquire the data.\n\nimport warnings\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nnp.set_printoptions(precision = 3)\nplt.style.use('seaborn-v0_8-whitegrid')\n\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/palmer-penguins.csv\"\n\n\ndf = pd.read_csv(url)\n\n The df variable holds a pandas.DataFrame object. You can think of a data frame as a table of data with a variety of useful behaviors for data manipulation and visualization.You can learn much more about the capabilities of pandas.DataFrame objects in Chapter 3 of @vanderplasPythonDataScience2016\nLet’s take a look:\n\ndf.head() #look at 5 rows of df\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/07\n39.1\n18.7\n181.0\n3750.0\nMALE\nNaN\nNaN\nNot enough blood for isotopes.\n\n\n1\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/07\n39.5\n17.4\n186.0\n3800.0\nFEMALE\n8.94956\n-24.69454\nNaN\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n11/16/07\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n3\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n11/16/07\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAdult not sampled.\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n11/16/07\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN\n\n\n\n\n\n\n\nIt’s always useful to get acquainted with the “basics” of the data. For example, how many rows and columns do we have?\n\ndf.shape #tells us how big data is (the rows,penguins, and columns)\n\n(344, 17)\n\n\nWhat are the data types of the columns? str columns are represented with the generic object in Pandas.\n\ndf.dtypes #tells us about the data types on each column on dataframe\n\nstudyName               object\nSample Number            int64\nSpecies                 object\nRegion                  object\nIsland                  object\nStage                   object\nIndividual ID           object\nClutch Completion       object\nDate Egg                object\nCulmen Length (mm)     float64\nCulmen Depth (mm)      float64\nFlipper Length (mm)    float64\nBody Mass (g)          float64\nSex                     object\nDelta 15 N (o/oo)      float64\nDelta 13 C (o/oo)      float64\nComments                object\ndtype: object\n\n\nHere’s the question we’ll ask today about this data set:\n\nGiven some physiological measurements of a penguin, can we reliably infer its species?\n\n\n\n\nWe can select our desired columns from the data frame, operate on them, and make assignments to them using the data-frame-as-dictionary paradigm explored in @vanderplasPythonDataScience2016.\nIn applied data science, at least 80% of the work is typically spent acquiring and preparing data. Here, we’re going to do some simple data preparation directed by our question. It’s going to be convenient to shorten the Species column for each penguin. Furthermore, for visualization purposes today we are going to focus on the Culmen Length (mm) and Culmen Depth (mm) columns.\n\ndf = df[['Culmen Length (mm)', 'Culmen Depth (mm)', 'Species']]#indexing df\n\ndf = df.dropna() #remvoing NA preguins from dataset\n\n# slightly advanced syntax: \n# replace the column with the first word in each entry\ndf[\"Species\"] = df[\"Species\"].str.split().str.get(0)\n\nLet’s take a look at what we’ve done so far:\n\ndf.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nSpecies\n\n\n\n\n0\n39.1\n18.7\nAdelie\n\n\n1\n39.5\n17.4\nAdelie\n\n\n2\n40.3\n18.0\nAdelie\n\n\n4\n36.7\n19.3\nAdelie\n\n\n5\n39.3\n20.6\nAdelie\n\n\n\n\n\n\n\nAs another preprocessing step, we are going to add transformed labels represented as integers.\n\n# for later: assign an integer to each species\nfrom sklearn.preprocessing import LabelEncoder \n\nle = LabelEncoder() #this creates new cols that save to df \ndf[\"species_label\"] = le.fit_transform(df[\"Species\"]) #col represents species\n\nfor i, c in enumerate(le.classes_):\n    print(f\"Class number {i} represents {c} penguins.\")\n\nClass number 0 represents Adelie penguins.\nClass number 1 represents Chinstrap penguins.\nClass number 2 represents Gentoo penguins.\n\n\nNow our data looks like this:\n\ndf.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nSpecies\nspecies_label\n\n\n\n\n0\n39.1\n18.7\nAdelie\n0\n\n\n1\n39.5\n17.4\nAdelie\n0\n\n\n2\n40.3\n18.0\nAdelie\n0\n\n\n4\n36.7\n19.3\nAdelie\n0\n\n\n5\n39.3\n20.6\nAdelie\n0\n\n\n\n\n\n\n\n\n\nWhen designing predictive models, it’s important to evaluate them in a context that simulates the prediction application as accurately as possible. One important way we do this is by performing a train-test split. We keep most of the data as training data which we’ll use to design the model. We’ll hold out a bit of the data as testing data, which we’ll treat as unseen and only use once we are ready to evaluate our final design. The testing data simulates the idea of “new, unseen data” – exactly the kind of data on which it would be useful for us to make predictions!\n\nfrom sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(df, test_size = 0.2)\n\nLet’s check the size of our two split data sets:\n\ndf_train.shape, df_test.shape\n\n((273, 4), (69, 4))\n\n\nNow we’re going to forget that df_test exists for a while. Instead, we’ll turn our attention to analysis, visualization and modeling.\n\n\n\n\nAs a first step, it’s useful to understand how many of each species there are in the training data:\nThis is an example of a “split-apply-combine” operation [@wickhamSplitApplyCombineStrategyData2011]. We split the dataframe into three groups depending on the species label, apply an operation (in this case, computing the number of rows), and then combine the results into a single object. Pandas implements split-apply-combine primarily through the groupby method and several associated functions. There are some nice examples of split-apply-combine in Pandas in @vanderplasPythonDataScience2016.\nThere are more Adelie penguins than Chintraps or Gentoos in this data set. Here are the proportions:\nSo, over 40% of the penguins in the data are Adelie penguins. One important consequence of this proportion is the base rate of the classification problem. The base rate refers to how well we could perform at prediction if we did not use any kind of predictive modeling, but instead simply predicted the most common class for every penguin. Here, if we always predicted “Adelie” for the species, we’d expect to be right more than 40% of the time. So, a minimal expectation of anything fancier we do is that it should be correct much more than 40% of the time.\nNow let’s take a look at our (training) data and see whether our chosen columns look like they have a chance of predicting the penguin species. We’ll show the plot both without and with the species labels.\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfig, ax = plt.subplots(1, 2, figsize = (8, 3.5))\n\np1 = sns.scatterplot(df_train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", ax = ax[0], color = \"darkgrey\")\np2 = sns.scatterplot(df_train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", hue = \"Species\", ax = ax[1])\n\n\n\n\nThese plots are generated using the Seaborn library for Python. Seaborn is a high-level wrapper around the classical matplotlib library for data visualization. Although Matplotlib is very flexible, Seaborn is optimized for visualizing data contained in Pandas data frames. You can find many examples of creating Seaborn plots in the official gallery, and many tips and examples for matplotlib in @vanderplasPythonDataScience2016.\n\n\n\n\nWe can think of the lefthand side as “what the model will see:” just physiological measurements with no labels. On the right we can see the data with its species labels included. We can see that the species are divided into clusters: Adelie penguins have measurements which tend to be similar to other Adelies; Chinstraps are similar to other Chinstraps, etc.\nThis pattern is promising! The approximate separation of the species suggests that a machine learning model which predicts the species label from these measurements is likely to be able to beat the base rate.\n\n\n\nLet’s go ahead and fit some models! We’re going to fit two models that are pre-implemented in the package scikit-learn. For now, you can think of these models as black-box algorithms that accept predictor variables as inputs and return a predicted target as an output. In our case, the predictor variables are the culmen length and culmen depth columns, while the target we are attempting to predict is the species. Later on, we’ll learn more about how some of these models actually work.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\n\nIt’s convenient to split our data into predictors \\(\\mathbf{X}\\) and targets \\(\\mathbf{y}\\). We need to do this once for each of the training and test sets.\n\npredictor_cols = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\ntarget_col = \"species_label\"\n\nX_train = df_train[predictor_cols]\ny_train = df_train[target_col]\n\nX_test = df_test[predictor_cols]\ny_test = df_test[target_col]\n\nLet’s take a quick look at X_train\n\nX_train #shows prediction data. what we will use to make predictions\n#y_train\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\n\n\n\n\n207\n52.2\n18.8\n\n\n38\n37.6\n19.3\n\n\n221\n50.0\n16.3\n\n\n232\n45.5\n13.7\n\n\n49\n42.3\n21.2\n\n\n...\n...\n...\n\n\n81\n42.9\n17.6\n\n\n103\n37.8\n20.0\n\n\n112\n39.7\n17.7\n\n\n171\n49.2\n18.2\n\n\n233\n48.4\n14.6\n\n\n\n\n273 rows × 2 columns\n\n\n\nWe’ll go in-depth on logistic regression later in this course.\nNow we’re ready to fit our first machine learning model. Let’s try logistic regression! In the Scikit-learn API, we first need to instantiate the LogisticRegression() class, and then call the fit() method of this class on the training predictors and targets.\n\nLR = LogisticRegression() #instantiate LR object\nm = LR.fit(X_train, y_train)\n\nSo, uh, did it work? The LogisticRegression() class includes a handy method to compute the accuracy of the classifier:\n\nLR.coef_ #matrix of parameters that represent the patterns the model has learned\n\n#did we learn patterns in data? compute score to find out\nLR.score(X_train, y_train) #score measures accuracy: how often was I right?\n\n0.9633699633699634\n\n\nWow! Much better than the base rate. Note that this is the accuracy on the training data. In theory, accuracy on the test data could look very different.\nA useful way to visualize models with two numerical predictors is via decision regions. Each region describes the set of possible measurements that would result in a given classification.\nYou can unfold this code to see a simple implementation of a function for plotting decision regions which wraps the plot_decision_regions function of the mlxtend package.\n\n\nCode\ndef decision_regions(X, y, model, title):\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        ax = plot_decision_regions(X_train.to_numpy(), y_train.to_numpy(), clf = model, legend = 2)\n\n        handles, labels = ax.get_legend_handles_labels()\n        ax.legend(handles, \n                le.classes_, \n                framealpha=0.3, scatterpoints=1)\n\n        ax.set(xlabel = \"Culmen Length (mm)\", ylabel = \"Culmen Depth (mm)\", title = f\"{title}: Accuracy = {model.score(X, y):.3f}\")\n\ndecision_regions(X_train, y_train, LR, \"Decision Regions for Logistic Regression\")\n\n\n\n\n\n\n\n\n\nYou can learn more about how support vector machines work in @vanderplasPythonDataScience2016. We’ll also study these models later in the course.\nWhile we’re at it, let’s try fitting a different classifier, also supplied by Scikit-learn. This classifier is called support vector machine (SVM).\n\n#using support vector machine\nSVM = SVC(gamma = 5)\nSVM.fit(X_train, y_train)\ndecision_regions(X_train, y_train, SVM, 'Support Vector Machine')\n\n#created an overfit graph. generalizing bc any penguin in the 55/14 point would be classified as an Adeline instead of a Gentoo\n\n\n\n\n\n\n\n\nWow! The support vector machine classifier achieved even higher accuracy on the training data. This is enabled by the greater flexibility of the SVM. Flexibility comes from a lot of places in machine learning, and generally refers to the ability of models to learn complicated decision boundaries like the ones shown here.\nBut is this increased flexibility a good thing? You might look at this predictor and think that something funny is going on. For example, shouldn’t a point on the bottom right be more likely to be a Gentoo penguin than an Adelie?…\n\n\nNow we have two competing classification models: logistic regression and support vector machine. Which one is going to do the best job of prediction on totally new, unseen data? We could go ahead and evaluate on our test set, but for statistical reasons we need to avoid doing this until we’ve made a final choice of classifier.\n@vanderplasPythonDataScience2016 has more on cross-validation and overfitting. We’ll confront overfitting agian many times in this course.\nIn order to make an assessment, we can simulate the process of fitting the model and evaluating on “test” data by witholding parts of our training data to use as testing. We split the data into chunks and withold each chunk, using the other chunks to train the data. This is called cross-validation, and it is illustrated in this figure:\n\n\n\nImage source: scikit-learn\n\n\nWe could do this with a janky for-loop, but the nice scikit-learn developers have implemented this for us. Here’s an example of cross-validation with 5 folds. This can take a little while, as there are actually 5 calls to model.fit() happening under the hood each time.\n\nfrom sklearn.model_selection import cross_val_score #write this isntead of for-loop\n\nFirst let’s compute the cross-validation accuracies for logistic regression:\n\ncv_scores_LR = cross_val_score(LR, X_train, y_train, cv = 5) #training on remaining 80% of data\ncv_scores_LR\n\narray([0.927, 1.   , 0.945, 0.944, 0.963])\n\n\nA convenient way to summarize these results is by computing the average:\n\ncv_scores_LR.mean()\n\n0.9560269360269359\n\n\nLet’s compare to SVM:\n\ncv_scores_SVM = cross_val_score(SVM, X_train, y_train, cv = 5) #100/5 = 20% \ncv_scores_SVM.mean()\n\n0.8643097643097641\n\n\nAh! It looks like our SVM classifier was indeed too flexible to do well in predicting data that it hasn’t seen before. Although the SVM had better training accuracy than the logistic regression model, it failed to generalize to the task of unseen prediction. This phenomenon is called overfitting. Dealing with overfitting is one of the fundamental modeling challenges in applied machine learning.\n\n\n\n\nSo far, we’ve fit a logistic regression model and a support vector machine model; compared the two on a cross-validation task; and determined that the logistic regression model is most likely to generalize. Let’s now retrain the logistic regression model on the complete training data and finally evaluate it on the test set:\n\nLR.fit(X_train, y_train)\nLR.score(X_test, y_test)\n\n#estimate of performance\n\n0.9710144927536232\n\n\nNot bad! This is our final estimate for the accuracy of our model as a classification tool on unseen penguin data.\n\n\nAccuracy is a simple measure of how many errors a model makes. In many applications, it’s important to understand what kind of errors the model makes, a topic which we’ll study much more when we come to decision theory in the near future. We can get a quick overview of the kinds of mistakes that a model makes by computing the confusion matrix between the true labels and predictions. This matrix cross-tabulates all the true labels with all the predicted ones.\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = LR.predict(X_test)\n#y_test_pred\nC = confusion_matrix(y_test, y_test_pred)\nC\n#each row says the penguin's true predictions adeline, chinstrap, gentoo\n#30 adeline classifed as adeline, one instance of adeline misclassidfied as chinstrap, etc\n\narray([[30,  1,  0],\n       [ 0, 10,  1],\n       [ 0,  0, 27]])\n\n\nThe entry in the ith row and jth column of the confusion matrix gives the number of data points that have true label i and predicted label j from our model.\n\nfor i in range(3):\n    for j in range(3):\n        print(f\"There were {C[i,j]} {le.classes_[i]} penguin(s) who were classified as {le.classes_[j]}.\")\n\n\n\n\n\nIn these notes, we took a very quick tour of the core data science workflow. We considered a simple classification problem in which we acquired some data, cleaned it up a bit, visualized several of its features, used those features to make a predictive classification model, visualized that model, and evaluated its accuracy. Along the way, we encountered the phenomenon of overfitting: models that are too flexible will achieve remarkable accuracy on the training set but will generalize poorly to unseen data. The problem of designing models that are “flexible enough” and “in the right way” is a fundamental driving force in modern machine learning, and the deep learning revolution can be viewed as the latest paradigm for seeking appropriately flexible models.\nSo far, we haven’t attempted to understand how any of these predictive models actually work. We’ll dive into this topic soon."
  },
  {
    "objectID": "ClassNotes/02-black-box-classification.html#classifying-the-palmer-penguins",
    "href": "ClassNotes/02-black-box-classification.html#classifying-the-palmer-penguins",
    "title": "Classification as a Black Box",
    "section": "",
    "text": "Image source: @allisonhorst\n\n\nOur data set for these notes is Palmer Penguins. This data set contains physiological measurements and species labels for several populations of Adelie, Chinstrap, and Gentoo penguins.\n.The Palmer Penguins data was originally collected by @gormanEcologicalSexualDimorphism2014 and was nicely packaged and released for use in the data science community by @horstAllisonhorstPalmerpenguinsV02020. You can find a very concise summary of the main workflow using a similar data set in @vanderplasPythonDataScience2016.\nLet’s go ahead and acquire the data.\n\nimport warnings\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nnp.set_printoptions(precision = 3)\nplt.style.use('seaborn-v0_8-whitegrid')\n\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/palmer-penguins.csv\"\n\n\ndf = pd.read_csv(url)\n\n The df variable holds a pandas.DataFrame object. You can think of a data frame as a table of data with a variety of useful behaviors for data manipulation and visualization.You can learn much more about the capabilities of pandas.DataFrame objects in Chapter 3 of @vanderplasPythonDataScience2016\nLet’s take a look:\n\ndf.head() #look at 5 rows of df\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/07\n39.1\n18.7\n181.0\n3750.0\nMALE\nNaN\nNaN\nNot enough blood for isotopes.\n\n\n1\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/07\n39.5\n17.4\n186.0\n3800.0\nFEMALE\n8.94956\n-24.69454\nNaN\n\n\n2\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n11/16/07\n40.3\n18.0\n195.0\n3250.0\nFEMALE\n8.36821\n-25.33302\nNaN\n\n\n3\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n11/16/07\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nAdult not sampled.\n\n\n4\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n11/16/07\n36.7\n19.3\n193.0\n3450.0\nFEMALE\n8.76651\n-25.32426\nNaN\n\n\n\n\n\n\n\nIt’s always useful to get acquainted with the “basics” of the data. For example, how many rows and columns do we have?\n\ndf.shape #tells us how big data is (the rows,penguins, and columns)\n\n(344, 17)\n\n\nWhat are the data types of the columns? str columns are represented with the generic object in Pandas.\n\ndf.dtypes #tells us about the data types on each column on dataframe\n\nstudyName               object\nSample Number            int64\nSpecies                 object\nRegion                  object\nIsland                  object\nStage                   object\nIndividual ID           object\nClutch Completion       object\nDate Egg                object\nCulmen Length (mm)     float64\nCulmen Depth (mm)      float64\nFlipper Length (mm)    float64\nBody Mass (g)          float64\nSex                     object\nDelta 15 N (o/oo)      float64\nDelta 13 C (o/oo)      float64\nComments                object\ndtype: object\n\n\nHere’s the question we’ll ask today about this data set:\n\nGiven some physiological measurements of a penguin, can we reliably infer its species?"
  },
  {
    "objectID": "ClassNotes/02-black-box-classification.html#data-preparation",
    "href": "ClassNotes/02-black-box-classification.html#data-preparation",
    "title": "Classification as a Black Box",
    "section": "",
    "text": "We can select our desired columns from the data frame, operate on them, and make assignments to them using the data-frame-as-dictionary paradigm explored in @vanderplasPythonDataScience2016.\nIn applied data science, at least 80% of the work is typically spent acquiring and preparing data. Here, we’re going to do some simple data preparation directed by our question. It’s going to be convenient to shorten the Species column for each penguin. Furthermore, for visualization purposes today we are going to focus on the Culmen Length (mm) and Culmen Depth (mm) columns.\n\ndf = df[['Culmen Length (mm)', 'Culmen Depth (mm)', 'Species']]#indexing df\n\ndf = df.dropna() #remvoing NA preguins from dataset\n\n# slightly advanced syntax: \n# replace the column with the first word in each entry\ndf[\"Species\"] = df[\"Species\"].str.split().str.get(0)\n\nLet’s take a look at what we’ve done so far:\n\ndf.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nSpecies\n\n\n\n\n0\n39.1\n18.7\nAdelie\n\n\n1\n39.5\n17.4\nAdelie\n\n\n2\n40.3\n18.0\nAdelie\n\n\n4\n36.7\n19.3\nAdelie\n\n\n5\n39.3\n20.6\nAdelie\n\n\n\n\n\n\n\nAs another preprocessing step, we are going to add transformed labels represented as integers.\n\n# for later: assign an integer to each species\nfrom sklearn.preprocessing import LabelEncoder \n\nle = LabelEncoder() #this creates new cols that save to df \ndf[\"species_label\"] = le.fit_transform(df[\"Species\"]) #col represents species\n\nfor i, c in enumerate(le.classes_):\n    print(f\"Class number {i} represents {c} penguins.\")\n\nClass number 0 represents Adelie penguins.\nClass number 1 represents Chinstrap penguins.\nClass number 2 represents Gentoo penguins.\n\n\nNow our data looks like this:\n\ndf.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nSpecies\nspecies_label\n\n\n\n\n0\n39.1\n18.7\nAdelie\n0\n\n\n1\n39.5\n17.4\nAdelie\n0\n\n\n2\n40.3\n18.0\nAdelie\n0\n\n\n4\n36.7\n19.3\nAdelie\n0\n\n\n5\n39.3\n20.6\nAdelie\n0\n\n\n\n\n\n\n\n\n\nWhen designing predictive models, it’s important to evaluate them in a context that simulates the prediction application as accurately as possible. One important way we do this is by performing a train-test split. We keep most of the data as training data which we’ll use to design the model. We’ll hold out a bit of the data as testing data, which we’ll treat as unseen and only use once we are ready to evaluate our final design. The testing data simulates the idea of “new, unseen data” – exactly the kind of data on which it would be useful for us to make predictions!\n\nfrom sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(df, test_size = 0.2)\n\nLet’s check the size of our two split data sets:\n\ndf_train.shape, df_test.shape\n\n((273, 4), (69, 4))\n\n\nNow we’re going to forget that df_test exists for a while. Instead, we’ll turn our attention to analysis, visualization and modeling."
  },
  {
    "objectID": "ClassNotes/02-black-box-classification.html#data-analysis-and-visualization",
    "href": "ClassNotes/02-black-box-classification.html#data-analysis-and-visualization",
    "title": "Classification as a Black Box",
    "section": "",
    "text": "As a first step, it’s useful to understand how many of each species there are in the training data:\nThis is an example of a “split-apply-combine” operation [@wickhamSplitApplyCombineStrategyData2011]. We split the dataframe into three groups depending on the species label, apply an operation (in this case, computing the number of rows), and then combine the results into a single object. Pandas implements split-apply-combine primarily through the groupby method and several associated functions. There are some nice examples of split-apply-combine in Pandas in @vanderplasPythonDataScience2016.\nThere are more Adelie penguins than Chintraps or Gentoos in this data set. Here are the proportions:\nSo, over 40% of the penguins in the data are Adelie penguins. One important consequence of this proportion is the base rate of the classification problem. The base rate refers to how well we could perform at prediction if we did not use any kind of predictive modeling, but instead simply predicted the most common class for every penguin. Here, if we always predicted “Adelie” for the species, we’d expect to be right more than 40% of the time. So, a minimal expectation of anything fancier we do is that it should be correct much more than 40% of the time.\nNow let’s take a look at our (training) data and see whether our chosen columns look like they have a chance of predicting the penguin species. We’ll show the plot both without and with the species labels.\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfig, ax = plt.subplots(1, 2, figsize = (8, 3.5))\n\np1 = sns.scatterplot(df_train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", ax = ax[0], color = \"darkgrey\")\np2 = sns.scatterplot(df_train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", hue = \"Species\", ax = ax[1])\n\n\n\n\nThese plots are generated using the Seaborn library for Python. Seaborn is a high-level wrapper around the classical matplotlib library for data visualization. Although Matplotlib is very flexible, Seaborn is optimized for visualizing data contained in Pandas data frames. You can find many examples of creating Seaborn plots in the official gallery, and many tips and examples for matplotlib in @vanderplasPythonDataScience2016.\n\n\n\n\nWe can think of the lefthand side as “what the model will see:” just physiological measurements with no labels. On the right we can see the data with its species labels included. We can see that the species are divided into clusters: Adelie penguins have measurements which tend to be similar to other Adelies; Chinstraps are similar to other Chinstraps, etc.\nThis pattern is promising! The approximate separation of the species suggests that a machine learning model which predicts the species label from these measurements is likely to be able to beat the base rate."
  },
  {
    "objectID": "ClassNotes/02-black-box-classification.html#modeling-and-model-selection",
    "href": "ClassNotes/02-black-box-classification.html#modeling-and-model-selection",
    "title": "Classification as a Black Box",
    "section": "",
    "text": "Let’s go ahead and fit some models! We’re going to fit two models that are pre-implemented in the package scikit-learn. For now, you can think of these models as black-box algorithms that accept predictor variables as inputs and return a predicted target as an output. In our case, the predictor variables are the culmen length and culmen depth columns, while the target we are attempting to predict is the species. Later on, we’ll learn more about how some of these models actually work.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\n\nIt’s convenient to split our data into predictors \\(\\mathbf{X}\\) and targets \\(\\mathbf{y}\\). We need to do this once for each of the training and test sets.\n\npredictor_cols = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\ntarget_col = \"species_label\"\n\nX_train = df_train[predictor_cols]\ny_train = df_train[target_col]\n\nX_test = df_test[predictor_cols]\ny_test = df_test[target_col]\n\nLet’s take a quick look at X_train\n\nX_train #shows prediction data. what we will use to make predictions\n#y_train\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\n\n\n\n\n207\n52.2\n18.8\n\n\n38\n37.6\n19.3\n\n\n221\n50.0\n16.3\n\n\n232\n45.5\n13.7\n\n\n49\n42.3\n21.2\n\n\n...\n...\n...\n\n\n81\n42.9\n17.6\n\n\n103\n37.8\n20.0\n\n\n112\n39.7\n17.7\n\n\n171\n49.2\n18.2\n\n\n233\n48.4\n14.6\n\n\n\n\n273 rows × 2 columns\n\n\n\nWe’ll go in-depth on logistic regression later in this course.\nNow we’re ready to fit our first machine learning model. Let’s try logistic regression! In the Scikit-learn API, we first need to instantiate the LogisticRegression() class, and then call the fit() method of this class on the training predictors and targets.\n\nLR = LogisticRegression() #instantiate LR object\nm = LR.fit(X_train, y_train)\n\nSo, uh, did it work? The LogisticRegression() class includes a handy method to compute the accuracy of the classifier:\n\nLR.coef_ #matrix of parameters that represent the patterns the model has learned\n\n#did we learn patterns in data? compute score to find out\nLR.score(X_train, y_train) #score measures accuracy: how often was I right?\n\n0.9633699633699634\n\n\nWow! Much better than the base rate. Note that this is the accuracy on the training data. In theory, accuracy on the test data could look very different.\nA useful way to visualize models with two numerical predictors is via decision regions. Each region describes the set of possible measurements that would result in a given classification.\nYou can unfold this code to see a simple implementation of a function for plotting decision regions which wraps the plot_decision_regions function of the mlxtend package.\n\n\nCode\ndef decision_regions(X, y, model, title):\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        ax = plot_decision_regions(X_train.to_numpy(), y_train.to_numpy(), clf = model, legend = 2)\n\n        handles, labels = ax.get_legend_handles_labels()\n        ax.legend(handles, \n                le.classes_, \n                framealpha=0.3, scatterpoints=1)\n\n        ax.set(xlabel = \"Culmen Length (mm)\", ylabel = \"Culmen Depth (mm)\", title = f\"{title}: Accuracy = {model.score(X, y):.3f}\")\n\ndecision_regions(X_train, y_train, LR, \"Decision Regions for Logistic Regression\")\n\n\n\n\n\n\n\n\n\nYou can learn more about how support vector machines work in @vanderplasPythonDataScience2016. We’ll also study these models later in the course.\nWhile we’re at it, let’s try fitting a different classifier, also supplied by Scikit-learn. This classifier is called support vector machine (SVM).\n\n#using support vector machine\nSVM = SVC(gamma = 5)\nSVM.fit(X_train, y_train)\ndecision_regions(X_train, y_train, SVM, 'Support Vector Machine')\n\n#created an overfit graph. generalizing bc any penguin in the 55/14 point would be classified as an Adeline instead of a Gentoo\n\n\n\n\n\n\n\n\nWow! The support vector machine classifier achieved even higher accuracy on the training data. This is enabled by the greater flexibility of the SVM. Flexibility comes from a lot of places in machine learning, and generally refers to the ability of models to learn complicated decision boundaries like the ones shown here.\nBut is this increased flexibility a good thing? You might look at this predictor and think that something funny is going on. For example, shouldn’t a point on the bottom right be more likely to be a Gentoo penguin than an Adelie?…\n\n\nNow we have two competing classification models: logistic regression and support vector machine. Which one is going to do the best job of prediction on totally new, unseen data? We could go ahead and evaluate on our test set, but for statistical reasons we need to avoid doing this until we’ve made a final choice of classifier.\n@vanderplasPythonDataScience2016 has more on cross-validation and overfitting. We’ll confront overfitting agian many times in this course.\nIn order to make an assessment, we can simulate the process of fitting the model and evaluating on “test” data by witholding parts of our training data to use as testing. We split the data into chunks and withold each chunk, using the other chunks to train the data. This is called cross-validation, and it is illustrated in this figure:\n\n\n\nImage source: scikit-learn\n\n\nWe could do this with a janky for-loop, but the nice scikit-learn developers have implemented this for us. Here’s an example of cross-validation with 5 folds. This can take a little while, as there are actually 5 calls to model.fit() happening under the hood each time.\n\nfrom sklearn.model_selection import cross_val_score #write this isntead of for-loop\n\nFirst let’s compute the cross-validation accuracies for logistic regression:\n\ncv_scores_LR = cross_val_score(LR, X_train, y_train, cv = 5) #training on remaining 80% of data\ncv_scores_LR\n\narray([0.927, 1.   , 0.945, 0.944, 0.963])\n\n\nA convenient way to summarize these results is by computing the average:\n\ncv_scores_LR.mean()\n\n0.9560269360269359\n\n\nLet’s compare to SVM:\n\ncv_scores_SVM = cross_val_score(SVM, X_train, y_train, cv = 5) #100/5 = 20% \ncv_scores_SVM.mean()\n\n0.8643097643097641\n\n\nAh! It looks like our SVM classifier was indeed too flexible to do well in predicting data that it hasn’t seen before. Although the SVM had better training accuracy than the logistic regression model, it failed to generalize to the task of unseen prediction. This phenomenon is called overfitting. Dealing with overfitting is one of the fundamental modeling challenges in applied machine learning."
  },
  {
    "objectID": "ClassNotes/02-black-box-classification.html#model-evaluation",
    "href": "ClassNotes/02-black-box-classification.html#model-evaluation",
    "title": "Classification as a Black Box",
    "section": "",
    "text": "So far, we’ve fit a logistic regression model and a support vector machine model; compared the two on a cross-validation task; and determined that the logistic regression model is most likely to generalize. Let’s now retrain the logistic regression model on the complete training data and finally evaluate it on the test set:\n\nLR.fit(X_train, y_train)\nLR.score(X_test, y_test)\n\n#estimate of performance\n\n0.9710144927536232\n\n\nNot bad! This is our final estimate for the accuracy of our model as a classification tool on unseen penguin data.\n\n\nAccuracy is a simple measure of how many errors a model makes. In many applications, it’s important to understand what kind of errors the model makes, a topic which we’ll study much more when we come to decision theory in the near future. We can get a quick overview of the kinds of mistakes that a model makes by computing the confusion matrix between the true labels and predictions. This matrix cross-tabulates all the true labels with all the predicted ones.\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = LR.predict(X_test)\n#y_test_pred\nC = confusion_matrix(y_test, y_test_pred)\nC\n#each row says the penguin's true predictions adeline, chinstrap, gentoo\n#30 adeline classifed as adeline, one instance of adeline misclassidfied as chinstrap, etc\n\narray([[30,  1,  0],\n       [ 0, 10,  1],\n       [ 0,  0, 27]])\n\n\nThe entry in the ith row and jth column of the confusion matrix gives the number of data points that have true label i and predicted label j from our model.\n\nfor i in range(3):\n    for j in range(3):\n        print(f\"There were {C[i,j]} {le.classes_[i]} penguin(s) who were classified as {le.classes_[j]}.\")"
  },
  {
    "objectID": "ClassNotes/02-black-box-classification.html#recap",
    "href": "ClassNotes/02-black-box-classification.html#recap",
    "title": "Classification as a Black Box",
    "section": "",
    "text": "In these notes, we took a very quick tour of the core data science workflow. We considered a simple classification problem in which we acquired some data, cleaned it up a bit, visualized several of its features, used those features to make a predictive classification model, visualized that model, and evaluated its accuracy. Along the way, we encountered the phenomenon of overfitting: models that are too flexible will achieve remarkable accuracy on the training set but will generalize poorly to unseen data. The problem of designing models that are “flexible enough” and “in the right way” is a fundamental driving force in modern machine learning, and the deep learning revolution can be viewed as the latest paradigm for seeking appropriately flexible models.\nSo far, we haven’t attempted to understand how any of these predictive models actually work. We’ll dive into this topic soon."
  },
  {
    "objectID": "ClassNotes/10-compas.html",
    "href": "ClassNotes/10-compas.html",
    "title": "Introduction to Algorithmic Disparity: COMPAS",
    "section": "",
    "text": "Today we are going to study an extremely famous investigation into algorithmic decision-making in the sphere of criminal justice by @angwin2022machine, originally written for ProPublica in 2016. This investigation significantly accelerated the pace of research into bias and fairness in machine learning, due in combination to its simple message and publicly-available data.\nIt’s helpful to look at a sample form used for feature collection in the COMPAS risk assessment.\nYou may have already read about the COMPAS algorithm in the original article at ProPublica. Our goal today is to reproduce some of the main findings of this article and set the stage for a more systematic treatment of bias and fairness in machine learning.\nParts of these lecture notes are inspired by the original ProPublica analysis and Allen Downey’s expository case study on the same data.\n\n\n Let’s first obtain the data. I’ve hosted a copy on the course website, so we can download it using a URL.This data set was obtained by @angwin2022machine through a public records request. The data comprises two years worth of COMPAS scoring in Broward County, Florida.\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nsns.set_style(\"whitegrid\")\nnp.set_printoptions(precision = 3)\npd.set_option('display.precision', 3)\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/compas/compas.csv\"\ncompas = pd.read_csv(url)\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\nFor today we are only going to consider a subset of columns.\n\ncompas\n#v_decile_score predicts if the person will be arrested again. The higher, the more likely.\n#two_year_recid is if the last two years they committed another offense\n\n\n\n\n\n\n\n\nid\nname\nfirst\nlast\ncompas_screening_date\nsex\ndob\nage\nage_cat\nrace\n...\nv_decile_score\nv_score_text\nv_screening_date\nin_custody\nout_custody\npriors_count.1\nstart\nend\nevent\ntwo_year_recid\n\n\n\n\n0\n1\nmiguel hernandez\nmiguel\nhernandez\n2013-08-14\nMale\n1947-04-18\n69\nGreater than 45\nOther\n...\n1\nLow\n2013-08-14\n2014-07-07\n2014-07-14\n0\n0\n327\n0\n0\n\n\n1\n3\nkevon dixon\nkevon\ndixon\n2013-01-27\nMale\n1982-01-22\n34\n25 - 45\nAfrican-American\n...\n1\nLow\n2013-01-27\n2013-01-26\n2013-02-05\n0\n9\n159\n1\n1\n\n\n2\n4\ned philo\ned\nphilo\n2013-04-14\nMale\n1991-05-14\n24\nLess than 25\nAfrican-American\n...\n3\nLow\n2013-04-14\n2013-06-16\n2013-06-16\n4\n0\n63\n0\n1\n\n\n3\n5\nmarcu brown\nmarcu\nbrown\n2013-01-13\nMale\n1993-01-21\n23\nLess than 25\nAfrican-American\n...\n6\nMedium\n2013-01-13\nNaN\nNaN\n1\n0\n1174\n0\n0\n\n\n4\n6\nbouthy pierrelouis\nbouthy\npierrelouis\n2013-03-26\nMale\n1973-01-22\n43\n25 - 45\nOther\n...\n1\nLow\n2013-03-26\nNaN\nNaN\n2\n0\n1102\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n7209\n10996\nsteven butler\nsteven\nbutler\n2013-11-23\nMale\n1992-07-17\n23\nLess than 25\nAfrican-American\n...\n5\nMedium\n2013-11-23\n2013-11-22\n2013-11-24\n0\n1\n860\n0\n0\n\n\n7210\n10997\nmalcolm simmons\nmalcolm\nsimmons\n2014-02-01\nMale\n1993-03-25\n23\nLess than 25\nAfrican-American\n...\n5\nMedium\n2014-02-01\n2014-01-31\n2014-02-02\n0\n1\n790\n0\n0\n\n\n7211\n10999\nwinston gregory\nwinston\ngregory\n2014-01-14\nMale\n1958-10-01\n57\nGreater than 45\nOther\n...\n1\nLow\n2014-01-14\n2014-01-13\n2014-01-14\n0\n0\n808\n0\n0\n\n\n7212\n11000\nfarrah jean\nfarrah\njean\n2014-03-09\nFemale\n1982-11-17\n33\n25 - 45\nAfrican-American\n...\n2\nLow\n2014-03-09\n2014-03-08\n2014-03-09\n3\n0\n754\n0\n0\n\n\n7213\n11001\nflorencia sanmartin\nflorencia\nsanmartin\n2014-06-30\nFemale\n1992-12-18\n23\nLess than 25\nHispanic\n...\n4\nLow\n2014-06-30\n2015-03-15\n2015-03-15\n2\n0\n258\n0\n1\n\n\n\n\n7214 rows × 53 columns\n\n\n\nWe are also only going to consider white (Caucasian) and Black (African-American) defendants:\n\ncols = [\"sex\", \"race\", \"decile_score\", \"two_year_recid\"]\ncompas = compas[cols]\n\nOur data now looks like this:\n\nis_white = compas[\"race\"] == \"Caucasian\" #is_white returns booleans\nis_black = compas[\"race\"] == \"African-American\"\n#compares the booleans\ncompas = compas[is_white | is_black]\ncompas = compas.copy()\ncompas.head()\n\n\n\n\n\n\n\n\nsex\nrace\ndecile_score\ntwo_year_recid\n\n\n\n\n1\nMale\nAfrican-American\n3\n1\n\n\n2\nMale\nAfrican-American\n4\n1\n\n\n3\nMale\nAfrican-American\n8\n0\n\n\n6\nMale\nCaucasian\n6\n1\n\n\n8\nFemale\nCaucasian\n1\n0\n\n\n\n\n\n\n\n\n\n\nLet’s do some quick exploration of our data. How many defendants are present in this data of each sex?\n\ncompas.groupby(\"sex\").size()\n\nsex\nFemale    1219\nMale      4931\ndtype: int64\n\n\nWhat about race?\n\ncompas.groupby(\"race\").size()\n\nrace\nAfrican-American    3696\nCaucasian           2454\ndtype: int64\n\n\nThe decile score is the algorithm’s prediction. Higher decile scores indicate that, according to the COMPAS model, the defendant has higher likelihood to be charged with a crime within the next two years. In the framework we’ve developed in this class, you can think of the decile score as being produced by computing a score like \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\) for each defendant \\(i\\), and then dividing these into the lowest 10% (decile score 1), the next 10% (decile score 2), the next 10% (decile score 3) and so on.\nThe easiest way to see how this looks is with a bar chart, which we can make efficiently using the seaborn (sns) package.\n\ncounts = compas.groupby([\"race\", \"decile_score\"]).size().reset_index(name = \"n\")\np = sns.barplot(data = counts, \n                x = \"decile_score\", \n                y = \"n\", \n                hue = \"race\", \n                palette = \"BuPu\", \n                saturation = 0.5)\n\n\n\n\n\n\n\n\nYou may notice that the number of white defendants who receive a given decile score tends to decrease as the score increases, whereas the number of Black defendants remains relatively constant.\nLet’s also take a look at the recidivism rate in the data:\n\ncompas[\"two_year_recid\"].mean()\n\n0.4661788617886179\n\n\nSo, in these data, approximately 47% of all defendants went on to be charged of another crime within the next two years. This is sometimes called the prevalence of the outcome. Although this is not a “good” outcome, it is labeled 1 in the target data and so we refer to this as the “positive” outcome. Prevalence without further specification usually refers to prevalence of the positive outcome.\nThe base rate of prediction accuracy in this problem is 53%: if we always guessed that the defendant was not arrested within two years, we would be right 53% of the time.\nWe can also compute the prevalence broken down by race of the defendant:\n\ncompas.groupby(\"race\")[\"two_year_recid\"].mean()\n\nrace\nAfrican-American    0.514\nCaucasian           0.394\nName: two_year_recid, dtype: float64\n\n\n\n\nWhen interpreting these different prevalences, it is important to remember that\n\nRace is itself a socially-constructed system of human categorization invented by humans with political and economic motives to describe other humans as property [@bonilla-silvaRacismRacistsColorblind2018].\n\nThe relation between arrest and actual criminal offense can display racial bias, with effects varying by geography [@fogliatoValidityArrestProxy2021].\nDecisions about which behaviors are criminal are contingent political decisions which have, historically, fallen hardest on Black Americans [@yusefCriminalizingRaceRacializing2017].\n\nThe prevalences between the two groups are substantially different. This difference will have major consequences later on for the possibility of different kinds of fairness in classifiers.\nWe’re going to treat the COMPAS algorithm as a binary classifier, but you might notice a problem: the algorithm’s prediction is the decile_score column, which is not actually a 0-1 label. Following the analysis of @angwin2022machine, we are going to construct a new binary column in which we say that a defendant is predicted_high_risk if their decile_score is larger than 4.\n\ncompas[\"predicted_high_risk\"] = compas[\"decile_score\"] &gt; 4 # if greater than four, you are a high risk\n\nNow that we’ve done that, we can ask: how likely are Black and white defendants to receive positive predictions in this data?\n\ncompas.groupby(\"race\")[[\"two_year_recid\", \"predicted_high_risk\"]].mean()\n\n\n\n\n\n\n\n\ntwo_year_recid\npredicted_high_risk\n\n\nrace\n\n\n\n\n\n\nAfrican-American\n0.514\n0.588\n\n\nCaucasian\n0.394\n0.348\n\n\n\n\n\n\n\nBlack defendants are substantially more likely to receive a positive prediction than white defendants, and the disparity is larger than the observed prevalence of the positive outcome.\n\n\n\n\n\n\nFairness (Part 1)\n\n\n\nIs this fair? What is your gut telling you? Yes, no, possibly? What information would you need in order to make a judgment? What is the principle on which your judgment rests?\n\n\n\n\n\nLet’s now ask a few questions about the the predictive accuracy of this algorithm. First, how accurate it is it overall?\n\ncompas[\"correct_prediction\"] = compas[\"predicted_high_risk\"] == compas[\"two_year_recid\"]\ncompas[\"correct_prediction\"].mean()\n\n0.6508943089430894\n\n\nRecall that the base rate in this problem is 53%, so our accuracy is somewhat better than random guessing.\nWhat about the accuracy on Black and white defendants separately?\n\ncompas.groupby([\"race\"])[\"correct_prediction\"].mean()\n\nrace\nAfrican-American    0.638\nCaucasian           0.670\nName: correct_prediction, dtype: float64\n\n\nThe overall accuracies for Black and white defendants are comparable, and both are somewhat higher than the base rate of 53%.\nWhat about the error rates? Here is a simple calculation which computes the false positive rate (FPR) in the first row and the true positive rate (TPR) on the bottom row:\n\ncompas.groupby([\"two_year_recid\"])[\"predicted_high_risk\"].mean()\n#checking false postive rate on top row (assessed at being at a high risk of committing another crime)\n#true positive rate on bottom row \n\ntwo_year_recid\n0    0.352\n1    0.654\nName: predicted_high_risk, dtype: float64\n\n\nHowever, and this was the main finding of the ProPublica study, the FPR and FNR are very different when we break down the data by race:\n\ncompas.groupby([\"two_year_recid\", \"race\"])[\"predicted_high_risk\"].mean()\n\ntwo_year_recid  race            \n0               African-American    0.448\n                Caucasian           0.235\n1               African-American    0.720\n                Caucasian           0.523\nName: predicted_high_risk, dtype: float64\n\n\nThe false positive rate for Black defendants is much higher than the false positive rate for white defendants. This was the main finding of @angwin2022machine. The FPR of 44% for Black defendants means that, out of every 100 Black defendants who in fact will not commit another crime, the algorithm nevertheless predicts that 44 of them will. In contrast, the FPR of 23% for white defendants indicates that only 23 out of 100 non-recidivating white defendants would be predicted to recidivate.\nThere are a few ways in which we can think of this result as reflecting bias:\n\nThe algorithm has learned an implicit pattern wherein Black defendants are intrinsically more “criminal” than white defendants, even among people who factually never committed another crime. This is a bias in the patterns that the algorithm has learned in order to formulate its predictions. This is related to the idea of representational bias, in which algorithms learn and reproduce toxic stereotypes about certain groups of people.\nRegardless of how the algorithm forms its predictions, the impact of the algorithm being used in the penal system is that more Black defendants will be classified as high-risk, resulting in more denials of parole, bail, early release, or other forms of freedom from the penal system. So, the algorithm has disparate impact on people. This is sometimes called allocative or distributional bias: bias in how resources or opportunities (in this case, freedom) are allocated or distributed between groups.\n\nSometimes predictive equality is also defined to require that the false negative rates (FNRs) be equal across the two groups as well.\nWe can think about the argument of @angwin2022machine as a two-step argument:\n\n\nThe COMPAS algorithm has disparate error rates by race.\nTherefore, the COMPAS algorithm is unjustly biased with respect to race.\n\n\nThis argument implicitly equates equality of error rates with lack of bias.\n\n\n\n\n\n\nFairness (Part 2)\n\n\n\n\nSuppose that we developed an alternative algorithm in which the false positive rates were equal, but there were still more positive predictions for Black defendants overall. Would that be enough to ensure fairness?\nSuppose that we developed an alternative prediction algorithm in which the rate of positive prediction was the same across racial groups, but the false positive rates were different. Would that be to ensure fairness?\n\n\n\n\n\n\n@angwin2022machine kicked off a vigorous discussion about what it means for an algorithm to fair and how to measure deviations from bias. In particular, Northpointe, the company that developed COMPAS, issued a report @flores2016false in which they argued that their algorithm was fair. Their argument is based on an idea of fairness which is sometimes called sufficiency @corbett-daviesAlgorithmicDecisionMaking2017.\nHere’s the intuition expressed by sufficiency. Imagine that you and your friend both received an A- in Data Structures. Suppose, however, that the instructor says different things to each of you:\n\nTo you, the instructor says: “You did fine in this class, but I don’t think that you are prepared to take Computer Architecture. I gave you a higher grade than I would normally because you wear cool hats in class.”\nTo your friend, the instructor says: “*You did fine in this class and I think you are prepared to take Computer Architecture. Some students got a bump in their grade because they are cool-hat-wearers, but you didn’t get that benefit.”\n\nFeels unfair, right? The instructor is saying that:\n\nWhat a grade means for you in terms of your future success depends on your identity group.\n\n\n\n\n\n\n\nNote\n\n\n\nSuppose that you heard this, but instead of cool hats it was because you are a member of an identity group that “needs some help” in order to achieve equitable representation in the CS major. How would you feel? Would that feel fair to you?\n\n\nWe’ll formally define sufficiency in a future lecture. For now, let’s use an informal definition:\n\nSufficiency means that a positive prediction means the same thing for future outcomes for each racial group.\n\nTo operationalize this idea, we are looking for the rate of re-arrest to be the same between (a) Black defendants who received a positive prediction and (b) white defendants who received a positive prediction.\nLet’s check this:\nThe rates of rearrest are relatively similar between groups when controlling for the predictions they collectively received. Formal statistical hypothesis tests are typically used to determine whether this difference is sufficiently “real” to warrant correction. In most of the published literature, scholars have considered that the two rates are sufficiently close that we should instead simply say that COMPAS appears to be relatively close to satisfying sufficiency.\nIndeed, in a rejoinder article published by affiliates of the company Northpointe which produced COMPAS, the fact that COMPAS satisfies sufficiency is one of the primary arguments [@flores2016false].\n\n\n\nIn these notes, we replicated the data analysis of @angwin2022machine, finding that the COMPAS algorithm has disparate error rates between Black and white defendants. We introduced the idea that fairness actually has several different facets in our moral intuitions, and found that the COMPAS algorithm satisfies one of them (sufficiency: equal scores mean the same thing regardless of your group membership) but not the others (equal prediction rates and equal error rates).\n\n\n\n\nCan we have it all? Could we modify the COMPAS algorithm in such a way that it satisfies all the ideas of fairness that we discussed above? Could we then call it “fair” or “unbiased?”\nAre there other ways to define fairness? Which ones are most compelling to us? Does the right idea of fairness depend on the context in which we apply it?\nHow did this happen? The COMPAS algorithm was never trained on race data about the defendant. How did it happen that this algorithm nevertheless made recommendations at different rates across groups?\nIs automated decision-making legitimate in this setting? Can it be legitimate (just, fair) to use an automated decision-system for making recommendations about parole and sentencing decisions at all? What safeguards and forms of recourse are necessary for the legitimate use of automated decision-making in criminal justice?\nWhat are the systemic impacts? Disparate sentencing decisions can have downstream impacts on communities and institutions. How could application of the COMPAS algorithm exacerbate systemic inequalities?"
  },
  {
    "objectID": "ClassNotes/10-compas.html#data-preparation",
    "href": "ClassNotes/10-compas.html#data-preparation",
    "title": "Introduction to Algorithmic Disparity: COMPAS",
    "section": "",
    "text": "Let’s first obtain the data. I’ve hosted a copy on the course website, so we can download it using a URL.This data set was obtained by @angwin2022machine through a public records request. The data comprises two years worth of COMPAS scoring in Broward County, Florida.\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nsns.set_style(\"whitegrid\")\nnp.set_printoptions(precision = 3)\npd.set_option('display.precision', 3)\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/compas/compas.csv\"\ncompas = pd.read_csv(url)\n\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\nIntel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n\n\nFor today we are only going to consider a subset of columns.\n\ncompas\n#v_decile_score predicts if the person will be arrested again. The higher, the more likely.\n#two_year_recid is if the last two years they committed another offense\n\n\n\n\n\n\n\n\nid\nname\nfirst\nlast\ncompas_screening_date\nsex\ndob\nage\nage_cat\nrace\n...\nv_decile_score\nv_score_text\nv_screening_date\nin_custody\nout_custody\npriors_count.1\nstart\nend\nevent\ntwo_year_recid\n\n\n\n\n0\n1\nmiguel hernandez\nmiguel\nhernandez\n2013-08-14\nMale\n1947-04-18\n69\nGreater than 45\nOther\n...\n1\nLow\n2013-08-14\n2014-07-07\n2014-07-14\n0\n0\n327\n0\n0\n\n\n1\n3\nkevon dixon\nkevon\ndixon\n2013-01-27\nMale\n1982-01-22\n34\n25 - 45\nAfrican-American\n...\n1\nLow\n2013-01-27\n2013-01-26\n2013-02-05\n0\n9\n159\n1\n1\n\n\n2\n4\ned philo\ned\nphilo\n2013-04-14\nMale\n1991-05-14\n24\nLess than 25\nAfrican-American\n...\n3\nLow\n2013-04-14\n2013-06-16\n2013-06-16\n4\n0\n63\n0\n1\n\n\n3\n5\nmarcu brown\nmarcu\nbrown\n2013-01-13\nMale\n1993-01-21\n23\nLess than 25\nAfrican-American\n...\n6\nMedium\n2013-01-13\nNaN\nNaN\n1\n0\n1174\n0\n0\n\n\n4\n6\nbouthy pierrelouis\nbouthy\npierrelouis\n2013-03-26\nMale\n1973-01-22\n43\n25 - 45\nOther\n...\n1\nLow\n2013-03-26\nNaN\nNaN\n2\n0\n1102\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n7209\n10996\nsteven butler\nsteven\nbutler\n2013-11-23\nMale\n1992-07-17\n23\nLess than 25\nAfrican-American\n...\n5\nMedium\n2013-11-23\n2013-11-22\n2013-11-24\n0\n1\n860\n0\n0\n\n\n7210\n10997\nmalcolm simmons\nmalcolm\nsimmons\n2014-02-01\nMale\n1993-03-25\n23\nLess than 25\nAfrican-American\n...\n5\nMedium\n2014-02-01\n2014-01-31\n2014-02-02\n0\n1\n790\n0\n0\n\n\n7211\n10999\nwinston gregory\nwinston\ngregory\n2014-01-14\nMale\n1958-10-01\n57\nGreater than 45\nOther\n...\n1\nLow\n2014-01-14\n2014-01-13\n2014-01-14\n0\n0\n808\n0\n0\n\n\n7212\n11000\nfarrah jean\nfarrah\njean\n2014-03-09\nFemale\n1982-11-17\n33\n25 - 45\nAfrican-American\n...\n2\nLow\n2014-03-09\n2014-03-08\n2014-03-09\n3\n0\n754\n0\n0\n\n\n7213\n11001\nflorencia sanmartin\nflorencia\nsanmartin\n2014-06-30\nFemale\n1992-12-18\n23\nLess than 25\nHispanic\n...\n4\nLow\n2014-06-30\n2015-03-15\n2015-03-15\n2\n0\n258\n0\n1\n\n\n\n\n7214 rows × 53 columns\n\n\n\nWe are also only going to consider white (Caucasian) and Black (African-American) defendants:\n\ncols = [\"sex\", \"race\", \"decile_score\", \"two_year_recid\"]\ncompas = compas[cols]\n\nOur data now looks like this:\n\nis_white = compas[\"race\"] == \"Caucasian\" #is_white returns booleans\nis_black = compas[\"race\"] == \"African-American\"\n#compares the booleans\ncompas = compas[is_white | is_black]\ncompas = compas.copy()\ncompas.head()\n\n\n\n\n\n\n\n\nsex\nrace\ndecile_score\ntwo_year_recid\n\n\n\n\n1\nMale\nAfrican-American\n3\n1\n\n\n2\nMale\nAfrican-American\n4\n1\n\n\n3\nMale\nAfrican-American\n8\n0\n\n\n6\nMale\nCaucasian\n6\n1\n\n\n8\nFemale\nCaucasian\n1\n0"
  },
  {
    "objectID": "ClassNotes/10-compas.html#preliminary-explorations",
    "href": "ClassNotes/10-compas.html#preliminary-explorations",
    "title": "Introduction to Algorithmic Disparity: COMPAS",
    "section": "",
    "text": "Let’s do some quick exploration of our data. How many defendants are present in this data of each sex?\n\ncompas.groupby(\"sex\").size()\n\nsex\nFemale    1219\nMale      4931\ndtype: int64\n\n\nWhat about race?\n\ncompas.groupby(\"race\").size()\n\nrace\nAfrican-American    3696\nCaucasian           2454\ndtype: int64\n\n\nThe decile score is the algorithm’s prediction. Higher decile scores indicate that, according to the COMPAS model, the defendant has higher likelihood to be charged with a crime within the next two years. In the framework we’ve developed in this class, you can think of the decile score as being produced by computing a score like \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\) for each defendant \\(i\\), and then dividing these into the lowest 10% (decile score 1), the next 10% (decile score 2), the next 10% (decile score 3) and so on.\nThe easiest way to see how this looks is with a bar chart, which we can make efficiently using the seaborn (sns) package.\n\ncounts = compas.groupby([\"race\", \"decile_score\"]).size().reset_index(name = \"n\")\np = sns.barplot(data = counts, \n                x = \"decile_score\", \n                y = \"n\", \n                hue = \"race\", \n                palette = \"BuPu\", \n                saturation = 0.5)\n\n\n\n\n\n\n\n\nYou may notice that the number of white defendants who receive a given decile score tends to decrease as the score increases, whereas the number of Black defendants remains relatively constant.\nLet’s also take a look at the recidivism rate in the data:\n\ncompas[\"two_year_recid\"].mean()\n\n0.4661788617886179\n\n\nSo, in these data, approximately 47% of all defendants went on to be charged of another crime within the next two years. This is sometimes called the prevalence of the outcome. Although this is not a “good” outcome, it is labeled 1 in the target data and so we refer to this as the “positive” outcome. Prevalence without further specification usually refers to prevalence of the positive outcome.\nThe base rate of prediction accuracy in this problem is 53%: if we always guessed that the defendant was not arrested within two years, we would be right 53% of the time.\nWe can also compute the prevalence broken down by race of the defendant:\n\ncompas.groupby(\"race\")[\"two_year_recid\"].mean()\n\nrace\nAfrican-American    0.514\nCaucasian           0.394\nName: two_year_recid, dtype: float64\n\n\n\n\nWhen interpreting these different prevalences, it is important to remember that\n\nRace is itself a socially-constructed system of human categorization invented by humans with political and economic motives to describe other humans as property [@bonilla-silvaRacismRacistsColorblind2018].\n\nThe relation between arrest and actual criminal offense can display racial bias, with effects varying by geography [@fogliatoValidityArrestProxy2021].\nDecisions about which behaviors are criminal are contingent political decisions which have, historically, fallen hardest on Black Americans [@yusefCriminalizingRaceRacializing2017].\n\nThe prevalences between the two groups are substantially different. This difference will have major consequences later on for the possibility of different kinds of fairness in classifiers.\nWe’re going to treat the COMPAS algorithm as a binary classifier, but you might notice a problem: the algorithm’s prediction is the decile_score column, which is not actually a 0-1 label. Following the analysis of @angwin2022machine, we are going to construct a new binary column in which we say that a defendant is predicted_high_risk if their decile_score is larger than 4.\n\ncompas[\"predicted_high_risk\"] = compas[\"decile_score\"] &gt; 4 # if greater than four, you are a high risk\n\nNow that we’ve done that, we can ask: how likely are Black and white defendants to receive positive predictions in this data?\n\ncompas.groupby(\"race\")[[\"two_year_recid\", \"predicted_high_risk\"]].mean()\n\n\n\n\n\n\n\n\ntwo_year_recid\npredicted_high_risk\n\n\nrace\n\n\n\n\n\n\nAfrican-American\n0.514\n0.588\n\n\nCaucasian\n0.394\n0.348\n\n\n\n\n\n\n\nBlack defendants are substantially more likely to receive a positive prediction than white defendants, and the disparity is larger than the observed prevalence of the positive outcome.\n\n\n\n\n\n\nFairness (Part 1)\n\n\n\nIs this fair? What is your gut telling you? Yes, no, possibly? What information would you need in order to make a judgment? What is the principle on which your judgment rests?"
  },
  {
    "objectID": "ClassNotes/10-compas.html#the-propublica-findings",
    "href": "ClassNotes/10-compas.html#the-propublica-findings",
    "title": "Introduction to Algorithmic Disparity: COMPAS",
    "section": "",
    "text": "Let’s now ask a few questions about the the predictive accuracy of this algorithm. First, how accurate it is it overall?\n\ncompas[\"correct_prediction\"] = compas[\"predicted_high_risk\"] == compas[\"two_year_recid\"]\ncompas[\"correct_prediction\"].mean()\n\n0.6508943089430894\n\n\nRecall that the base rate in this problem is 53%, so our accuracy is somewhat better than random guessing.\nWhat about the accuracy on Black and white defendants separately?\n\ncompas.groupby([\"race\"])[\"correct_prediction\"].mean()\n\nrace\nAfrican-American    0.638\nCaucasian           0.670\nName: correct_prediction, dtype: float64\n\n\nThe overall accuracies for Black and white defendants are comparable, and both are somewhat higher than the base rate of 53%.\nWhat about the error rates? Here is a simple calculation which computes the false positive rate (FPR) in the first row and the true positive rate (TPR) on the bottom row:\n\ncompas.groupby([\"two_year_recid\"])[\"predicted_high_risk\"].mean()\n#checking false postive rate on top row (assessed at being at a high risk of committing another crime)\n#true positive rate on bottom row \n\ntwo_year_recid\n0    0.352\n1    0.654\nName: predicted_high_risk, dtype: float64\n\n\nHowever, and this was the main finding of the ProPublica study, the FPR and FNR are very different when we break down the data by race:\n\ncompas.groupby([\"two_year_recid\", \"race\"])[\"predicted_high_risk\"].mean()\n\ntwo_year_recid  race            \n0               African-American    0.448\n                Caucasian           0.235\n1               African-American    0.720\n                Caucasian           0.523\nName: predicted_high_risk, dtype: float64\n\n\nThe false positive rate for Black defendants is much higher than the false positive rate for white defendants. This was the main finding of @angwin2022machine. The FPR of 44% for Black defendants means that, out of every 100 Black defendants who in fact will not commit another crime, the algorithm nevertheless predicts that 44 of them will. In contrast, the FPR of 23% for white defendants indicates that only 23 out of 100 non-recidivating white defendants would be predicted to recidivate.\nThere are a few ways in which we can think of this result as reflecting bias:\n\nThe algorithm has learned an implicit pattern wherein Black defendants are intrinsically more “criminal” than white defendants, even among people who factually never committed another crime. This is a bias in the patterns that the algorithm has learned in order to formulate its predictions. This is related to the idea of representational bias, in which algorithms learn and reproduce toxic stereotypes about certain groups of people.\nRegardless of how the algorithm forms its predictions, the impact of the algorithm being used in the penal system is that more Black defendants will be classified as high-risk, resulting in more denials of parole, bail, early release, or other forms of freedom from the penal system. So, the algorithm has disparate impact on people. This is sometimes called allocative or distributional bias: bias in how resources or opportunities (in this case, freedom) are allocated or distributed between groups.\n\nSometimes predictive equality is also defined to require that the false negative rates (FNRs) be equal across the two groups as well.\nWe can think about the argument of @angwin2022machine as a two-step argument:\n\n\nThe COMPAS algorithm has disparate error rates by race.\nTherefore, the COMPAS algorithm is unjustly biased with respect to race.\n\n\nThis argument implicitly equates equality of error rates with lack of bias.\n\n\n\n\n\n\nFairness (Part 2)\n\n\n\n\nSuppose that we developed an alternative algorithm in which the false positive rates were equal, but there were still more positive predictions for Black defendants overall. Would that be enough to ensure fairness?\nSuppose that we developed an alternative prediction algorithm in which the rate of positive prediction was the same across racial groups, but the false positive rates were different. Would that be to ensure fairness?"
  },
  {
    "objectID": "ClassNotes/10-compas.html#the-rebuttal",
    "href": "ClassNotes/10-compas.html#the-rebuttal",
    "title": "Introduction to Algorithmic Disparity: COMPAS",
    "section": "",
    "text": "@angwin2022machine kicked off a vigorous discussion about what it means for an algorithm to fair and how to measure deviations from bias. In particular, Northpointe, the company that developed COMPAS, issued a report @flores2016false in which they argued that their algorithm was fair. Their argument is based on an idea of fairness which is sometimes called sufficiency @corbett-daviesAlgorithmicDecisionMaking2017.\nHere’s the intuition expressed by sufficiency. Imagine that you and your friend both received an A- in Data Structures. Suppose, however, that the instructor says different things to each of you:\n\nTo you, the instructor says: “You did fine in this class, but I don’t think that you are prepared to take Computer Architecture. I gave you a higher grade than I would normally because you wear cool hats in class.”\nTo your friend, the instructor says: “*You did fine in this class and I think you are prepared to take Computer Architecture. Some students got a bump in their grade because they are cool-hat-wearers, but you didn’t get that benefit.”\n\nFeels unfair, right? The instructor is saying that:\n\nWhat a grade means for you in terms of your future success depends on your identity group.\n\n\n\n\n\n\n\nNote\n\n\n\nSuppose that you heard this, but instead of cool hats it was because you are a member of an identity group that “needs some help” in order to achieve equitable representation in the CS major. How would you feel? Would that feel fair to you?\n\n\nWe’ll formally define sufficiency in a future lecture. For now, let’s use an informal definition:\n\nSufficiency means that a positive prediction means the same thing for future outcomes for each racial group.\n\nTo operationalize this idea, we are looking for the rate of re-arrest to be the same between (a) Black defendants who received a positive prediction and (b) white defendants who received a positive prediction.\nLet’s check this:\nThe rates of rearrest are relatively similar between groups when controlling for the predictions they collectively received. Formal statistical hypothesis tests are typically used to determine whether this difference is sufficiently “real” to warrant correction. In most of the published literature, scholars have considered that the two rates are sufficiently close that we should instead simply say that COMPAS appears to be relatively close to satisfying sufficiency.\nIndeed, in a rejoinder article published by affiliates of the company Northpointe which produced COMPAS, the fact that COMPAS satisfies sufficiency is one of the primary arguments [@flores2016false]."
  },
  {
    "objectID": "ClassNotes/10-compas.html#recap",
    "href": "ClassNotes/10-compas.html#recap",
    "title": "Introduction to Algorithmic Disparity: COMPAS",
    "section": "",
    "text": "In these notes, we replicated the data analysis of @angwin2022machine, finding that the COMPAS algorithm has disparate error rates between Black and white defendants. We introduced the idea that fairness actually has several different facets in our moral intuitions, and found that the COMPAS algorithm satisfies one of them (sufficiency: equal scores mean the same thing regardless of your group membership) but not the others (equal prediction rates and equal error rates)."
  },
  {
    "objectID": "ClassNotes/10-compas.html#some-questions-moving-forward",
    "href": "ClassNotes/10-compas.html#some-questions-moving-forward",
    "title": "Introduction to Algorithmic Disparity: COMPAS",
    "section": "",
    "text": "Can we have it all? Could we modify the COMPAS algorithm in such a way that it satisfies all the ideas of fairness that we discussed above? Could we then call it “fair” or “unbiased?”\nAre there other ways to define fairness? Which ones are most compelling to us? Does the right idea of fairness depend on the context in which we apply it?\nHow did this happen? The COMPAS algorithm was never trained on race data about the defendant. How did it happen that this algorithm nevertheless made recommendations at different rates across groups?\nIs automated decision-making legitimate in this setting? Can it be legitimate (just, fair) to use an automated decision-system for making recommendations about parole and sentencing decisions at all? What safeguards and forms of recourse are necessary for the legitimate use of automated decision-making in criminal justice?\nWhat are the systemic impacts? Disparate sentencing decisions can have downstream impacts on communities and institutions. How could application of the COMPAS algorithm exacerbate systemic inequalities?"
  },
  {
    "objectID": "ClassNotes/03-score-based-classification.html",
    "href": "ClassNotes/03-score-based-classification.html",
    "title": "Score-Based Classification",
    "section": "",
    "text": "A particular focus of this course is the use of machine learning models for automated decision-making. Now that we’ve been introduced to the fundamental idea of finding patterns in data, let’s jump straight into a problem of predictive modeling. Predictive modeling is based on a simple idea: let’s use past observations to make decisions about the future, in an automated way.\n\n\nBanks are in the business of lending money, and they must often decide when to loan whom how much money and under what terms. When deciding whether to loan a sum of money, there are two major competing questions:\n\nHow much profit does the bank stand to make if the loan is paid off in full?\nWhat is the risk that an individual might default on their loan and fail to pay it back? In this case, the bank may lose a significant fraction of the loan amount.\n\nBanks can try to balance these risks by controlling interest rates. Higher interest rates increase prospective profit if the loan is repaid in full, but also increase the risk that an individual may be unable to keep up with payments.\nThe judgment of whether to extend an individual a loan is handled by human experts. Recently, human experts have been seeking assistance from machine learning algorithms. As in most predictive modeling, the idea is to use the past to predict the future. Here, we’ll consider simple modeling problem in which we aim to learn patterns in when individuals are able to pay off loans, and use these patterns to make predictions.\nWe’ll first load in the pandas package and use the read_csv command to acquire our data for this problem as a pd.DataFrame. This data set was produced by Kaggle; it is a simulated data set based on patterns in real world data, which, of course, is sensitive and confidential. For today, we are only going to focus on the first 1,000 rows of data.\n\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport numpy as np \nplt.style.use('seaborn-v0_8-whitegrid')\n\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/credit_risk_dataset.csv\"\n\n\ndf = pd.read_csv(url)\n\nLet’s take a look at an excerpt of the data.\n\ndf = df.head(1000).copy() #grab first 1000 rows\ndf\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n22\n59000\nRENT\n123.0\nPERSONAL\nD\n35000\n16.02\n1\n0.59\nY\n3\n\n\n1\n21\n9600\nOWN\n5.0\nEDUCATION\nB\n1000\n11.14\n0\n0.10\nN\n2\n\n\n2\n25\n9600\nMORTGAGE\n1.0\nMEDICAL\nC\n5500\n12.87\n1\n0.57\nN\n3\n\n\n3\n23\n65500\nRENT\n4.0\nMEDICAL\nC\n35000\n15.23\n1\n0.53\nN\n2\n\n\n4\n24\n54400\nRENT\n8.0\nMEDICAL\nC\n35000\n14.27\n1\n0.55\nY\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n995\n22\n46610\nRENT\n6.0\nDEBTCONSOLIDATION\nB\n18000\n10.71\n1\n0.39\nN\n3\n\n\n996\n24\n48000\nRENT\n5.0\nPERSONAL\nA\n18000\n6.54\n1\n0.38\nN\n2\n\n\n997\n23\n24000\nOWN\n0.0\nPERSONAL\nA\n8000\n5.79\n0\n0.33\nN\n3\n\n\n998\n25\n55000\nRENT\n2.0\nEDUCATION\nC\n18000\n12.84\n1\n0.33\nN\n2\n\n\n999\n25\n55344\nRENT\n2.0\nHOMEIMPROVEMENT\nB\n18000\n10.99\n1\n0.33\nN\n4\n\n\n\n\n1000 rows × 12 columns\n\n\n\nEach row of this data set describes a single loan and the attributes of the borrower. For visualization purposes, today we are going to focus on just three of the columns:\n\nloan_percent_income is the ratio of the loan amount to the annual income of the individual.\nloan_int_rate is the interest rate on the loan.\nloan_status describes whether or not the individual defaulted on the loan. This column has value 1 if the individual defaulted on the loan and value 0 if the loan was repaid in full.\n\nOur primary predictive interest is whether or not a borrower is likely to default on a loan. How common is this in our data set?\n\ndf['loan_status'].mean()\n#percentage of defaults\n\n0.553\n\n\nIn this data, roughly 55% of borrowers default on their loan. An important aspect of this learning is the base rate for prediction. If we predicted that every borrower would default on a loan, we would be right 55% of the time. So, if we want to find patterns in our data set and use those patterns to make predictions, we should aim for accuracy greater than 55%.\nSo, can we find some patterns? Here is a labeled scatterplot of our simplified data set.\n\ndef scatter_data(ax, df):\n\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        to_plot = df[df[\"loan_status\"] == i]\n        ax.scatter(to_plot[\"loan_int_rate\"], to_plot[\"loan_percent_income\"], c = to_plot[\"loan_status\"], vmin = -0.5, vmax = 1.5, facecolors='none', edgecolors = \"darkgrey\", alpha = 0.5, label = f\"{['repaid', 'defaulted'][i]}\", cmap = \"BrBG\", marker = markers[i])\n        ax.legend()\n        ax.set(xlabel = \"Loan interest rate\", ylabel = \"Loan / income ratio\")\n\ndf = df.head(1000)\nfig, ax = plt.subplots(1, 1)\nscatter_data(ax, df)\n\n\n\n\n\n\n\n\nAlthough it looks difficult to completely separate the defaulted loans from the loans which were repaid in full, it does look like there is some pattern to find. Loans which were repaid in full concentrate in the lower right corner of the visualization. This makes sense – these are loans which have low interest rates and which are relatively small sums relative to the annual resources of the borrower.\nA very common approach in problems like this one is to assign, to each loan applicant \\(i\\), a score \\(s_i\\) which predicts their likelihood to default on a loan. Higher scores indicate greater reliability. Let’s formulate a linear score function:\n\\[\n\\begin{aligned}\n    s_i = w_1 \\times (\\text{loan interest rate}_i) + w_2 \\times (\\text{loan percent income/loan/income ratio}_i)\\;.\n\\end{aligned}\n\\]\nWe can write this score function much more compactly by defining a data point\n\\[\n\\begin{aligned}\n    \\mathbf{x}_{i} = \\left(\\text{loan interest rate}_i, \\text{loan percent income}_i\\right)\n\\end{aligned}\n\\]\nand weight vector\n\\[\n\\begin{aligned}\n    \\mathbf{w} = \\left(w_1, w_2\\right)\\;.\n\\end{aligned}\n\\]\nThen, we can compactly write our score function as\n\\[\n\\begin{aligned}\n    s_i = \\langle \\mathbf{w}, \\mathbf{x}_i\\rangle\\;.\n\\end{aligned}\n\\tag{1}\\]\nLet’s implement this score in Python.\n\ndef linear_score(w, x0, x1):\n    return w[0] * x0 + w[1] * x1\n#scoer of all data simiultaneously\n\nNow we can plot this score function in the data space.\n\n\nShow code\ndef plot_score(ax, score_fun, w, df):\n    \"\"\"\n    Plot a given score function on axis ax with weights w and data df. \n    \"\"\"\n\n    x0_col = \"loan_int_rate\"\n    x1_col = \"loan_percent_income\"\n\n    x0_min, x0_max = df[x0_col].min(), df[x0_col].max()\n    x1_min, x1_max = df[x1_col].min(), df[x1_col].max()\n\n    x0 = np.linspace(x0_min, x0_max, 101)\n    x1 = np.linspace(x1_min, x1_max, 101)\n\n    X0, X1 = np.meshgrid(x0, x1)\n    S = score_fun(w, X0, X1)\n\n    ticks = np.linspace(0, 101, 6)\n\n    im = ax.contourf(X0, X1, S, origin = \"lower\", extent = (x0_min, x0_max, x1_min, x1_max),  cmap = \"BrBG\", vmin = 2*S.min() - S.max(), vmax = 2*S.max() - S.min())\n    \n    ax.set(xlabel = \"Loan interest rate\", ylabel = \"Loan / income ratio\")\n    \n    cbar = plt.colorbar(im, )\n    cbar.set_label(\"Predicted score\")\n\ndef score_viz(score_fun, w, df):\n    fig, ax = plt.subplots(1, 2, figsize = (7, 2.7)) \n    plot_score(ax[0], score_fun, w, df)\n    plot_score(ax[1], score_fun, w, df)\n    scatter_data(ax[1], df)\n    plt.tight_layout()\n\n\nTo see the scores, we need to make an initial choice about the weight vector \\(\\mathbf{w}\\).\n\nw = np.array([0.4, -2.0])\nscore_viz(linear_score, w, df)\n\n\n\n\n\n\n\n\nHmmm, that doesn’t look so good. Ideally, we’d like the higher scores to line up with the borrowers who defaulted, and the lower scores to line up with the borrowers who fully repaid their loans. Can we find a better choice?\n\nw = np.array([0.01, 1.1])\nscore_viz(linear_score, w, df)\n\n\n\n\n\n\n\n\nThis looks a bit better! You might be wondering: isn’t there a better way to choose the weight vector \\(\\mathbf{w}\\) than to guess and check? Of course there is! This is the topic of model training, which we will come to soon.\n\n\n\nOk, great – we have a risk score for historical applicants. We can even compute risk scores for future applicants: plug their data into Equation 1. But in order to make a decision, we need to conver the score into a yes-no decision. A common way to do this is called thresholding: we pick a threshold \\(t\\) and approve a loan to individual \\(i\\) of \\(s_i &lt; t\\). Loan granted if \\(s_i &lt; t\\).\n\n\nShow code\ndef plot_threshold(ax, score_fun, w, df, threshold):\n    \"\"\"\n    Plot the t-level-set of a given score function on axis ax with weights w and data df. \n    \"\"\"\n    x0_col = \"loan_int_rate\"\n    x1_col = \"loan_percent_income\"\n\n    x0_min, x0_max = df[x0_col].min(), df[x0_col].max()\n    x1_min, x1_max = df[x1_col].min(), df[x1_col].max()\n\n    x0 = np.linspace(x0_min, x0_max, 101)\n    x1 = np.linspace(x1_min, x1_max, 101)\n\n    X0, X1 = np.meshgrid(x0, x1)\n    S = score_fun(w, X0, X1)\n\n    ax.contour(X0, X1, S, levels = [threshold], colors = [\"black\"], linestyles = [\"--\"])\n\n\nNow we can pick a threshold and see how it does in dividing borrowers who fully repay loans from borrowers who default:\n\nthreshold = 0.4 # = t\n\n\nfig, ax = plt.subplots(1, 1)\nplot_score(ax, linear_score, w, df)\nscatter_data(ax, df) \nplot_threshold(ax, linear_score, w,  df, threshold)\n\n\n\n\n\n\n\nFigure 1: Linear score-based classification.\n\n\n\n\n\nSomething interesting to notice here is that our two step method of computing a linear score function and thresholding gave us the same linear classification pattern as the one we saw in ?@fig-examples-with-patterns-2.\nFinally, once we’ve picked the weight vector \\(\\mathbf{w}\\) and a threshold function \\(t\\), we are ready to simulate making decisions. For example, with our current weights and threshold, we can add a column with what our retrospective “decisions” would have been on this historical data. Here is a function that generates the column.\n\ndef predict(score_fun, w, threshold, df):\n    \n    #make binary predictions for data df using a supplied score function with weights w and supplied threshold. \n    \n    scores = score_fun(w, df['loan_int_rate'], df['loan_percent_income'])\n    return 1 * (scores &gt; threshold)\n\nNow let’s use this function to add the predictions as a new column in the data frame:\n\ndf[\"decision\"] = predict(linear_score, w, threshold, df) \ndf\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\ndecision\n\n\n\n\n0\n22\n59000\nRENT\n123.0\nPERSONAL\nD\n35000\n16.02\n1\n0.59\nY\n3\n1\n\n\n1\n21\n9600\nOWN\n5.0\nEDUCATION\nB\n1000\n11.14\n0\n0.10\nN\n2\n0\n\n\n2\n25\n9600\nMORTGAGE\n1.0\nMEDICAL\nC\n5500\n12.87\n1\n0.57\nN\n3\n1\n\n\n3\n23\n65500\nRENT\n4.0\nMEDICAL\nC\n35000\n15.23\n1\n0.53\nN\n2\n1\n\n\n4\n24\n54400\nRENT\n8.0\nMEDICAL\nC\n35000\n14.27\n1\n0.55\nY\n4\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n995\n22\n46610\nRENT\n6.0\nDEBTCONSOLIDATION\nB\n18000\n10.71\n1\n0.39\nN\n3\n1\n\n\n996\n24\n48000\nRENT\n5.0\nPERSONAL\nA\n18000\n6.54\n1\n0.38\nN\n2\n1\n\n\n997\n23\n24000\nOWN\n0.0\nPERSONAL\nA\n8000\n5.79\n0\n0.33\nN\n3\n1\n\n\n998\n25\n55000\nRENT\n2.0\nEDUCATION\nC\n18000\n12.84\n1\n0.33\nN\n2\n1\n\n\n999\n25\n55344\nRENT\n2.0\nHOMEIMPROVEMENT\nB\n18000\n10.99\n1\n0.33\nN\n4\n1\n\n\n\n\n1000 rows × 13 columns\n\n\n\nWould our decisions have accurately reflected who in fact defaulted? One way to address this question is by measuring the accuracy of our decisions, which we can compute using vectorized code:\n\n(df[\"decision\"] == df[\"loan_status\"]).mean()\n\n0.767\n\n\nThis accuracy is much higher than the base rate, suggesting that we have indeed learned some amount of pattern in our data.\n\n\n\nYou’ll notice in Figure 1 that the decision boundary is a straight line. This is due to the way that we chose to compute scores. Recall that the score function we used is \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\). Since we imposed a threshold \\(t\\), the decision boundary is defined by the equation \\(t = s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\). Generically, this is the equation of a hyperplane (technically, an affine subspace). The dimension of this space is \\(p-1\\), where \\(p\\) is the number of features. Here we have two features, so the decision boundary is a \\(2-1=1\\)-dimensional subspace–i.e. a line.\nWhat if we think a curved decision boundary would be more appropriate? In that case, we need to define a score function that factors in the features in a nonlinear way.\nWe started by representing each point as a 2-vector of predictors \\(\\mathbf{x} = \\left(\\text{loan interest rate}, \\text{loan percent income}\\right)\\). Let’s now add a feature map \\(\\phi\\) that accepts this vector and adds three nonlinear functions of the predictors:\n\\[\n\\begin{aligned}\n    \\phi(\\mathbf{x}) =\n        \\left(\\begin{matrix}\n            \\text{loan interest rate} \\\\\n            \\text{loan percent income} \\\\\n            \\left(\\text{loan interest rate}\\right)^2 \\\\  \n            \\left(\\text{loan percent income}\\right)^2 \\\\\n            \\text{loan interest rate} \\times \\text{loan percent income}\n        \\end{matrix}\\right)\n\\end{aligned}\n\\]\nBecause the new features are order-2 polynomials in the predictors, this feature map is often called the quadratic feature map.\nWe’ll still use an inner product to compute our score but now the formula will be  \\[\n\\begin{aligned}\n    s_i = \\langle \\mathbf{w}, \\phi(\\mathbf{x}_i) \\rangle\\;.\n\\end{aligned}\n\\]In order for this formula to make sense, we now need \\(\\mathbf{w}\\in \\mathbb{R}^5\\).\nHere’s an implementation of a score function with quadratic features:\n\ndef quadratic_score(w, X0, X1):\n    return w[0]*X0 + w[1]*X1 + w[2]*X0**2 + w[3]*X1**2 + w[4]*X0*X1\n\nNow we can set a new vector of weights \\(\\mathbf{w}\\in \\mathbb{R}^5\\) and a threshold \\(t\\).\n\nw = np.array([0.01, 1, 0.0005, 0.6, 0.001])\nthreshold = 0.5\n\nOur classification now looks like this:\n\nfig, ax = plt.subplots(1, 1)\nplot_score(ax, quadratic_score, w, df)\nscatter_data(ax, df)\nplot_threshold(ax, quadratic_score, w,  df, threshold)\n\n\n\n\n\n\n\nFigure 2: quadratic score-based classification.\n\n\n\n\n\nHow accurate were we?\n\ndf[\"decision\"] = predict(quadratic_score, w, threshold, df)\n(df[\"decision\"] == df[\"loan_status\"]).mean()\n\n0.777\n\n\nOur nonlinear score function was very slightly more accurate than our linear score function on training data. A few things to keep in mind:\n\nPerformance on training data is not always a reliable indicator of performance on unseen data.\nAdding nonlinear features is one way of adding flexibility to a model, allowing that model to learn complicated, “wiggly” decision patterns. As we saw with the Palmer penguins case study, too much model flexibility can lead to worse predictive performance. We’ll regularly revisit the problem of balancing flexibility/features against predictive generalization throughout these notes.\n\n\n\nSo, we looked at a simplified data set in which we were able to observe some features of each prospective borrower \\(i\\) in the form of a vector \\(\\mathbf{x}_i\\). We then computed a score for each borrower \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\) and used a threshold to decide whether or not to make a loan: the loan is approved if \\(s_i \\leq t\\) for a chosen threshold \\(t\\). We can think of this as a decision-making model for the loan approval problem.\nIs that the end of the story? Of course not! There are many questions remaining.\n\nModel Evaluation: How do we actually measure whether our decision-making model is good or not? Is accuracy the right measure? Is computing accuracy on the training data reliable? How would the model perform on unseen data that wasn’t used to decide \\(\\mathbf{w}\\) or \\(t\\)? What other ways could we measure the performance of models?\nLegitimacy: Is it morally and politically appropriate to use algorithmic decision-making in the context of loan applications? What is the potential for disparate harm? What is the potential for contributing to the reinforcement of historically disparity? In what cases could algorithmic loan-making be appropriate in a democratic society? In what cases could it constitute a violation of personal political or moral rights?\nTask Choice: How was the data collected? Is it complete? Why did I choose a certain set of predictors and targets? Are my predictors and targets reliable measurements of what they claim to represent? Whose interests are served by the existence of a machine learning model that completes this task?\nAlgorithm Design: What algorithm was used to find the model (i.e. the separating line)? Is that algorithm guaranteed to converge? Will it converge quickly? Would a different algorithm find a better model? Or would it find a model that is equally good more quickly?\nVectorization: Instead of classifying points in a measurement space, how could I instead classify images, videos, or bodies of text?\n\nWe’ll discuss all of these questions – in approximately this order – later in these notes."
  },
  {
    "objectID": "ClassNotes/03-score-based-classification.html#what-about-nonlinear-scores",
    "href": "ClassNotes/03-score-based-classification.html#what-about-nonlinear-scores",
    "title": "Score-Based Classification",
    "section": "",
    "text": "You’ll notice in Figure 1 that the decision boundary is a straight line. This is due to the way that we chose to compute scores. Recall that the score function we used is \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\). Since we imposed a threshold \\(t\\), the decision boundary is defined by the equation \\(t = s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\). Generically, this is the equation of a hyperplane (technically, an affine subspace). The dimension of this space is \\(p-1\\), where \\(p\\) is the number of features. Here we have two features, so the decision boundary is a \\(2-1=1\\)-dimensional subspace–i.e. a line.\nWhat if we think a curved decision boundary would be more appropriate? In that case, we need to define a score function that factors in the features in a nonlinear way.\nWe started by representing each point as a 2-vector of predictors \\(\\mathbf{x} = \\left(\\text{loan interest rate}, \\text{loan percent income}\\right)\\). Let’s now add a feature map \\(\\phi\\) that accepts this vector and adds three nonlinear functions of the predictors:\n\\[\n\\begin{aligned}\n    \\phi(\\mathbf{x}) =\n        \\left(\\begin{matrix}\n            \\text{loan interest rate} \\\\\n            \\text{loan percent income} \\\\\n            \\left(\\text{loan interest rate}\\right)^2 \\\\  \n            \\left(\\text{loan percent income}\\right)^2 \\\\\n            \\text{loan interest rate} \\times \\text{loan percent income}\n        \\end{matrix}\\right)\n\\end{aligned}\n\\]\nBecause the new features are order-2 polynomials in the predictors, this feature map is often called the quadratic feature map.\nWe’ll still use an inner product to compute our score but now the formula will be  \\[\n\\begin{aligned}\n    s_i = \\langle \\mathbf{w}, \\phi(\\mathbf{x}_i) \\rangle\\;.\n\\end{aligned}\n\\]In order for this formula to make sense, we now need \\(\\mathbf{w}\\in \\mathbb{R}^5\\).\nHere’s an implementation of a score function with quadratic features:\n\ndef quadratic_score(w, X0, X1):\n    return w[0]*X0 + w[1]*X1 + w[2]*X0**2 + w[3]*X1**2 + w[4]*X0*X1\n\nNow we can set a new vector of weights \\(\\mathbf{w}\\in \\mathbb{R}^5\\) and a threshold \\(t\\).\n\nw = np.array([0.01, 1, 0.0005, 0.6, 0.001])\nthreshold = 0.5\n\nOur classification now looks like this:\n\nfig, ax = plt.subplots(1, 1)\nplot_score(ax, quadratic_score, w, df)\nscatter_data(ax, df)\nplot_threshold(ax, quadratic_score, w,  df, threshold)\n\n\n\n\n\n\n\nFigure 2: quadratic score-based classification.\n\n\n\n\n\nHow accurate were we?\n\ndf[\"decision\"] = predict(quadratic_score, w, threshold, df)\n(df[\"decision\"] == df[\"loan_status\"]).mean()\n\n0.777\n\n\nOur nonlinear score function was very slightly more accurate than our linear score function on training data. A few things to keep in mind:\n\nPerformance on training data is not always a reliable indicator of performance on unseen data.\nAdding nonlinear features is one way of adding flexibility to a model, allowing that model to learn complicated, “wiggly” decision patterns. As we saw with the Palmer penguins case study, too much model flexibility can lead to worse predictive performance. We’ll regularly revisit the problem of balancing flexibility/features against predictive generalization throughout these notes.\n\n\n\nSo, we looked at a simplified data set in which we were able to observe some features of each prospective borrower \\(i\\) in the form of a vector \\(\\mathbf{x}_i\\). We then computed a score for each borrower \\(s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle\\) and used a threshold to decide whether or not to make a loan: the loan is approved if \\(s_i \\leq t\\) for a chosen threshold \\(t\\). We can think of this as a decision-making model for the loan approval problem.\nIs that the end of the story? Of course not! There are many questions remaining.\n\nModel Evaluation: How do we actually measure whether our decision-making model is good or not? Is accuracy the right measure? Is computing accuracy on the training data reliable? How would the model perform on unseen data that wasn’t used to decide \\(\\mathbf{w}\\) or \\(t\\)? What other ways could we measure the performance of models?\nLegitimacy: Is it morally and politically appropriate to use algorithmic decision-making in the context of loan applications? What is the potential for disparate harm? What is the potential for contributing to the reinforcement of historically disparity? In what cases could algorithmic loan-making be appropriate in a democratic society? In what cases could it constitute a violation of personal political or moral rights?\nTask Choice: How was the data collected? Is it complete? Why did I choose a certain set of predictors and targets? Are my predictors and targets reliable measurements of what they claim to represent? Whose interests are served by the existence of a machine learning model that completes this task?\nAlgorithm Design: What algorithm was used to find the model (i.e. the separating line)? Is that algorithm guaranteed to converge? Will it converge quickly? Would a different algorithm find a better model? Or would it find a model that is equally good more quickly?\nVectorization: Instead of classifying points in a measurement space, how could I instead classify images, videos, or bodies of text?\n\nWe’ll discuss all of these questions – in approximately this order – later in these notes."
  }
]